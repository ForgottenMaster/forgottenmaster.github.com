[{"content":"Overview We often find ourselves wanting to find a smaller sequence, inside of a larger sequence. This often manifests as searching for a substring in a larger text, or determining if a list of numbers is a sublist of another.\nWe can achieve this by looking at a sequence of characters at the beginning of the larger sequence (known as the haystack) that is the same length as the smaller sequence (known as the needle). This sliding motion can be viewed as the following animation\nHowever, with the Naiive approach, when we compare the needle against a specific window in the haystack, we always start by comparing the first elements, then the second elements, and so on until we either hit a mismatch, or have compared all elements as equal.\nThis is obviously a problem for larger sequences as, every time the window slides one position to the right in the haystack, we can end up checking every character in the needle.\nHow is Rabin-Karp different? The basic movement of the \u0026ldquo;window\u0026rdquo; that we\u0026rsquo;re checking in the haystack is still the same - it slides right by one position each step. However where Rabin-Karp differs is by avoiding checking each character to find a mismatch if it knows a mismatch occurs. The way it achieves this is by using a single numeric hash code that represents the sequence of elements we are looking for (known as the fingerprint).\nThe fingerprint of the initial window can be calculated as usual by hashing all the elements in the window. However, where the efficiency comes from with Rabin-Karp is that the method used to calculate the fingerprint allows us to \u0026ldquo;roll\u0026rdquo; that fingerprint each time we move the window to the right by one step.\nWhat this means is, when we move the window to the right by one step, we drop whatever contribution to the overall hash was made by the leftmost element, and then incorporate the new element that\u0026rsquo;s coming in on the right hand side of the window - without having to recalculate all the elements in between.\nHow can it do this? We can do this by multiplying the hash code of each element by a particular, unique number and adding all the values together for a unique fingerprint.\nWe need to first choose a number as a base which we will raise to consecutive powers to determine these multipliers. It doesn\u0026rsquo;t matter too much what this number is, except that it must be greater than 1 (because raising 1 to any power gives 1 which isn\u0026rsquo;t a unique multiplier).\nThe initial fingerprint Given that B is the arbitrary numerical base we will raise, W is the window we\u0026rsquo;re calculating the fingerprint for, and L is the length of that sequence, then the formula is given as follows:\n$$ Fingerprint(W) = \\sum_{n=0}^{L-1} Hash(W_n) \\times B^{L-1-n} $$\nOr, written another way:\n$$ Fingerprint(W) = (Hash(W_0) \\times B^{L-1}) + (Hash(W_1) \\times B^{L-1-1}) + (Hash(W_2) \\times B^{L-1-2}) $$ $$ + \u0026hellip; + (Hash(W_n) \\times B^0 ) $$\n A concrete example It\u0026rsquo;s always difficult to interpret mathematical formulas sometimes, so here is a small and concrete example of calculating the hash code. Given the sequence of integers W=\\([17, 23, 49, 51]\\) we can see that L=4, and if we pick as our base B=2 then in order to calculate the fingerprint, we simply do the following:\n$$ Fingerprint(W) = (Hash(17) \\times 2^3) + (Hash(23) \\times 2^2) + (Hash(49) \\times 2) + Hash(51) $$\nIf we furthermore take Hash(X) to be X itself (as they\u0026rsquo;re already integers), then we can easily compute the final fingerprint as:\n$$ (17 \\times 8) + (23 \\times 4) + (49 \\times 2) + 51 $$ $$ = 136 + 92 + 98 + 51 $$ $$ = 377 $$\n Rolling In order to update the fingerprint after the initial calculation, we will need to do the following in sequence:\n Subtract the highest power term on the left Multiply the fingerprint by B - this has the effect of raising the remaining powers by 1 Add the new term to the fingerprint  Let\u0026rsquo;s look at these in turn\u0026hellip;\nSubtract the highest power term When we slide the window to the right, the elements on the left of the window (and the left of the above formula) will \u0026ldquo;drop off\u0026rdquo;. As we have raised each element to successive powers, we know how to calculate the multiplier added to the hash of element 0. The multiplier is simply \\(B^{L-1}\\), and the value we will subtract from the fingerprint is \\(Hash(W_0) \\times B^{L-1})\\)\nIn the concrete example shown above, we subtract \\((Hash(17) \\times 2^3)\\) and are left with:\n$$ Fingerprint(W) = (Hash(23) \\times 2^2) + (Hash(49) \\times 2^1) + (Hash(51) \\times 2^0) $$\nRaise the powers We now multiply by B (in the concrete example this is 2). Since the following is true:\n$$ (X + Y) \\times Z \\equiv (X \\times Z) + (Y \\times Z) $$\nThis has the effect of multiplying each term in the formula by B, which furthermore, has the effect of raising the power by 1 of each term.\nAfter multiplying by 2, the concrete example will be given as:\n$$ Fingerprint(W) = (Hash(23) \\times 2^3) + (Hash(49) \\times 2^2) + (Hash(51) \\times 2^1) $$\nAdd the new term This is the easiest part. Since the powers of the other terms have been raised, we only need to add the new term into the \u0026ldquo;zeroeth\u0026rdquo; power position, which is simply adding the hashcode of the element.\nIn our concrete example, say that we are rotating in a new element, 101, on the right as the window slides. The new fingerprint is represented as:\n$$ Fingerprint(W) = (Hash(23) \\times 2^3) + (Hash(49) \\times 2^2) + (Hash(51) \\times 2) + Hash(101) $$\nWhich, again assuming Hash(X) is X, gives the new fingerprint of:\n$$ (23 \\times 8) + (49 \\times 4) + (51 \\times 2) + 101 $$ $$ = 184 + 196 + 102 + 101 $$ $$ = 583 $$\nBut what about overflow? As you can see however, from this formula that for large sequence lengths, even for the smallest viable base of 2, will result in an integer growing too large to fit in any sensible datatype.\nAfter all \\(2^{500000}\\) is\u0026hellip;..huge\nWhat can we do to keep these numbers small?\u0026hellip;.Modular Arithmetic\nModular Arithmetic Using modular arithmetic involves using integer division of the number at each step by some known value (known as the modulus) and retaining the remainder. In this way all the numbers \u0026ldquo;wrap around\u0026rdquo; but the formula is still valid, it\u0026rsquo;s just being done on a number circle rather than a number line.\nAn illustration of this is with clocks. Clocks use a modulus of 12 before they wrap around, but you can still add, for example, 4 hours, or subtract 4 hours when that wraps around.\nAdapting the formulas is easy enough, we just apply the modulo operator when calculating the hash code of an element, and at every step of the calculation.\nThe tricky part of this however, is when we are calculating the powers - we can\u0026rsquo;t calculate the power and then apply the modulus as the power calculation overflows. Instead we need to recognise that:\n$$ pow(X, 3) \\equiv (X \\times X \\times X) $$\nAnd this lets us apply modulo at every step, as in (assuming modulus of M):\n$$ ((((X \\mod M) \\times X) \\mod M) \\times X) \\mod M $$\nOne thing we need to accumulate while doing this is the multiplier we have applied to the left most element (\\(B^L-1\\)) which we then can just use later when we\u0026rsquo;re subtracting the left hand term.\nCoding it up Following is a walkthrough of how to code this algorithm up in Rust, the complete source can be found at the playground link HERE\nI\u0026rsquo;ll run through the steps one by one below, explaining the code for those who may be unfamiliar with Rust syntax.\nStep 1 - HashCode trait In Rust we are able to get the hash of a type that implements the Hash trait for use in a HashMap. However this method requires passing the type through a Hasher and incurring a performance cost to generate a hash code for even basic types such as integers.\nSince an integer is its own hash code, and a character can be converted to an integer as a hash code we don\u0026rsquo;t need to do anything too tricky.\nFor the element hashing therefore, I\u0026rsquo;ve gone with creating a new trait:\ntrait HashCode { fn hash_code(\u0026amp;self) -\u0026gt; u64; } That is, a simple trait (interface in other languages) with a single function that operates on an const reference to the element (\u0026amp;self) and returns an integer hash code for it (u64).\nStep 2 - Implementing HashCode for types we want to use The next step is to actually implement the trait for the types we want to be able to use in the sequences for the algorithm. Rust allows us to implement custom traits for existing types in order to extend their functionality - even primitive types. For this, we will implement it for the following primitive types:\n i32 - A signed 32-bit integer. For this, if it\u0026rsquo;s a positive value we can simply keep the value and cast it to a wider, 64 bit integer with no loss. If it\u0026rsquo;s negative, because we know that the range of a 64-bit integer covers the range of the 32-bit integer then we will map the negative portion of i32 by negating it - and then subtracting from u64::MAX. u32 - This involves a simple widening cast which is safe since we know all unsigned 32-bit integer values will fit into an unsigned 64-bit variable. u64 - For this, the hash code is the value itself so it simply returns it. char - Characters in rust are 4 bytes large representing a unicode codepoint. For the same reason as u32 will be safely castable into u64, so are characters.  The implementation of the HashCode trait then is as follows:\nimpl HashCode for i32 { fn hash_code(\u0026amp;self) -\u0026gt; u64 { if *self \u0026gt;= 0 { *self as u64 // if we\u0026#39;re positive, just keep our value and cast as a u64  } else { std::u64::MAX - self.abs() as u64 // if we\u0026#39;re negative, just negate it and then subtract from u64 MAX to use the upper end  } } } impl HashCode for u32 { fn hash_code(\u0026amp;self) -\u0026gt; u64 { *self as u64 } } impl HashCode for u64 { fn hash_code(\u0026amp;self) -\u0026gt; u64 { *self } } impl HashCode for char { fn hash_code(\u0026amp;self) -\u0026gt; u64 { (*self).into() } } Step 3 - Generating a fingerprint In order to be able to roll a fingerprint as described previously, we first need to construct one from scratch for a given range. Given a sequence of elements (that implement our HashCode trait), along with a base to use, and a modulus to keep the numbers small as described in the section on modular arithmetic - we would like a function that will generate the fingerprint for the sequence. Additionally, we want to return the calculated multiplier for that left-most term so that we don\u0026rsquo;t need to calculate it later.\nTo allow us to keep the numbers small, we don\u0026rsquo;t use the pow function, but use an imperative loop to accumulate the fingerprint and base offset.\nThe code for this function looks like the following (note that this assumes the list isn\u0026rsquo;t empty and will panic if it is due to the [0] access):\nfn generate_fingerprint\u0026lt;T: HashCode\u0026gt;(list: \u0026amp;[T], base: u64, modulus: u64) -\u0026gt; (u64, u64) { let mut fingerprint = list[0].hash_code() % modulus; let mut base_offset = 1; for elem in \u0026amp;list[1..] { let elem_hash = elem.hash_code() % modulus; fingerprint = (((fingerprint * base) % modulus) + elem_hash) % modulus; base_offset = (base_offset * base) % modulus; } (fingerprint, base_offset) } Step 4 - Rolling the fingerprint In order to \u0026ldquo;roll\u0026rdquo; the fingerprint and generate the next one from the previous one, we need the following pieces of information:\n The previous fingerprint - for obvious reasons The calculated multiplier (called the base offset) for the left-most element - we use this to calculate the final value to subtract from the fingerprint The old element we\u0026rsquo;re rotating out - we need this to get the hash code from, which is combined with the base offset to get the value to subtract The new element we\u0026rsquo;re rotating in - we need this again to get the hash code which will be added to the fingerprint The base - we need this to allow us to \u0026ldquo;raise the powers\u0026rdquo; of all the remaining terms in the fingerprint after removing the left most term The modulus - we need this for the same reason as we needed it in generate_fingerprint. It lets us perform modular arithmetic and keep the values small  One additional thing to note which could be missed is that before removing the term we want to be rid of, we must first add the modulus to the fingerprint. This is because we\u0026rsquo;re using modular arithmetic - it might wrap around so that the current fingerprint value is less than the value we want to subtract. Adding the modulus essentially adds one full rotation to the fingerprint - allowing us to subtract the term safely.\nThe function looks like the following:\nfn roll_fingerprint\u0026lt;T: HashCode\u0026gt;( mut fingerprint: u64, base_offset: u64, old_term: \u0026amp;T, new_term: \u0026amp;T, base: u64, modulus: u64, ) -\u0026gt; u64 { let old_term_hash = old_term.hash_code() % modulus; let new_term_hash = new_term.hash_code() % modulus; let term_to_subtract = (old_term_hash * base_offset) % modulus; fingerprint = fingerprint + modulus - term_to_subtract; // remove the old term after adding the modulus on to protect against underflow.  fingerprint *= base; // power shift all other terms up by 1  (fingerprint + new_term_hash) % modulus // return new fingerprint after adding in new term and modding } Step 5 - Putting it together Now we can write the actual Rabin-Karp implementation. This function will take a sequence known as the needle, and an equal or larger sequence known as the Haystack, along with the standard base and modulus to use.\nIt will return a boolean value indicating whether the needle was found in the haystack or not. This could be extended if necessary in the future to return the index of the match.\nFor Rabin-Karp, the steps are as follows:\n Calculate the fingerprint of the needle - this will never change and is the fingerprint we\u0026rsquo;re trying to match Handle the trivial case where the needle is empty - an empty needle is always present in any list Generate the initial fingerprint for the slice of the haystack of the same length as the needle - This is the starting fingerprint to match, and also gives us the base offset to use If they match already, then we return a match Otherwise we slide the window along by 1 each time (until the right side of the window hits the end of the haystack), rolling the hash each time to remove the old left hand element and add the incoming element Each time, check if there\u0026rsquo;s a match If we\u0026rsquo;ve checked all windows and not found a match, it\u0026rsquo;s not there  One thing to note though is that it is sufficient to detect a mismatch by mismatching fingerprints however it\u0026rsquo;s not sufficient to detect a match with matching fingerprints. This is because we\u0026rsquo;re using modular arithmetic and a mathematical formula for calculating the final fingerprint - it\u0026rsquo;s possible different sequences end up with the same fingerprint.\nThe efficiency of this algorithm is in the fact we don\u0026rsquo;t have to check elementwise when we know there\u0026rsquo;s a mismatch, and only have to check elementwise in the cases that the fingerprints match.\nBecause of this requirement that elements need to be compared as equal, our Rabin-Karp function requires an additional bound on it\u0026rsquo;s generic type, that of PartialEq (which lets us use the == operator). The final function is as follows:\nfn rabin_karp\u0026lt;T: HashCode + PartialEq\u0026gt;( needle: \u0026amp;[T], haystack: \u0026amp;[T], base: u64, modulus: u64, ) -\u0026gt; bool { if needle.len() == 0 { true // we can always find the empty list inside any list  } else { // get the initial fingerprints and window  let (needle_fingerprint, _) = generate_fingerprint(needle, base, modulus); let needle_len = needle.len(); let haystack_len = haystack.len(); let mut window = \u0026amp;haystack[0..needle_len]; let (mut window_fingerprint, base_offset) = generate_fingerprint(window, base, modulus); // check the initial fingerprints/window for match  if needle_fingerprint == window_fingerprint \u0026amp;\u0026amp; needle == window { return true; } // otherwise run a starting index for the window from 1 up to and including haystack_len-needle_len.  for window_index in 1..=(haystack_len - needle_len) { let new_window = \u0026amp;haystack[window_index..window_index + needle_len]; let roll_out = \u0026amp;window[0]; let roll_in = \u0026amp;new_window[needle_len - 1]; window_fingerprint = roll_fingerprint( window_fingerprint, base_offset, roll_out, roll_in, base, modulus, ); window = new_window; if needle_fingerprint == window_fingerprint \u0026amp;\u0026amp; needle == window { return true; } } // wasn\u0026#39;t found or we\u0026#39;d have returned true on a match.  false } } Testing the implementation The following code snippet is used to test the implementation of Rabin-Karp finds a match or not in the correct cases:\nfn main() { const BASE: u64 = 253; const MODULUS: u64 = 101; println!( \u0026#34;[2, 4, 1] in [7, 8, 2, 4, 1, 5] =\u0026gt; {}\u0026#34;, rabin_karp(\u0026amp;[2, 4, 1], \u0026amp;[7, 8, 2, 4, 1, 5], BASE, MODULUS) ); println!( \u0026#34;[2, 4, 1] in [7, 8, 2, 4, 3, 5] =\u0026gt; {}\u0026#34;, rabin_karp(\u0026amp;[2, 4, 1], \u0026amp;[7, 8, 2, 4, 3, 5], BASE, MODULUS) ); } We\u0026rsquo;re using relatively small sequences, and small modulus but this algorithm is pretty efficient when scaled up at large sizes. In my experiments, a haystack of length 1,000,000 and a needle of length 500,000 resulted in a benchmark time on the naiive algorithm of over 1 minute, whereas with the Rabin-Karp implementation benchmarked the same problem at around 13 milliseconds\nThe output from this is:\n[2, 4, 1] in [7, 8, 2, 4, 1, 5] =\u0026gt; true\r[2, 4, 1] in [7, 8, 2, 4, 3, 5] =\u0026gt; false\r","permalink":"https://forgottenmaster.github.io/posts/algorithms/searching/rabinkarp/","summary":"Overview We often find ourselves wanting to find a smaller sequence, inside of a larger sequence. This often manifests as searching for a substring in a larger text, or determining if a list of numbers is a sublist of another.\nWe can achieve this by looking at a sequence of characters at the beginning of the larger sequence (known as the haystack) that is the same length as the smaller sequence (known as the needle).","title":"Rabin-Karp Pattern Search"},{"content":"Repository A Git repository has 2 main storages:\n  The object store This storage is used to store the actual data, commits, etc. for the repository and is a permanent record of all the changes to the repository. This is efficiently copied across when cloning an existing repository to provide an exact duplicate of not only the data but the whole history.\n  The index This is a temporary store which records changes that have yet to be made to the repository but have been staged.\n  We\u0026rsquo;ll look at these in more detail now\nObject Store The object store portion of the repository stores the 4 main atomic types of objects that Git uses. These are:\n  Blobs - The contents of a single version of a file is represented as a Blob (a contraction of \u0026ldquo;binary large object\u0026rdquo;). A blob is simply the bytes of the file, along with a hash of the contents. Git doesn\u0026rsquo;t store any metadata along with the blob here, but that\u0026rsquo;s stored in other structures within the object store.\n  Trees - A tree is the information about 1 level of the directory structure. It contains references to all the blobs for the files in one directory, along with their path names and some metadata. It may also refer to child trees in order to build up a complete hierarchy by following the root level tree.\n  Commits - A commit object contains the author name/email, along with the commit data and the message that was provided to the log. Each commit points to a single tree object which is the root tree that allows the whole state of the repository to be reproduced for a given commit. Additionally, every commit except for the initial commit will have one (or more - in the case of branch merging) parent commits which allows the software to traverse backwards through the commit chain.\n  Tags - A tag object is an arbitrary string, usually human readable which is assigned to a specific object to allow for it to be referenced by a more readable string rather than the hash that\u0026rsquo;s generated for the object. This is usually used to give certain commits descriptive names, such as for assigning releases.\n  The Index The second storage in a repository is the index, which is a temporary binary file that captures a version of the project\u0026rsquo;s structure at some moment in time. This could be a reference to a given commit (from which we can traverse the tree objects and the blob objects to recreate the directory structure of the whole repository).\nThe developer is allowed to add and remove changes to the index in incremental steps, before finally applying the contents of the index to the object store.\nWhen one runs commands such as add, rm, or mv the changes are staged in the index in a quick and efficient way.\nThe more expensive persistence of the index is done only when the developer commits those changes to the repository.\nTherefore the index is a cache of sorts that allows adding/removing/restoring files as needed in a staging environment before finally committing the index to the repository, resulting in the more heavy processing required.\nThe index also plays an important part in merges, since it can store multiple copies of the same file for merging purposes.\nHashing Every object in the object store in Git is referenced by a unique identifier that represents it, and it only.\nIn the case of Git, this identifier is the SHA-1 hash of the contents of the blob.\nTherefore the object store is basically a hash map that allows efficient retrieval of an object from the store given its unique hash of the contents.\nThis is different to the way that most source control software will store and retrieve files. In others, the files are indexed by file path derived from the directory structure on disk. However Git indexes by hashing the content of the files, meaning if you have two hashes that are the same, you can guarantee that the contents of the blob are the same.\nAdditionally, and more powerfully, since Git stores the entire history as referenced from a head (most recent) commit, and this commit is an object in the store, just like the others, the hash of a commit or tree is derived from any child trees or commits.\nThis is a very powerful statement because it means that if you have two identifiers of two commits, and they are the same - not only do you know the same changes were made in those commits, but you know that the entire history of the repository was the same in both cases too.\nPack Files Git stores the complete contents of each version of every file, since it\u0026rsquo;s deriving the identifier of the file version from the contents of the data itself, it can only operate on entire and complete file contents.\nBut how can it store many different instances of the same file when they only differ by a few characters?\nGit solves this by using pack files, and it achieves it by storing the full contents of a certain blob, and other blobs that are close to it in content are stored alongside that as a diff.\nThus if you have version A of a file, and version B of a file which only has a single character changed, then the pack file will have the full contents of A, along with a diff with the changed character.\nHowever, because Git indexes data by the content itself, and doesn\u0026rsquo;t care about directory structure, it can store different blobs that are in no way related together in a pack file, as long as they\u0026rsquo;re close to each other in nature.\nIn order to be able to locate an object within a pack, Git will store the original SHA-1 hash for each alongside either the complete content or the delta for that content.\nObject Store Diagram A picture is worth a thousand words, as the saying goes, so below is a diagram of a sample object store - showing how blobs, trees, commits, and tags all reference one another.\nIn the diagram, the blobs, being the raw data, are located at the bottom of the diagram. Blobs are standalone objects and don\u0026rsquo;t reference anything, but are referenced by tree objects. These are represented as a rectangle.\nTree objects can reference blobs, and other child trees, along with metadata identifying the path on the user\u0026rsquo;s disk so that it can be reconstructed in the same way on disk. These are represented as a triangle.\nA circle represents a commit here, which may have one or more parent commits, allowing us to traverse backward through history (the root/initial commit has no parent), and points to a single tree, that represents the entire state of the repository at that commit.\nTags point to a commit, and are represented as a parallelogram.\nAs you can see in the diagram, Git stores references from child commits, to their parents. This makes it super easy to add a new commit, as you make the commit, and point it to the previous one - then the new commit becomes the head.\nFrom the diagram, we can see that commit #11235 has information about the author, the commit message, and the timestamp. Additionally has a reference to the parent (initial) commit.\nThe commit object references a tree that in turn, references two blobs, and a child tree referencing a blob.\nThe initial commit references a tree that references two of the same blobs (dead23 and feeb1e) as the new one, but doesn\u0026rsquo;t have access to tree #1010220.\nTherefore we can see from the diagram that the new commit added a file into a subfolder, but all the other files remain the same. Because Git indexes files by their content only, which is immutable, it\u0026rsquo;s able to refer to the same instances of the blobs.\nAccessing the object store You\u0026rsquo;re able to access any given object from the object store by it\u0026rsquo;s SHA-1 hash, which as we\u0026rsquo;re now aware, is the ID of the object (and the hash of the contents).\nWe can do this with the cat-file subcommand. The following is an example of using it to retrieve a data blob from the object store:\ngit cat-file -p 2d10\rText inside the file\rNote that we don\u0026rsquo;t need the full identifier of the blob, just enough of the prefix to allow Git to locate it for display.\nWe can access any object from the store this way, for example accessing a commit\ngit cat-file -p 7a97\rtree 17efabebf0f96829e91a5b9dc358b2e2c2eec05e\rparent 8bddb3945ff1f5978c57fc298c2ab3ba88945a83\rauthor Robin Firth \u0026lt;theforgottenmaster@googlemail.com\u0026gt; 1636230599 +0000\rcommitter Robin Firth \u0026lt;theforgottenmaster@googlemail.com\u0026gt; 1636230599 +0000\rAdded file only on branch\rAnd we can see that the commit has a reference to its tree object, parent commit, and the author metadata.\n","permalink":"https://forgottenmaster.github.io/posts/git/basic_concepts/","summary":"Repository A Git repository has 2 main storages:\n  The object store This storage is used to store the actual data, commits, etc. for the repository and is a permanent record of all the changes to the repository. This is efficiently copied across when cloning an existing repository to provide an exact duplicate of not only the data but the whole history.\n  The index This is a temporary store which records changes that have yet to be made to the repository but have been staged.","title":"Basic Concepts"},{"content":"Creating a repository There are two different ways to establish a repository in Git in contrast to other version control systems where there is only creating the initial repository.\nIn Git we are also able to clone a repository to create copy containing all of the objects and history from an existing repository.\nInitialising a new repository This is how we can create a brand new Git repository which may either be empty, or contain data/files already.\nIn order to initialise a new repository we simply use the init subcommand while inside the root folder we want to turn into a repository. For example if we want to make a brand new one.\nmkdir repo\rcd repo\rgit init\rOf course, the repo folder need not be empty, and the steps would be the same to initialise an existing folder as a repository.\nCloning an existing repository Git is also able to easily make a clone of an existing repository which will copy all of the objects and history across with it, but allows branching and commits to this new repository independant of the source one.\nIn open source development, this is the most common way, as a developer will make a clone of the central repository in order to make their own fixes that they can then request to be merged back into the central/online repository.\nIn order to clone a repository we can do\ngit clone \u0026lt;path-to-repository\u0026gt; repo\rWhere path-to-repository can either be a relative or absolute path to another local repository on the machine or something more exotic such as a URL.\nThe most popular way to clone is using the GitHub URL to the repository.\nAdding and removing files In order to add and remove files to the repository, one can use the add and rm subcommands, along with a set of files to add or remove.\nWhen a file is added or removed however, it is not immediately added to the repository, or removed from the repository but only staged as a change to make to the repository.\nIn order to add a file that is either currently untracked by the repository, or has been edited and needs updating in the repository, we can do the following\ngit add file_to_add.txt\rAnd we can remove a file that is currently tracked by the repository also\ngit rm file_to_remove.txt\rThis will add or remove the file from the staged change as mentioned previously\nViewing staged changes We can use the subcommand status to display the list of files that have been staged to be added or modified, the list of files staged for removal, and the list of files that Git has found in the folder that aren\u0026rsquo;t tracked yet.\nThis last type is the state that a file will be in when you first create it and add it to the folder (or a subfolder), but before it\u0026rsquo;s been staged for addition with the add subcommand.\nFor example, after the following sequence of commands where we add a file, and then remove a file:\ngit add file_to_add.txt\rgit rm file_to_remove.txt\rWe will see the following when we ask for the status:\ngit status\rOn branch master\rChanges to be committed:\r(use \u0026quot;git restore --staged \u0026lt;file\u0026gt;...\u0026quot; to unstage)\rnew file: file_to_add.txt\rdeleted: file_to_remove.txt\rUntracked files:\r(use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to include in what will be committed)\runtracked_file.txt\rCommitting staged changes Once we\u0026rsquo;ve added and removed files to the stage, and we are ready for the repository to be updated to reflect the changes, we will need to perform a commit operation.\nWhen we commit to the repository, we are required to give a message identifying the changes that were made.\nWe can either do this by specifying it on the command line to the commit subcommand as follows:\ngit commit -m \u0026quot;Committing some changes\u0026quot;\rOr, for more detailed messages, they can be composed in a text editor. To do this, just use the commit command without specifying the message:\ngit commit\rWhich will then open the default text editor where you can type a more detailed message, save, and exit - the commit will then be applied.\nOnce staged changes are committed, using the status subcommand again will show that the stage is upto date with the repository, this state is referred to as clean.\nConfiguration The subcommand config can be used to specify various parameters affecting the operation of Git. Before you can make a commit, Git needs to know your name and email address as a minimum.\nThese can be set as such:\ngit config user.name \u0026quot;Name Here\u0026quot;\rgit config user.email \u0026quot;myemailaddress@example.com\u0026quot;\rViewing commits The log subcommand will allow us to see the history of commits done to the repository. They will be displayed from most recent to the oldest, since Git always keeps the head of the commit chain and accesses the others from there.\nEach entry will show the commit hash, along with the author name/email, the date of the commit, and the message.\nFor example after doing two commits to a repository, we may see something like the following on the command line:\ngit log\rcommit 2f988a4223baa3d8bd1db16f8cc777181eb390cd (HEAD -\u0026gt; master)\rAuthor: Robin Firth \u0026lt;theforgottenmaster@googlemail.com\u0026gt;\rDate: Sat Nov 6 19:34:57 2021 +0000\rChanged the text from \u0026quot;Some text\u0026quot; to \u0026quot;Changed text\u0026quot;\rcommit 18dd164cf53fdb05bb757d3e0b452c4bfcf0b38a\rAuthor: Robin Firth \u0026lt;theforgottenmaster@googlemail.com\u0026gt;\rDate: Sat Nov 6 19:33:55 2021 +0000\rInitial commit\rAn individual commit can be viewed with the show subcommand. This is useful if you are given a commit hash in conversation with someone and you want to see what was changed in that commit.\nFor example, to see the initial commit above we can use show and see the following:\ngit show 18dd164cf53fdb05bb757d3e0b452c4bfcf0b38a\rcommit 18dd164cf53fdb05bb757d3e0b452c4bfcf0b38a\rAuthor: Robin Firth \u0026lt;theforgottenmaster@googlemail.com\u0026gt;\rDate: Sat Nov 6 19:33:55 2021 +0000\rInitial commit\rdiff --git a/file_to_add.txt b/file_to_add.txt\rnew file mode 100644\rindex 0000000..9dbfeee\r--- /dev/null\r+++ b/file_to_add.txt\r@@ -0,0 +1 @@\r+Some text\r\\ No newline at end of file\rThis shows the same information as in the log, however also shows the file differences that were part of that commit.\nDiffing commits If you have any 2 commit hashes, you can easily determine the diff that is applied to the first commit, in order to reach the second commit.\nFor example, in order to see the diff that was applied between the initial commit, and the second commit above, we will use the command and see something like:\ngit diff 18dd164cf53fdb05bb757d3e0b452c4bfcf0b38a 2f988a4223baa3d8bd1db16f8cc777181eb390cd\rdiff --git a/file_to_add.txt b/file_to_add.txt\rindex 9dbfeee..41c4a21 100644\r--- a/file_to_add.txt\r+++ b/file_to_add.txt\r@@ -1 +1 @@\r-Some text\r\\ No newline at end of file\r+Changed text\r\\ No newline at end of file\rAnd we can see fromm the diff that \u0026ldquo;Some text\u0026rdquo; was removed, and \u0026ldquo;Changed text\u0026rdquo; was added in its place.\nRenaming files We could achieve the same result as a rename by removing the file, renaming it, and adding it back again, however there is a Git command for renaming or moving a file. For example if we want to rename file_to_add.txt to renamed_file.txt, we can do so as follows:\ngit mv file_to_add.txt renamed_file.txt\rA move can be achieved by keeping the destination filename the same, but specifying the folder that it should be placed under.\nAfter the above rename, running git status shows:\nOn branch master\rChanges to be committed:\r(use \u0026quot;git restore --staged \u0026lt;file\u0026gt;...\u0026quot; to unstage)\rrenamed: file_to_add.txt -\u0026gt; renamed_file.txt\rAdvanced configuration There are actually 3 levels of configuration for the Git config subcommand\n Repository-specific. These are the default level if you use the config subcommand without specifying one of the others. These will take precedence if set and override any system or user level configuration settings. User-specific. These are next lowest in the hierarchy and if not overridden will be applied for all repositories for that user only. These are set by using the \u0026ndash;global option. System-wide. These are the lowest priority and if not overridden will apply to all repositories, of all users on that system. This is specified with the \u0026ndash;system option.  Example: setting name For an example, we\u0026rsquo;ll show setting the user.name configuration setting we showed before, at the 3 levels of configuration.\n Repository-specific  git config user.name \u0026quot;User Name For This Repo Only\u0026quot;\rUser-specific  git config --global user.name \u0026quot;User Name For All Repositories For This User\u0026quot;\rSystem-wide  git config --system user.name \u0026quot;User Name For Everybody\u0026quot;\rViewing configuration settings We can view all the set configuration settings by passing the \u0026ldquo;-l\u0026rdquo; flag to the config subcommand. Which will display something like the following:\ngit config -l\rdiff.astextplain.textconv=astextplain\rfilter.lfs.clean=git-lfs clean -- %f\rfilter.lfs.smudge=git-lfs smudge -- %f\rfilter.lfs.process=git-lfs filter-process\rfilter.lfs.required=true\rhttp.sslbackend=openssl\rhttp.sslcainfo=C:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crt\rcore.autocrlf=true\rcore.fscache=true\rcore.symlinks=false\rcore.editor=\u0026quot;C:\\\\Program Files\\\\Microsoft VS Code\\\\bin\\\\code.cmd\u0026quot; --wait\rpull.rebase=false\rcredential.helper=manager-core\rcredential.https://dev.azure.com.usehttppath=true\rinit.defaultbranch=master\ruser.email=theforgottenmaster@googlemail.com\ruser.name=Robin Firth\rcore.repositoryformatversion=0\rcore.filemode=false\rcore.bare=false\rcore.logallrefupdates=true\rcore.symlinks=false\rcore.ignorecase=true\rUnsetting a configuration setting The \u0026ndash;unset flag can be passed to unset a specific configuration setting at any of the three levels (by omitting, or including either \u0026ndash;global or \u0026ndash;system flags). For unsetting the user.name setting for example at all levels, we could do:\ngit config --unset user.name\rgit config --unset --global user.name\rgit config --unset --system user.name\rAliases You can set your own aliases for more complex commands in Git. This allows you to run complex commands with a shorter subcommand.\nFor example we can make an alias which will commit with a default message, and run it:\ngit config alias.default-commit -- \u0026quot;commit -m 'Default commit message'\u0026quot;\rgit default-commit\r","permalink":"https://forgottenmaster.github.io/posts/git/basic_usage/","summary":"Creating a repository There are two different ways to establish a repository in Git in contrast to other version control systems where there is only creating the initial repository.\nIn Git we are also able to clone a repository to create copy containing all of the objects and history from an existing repository.\nInitialising a new repository This is how we can create a brand new Git repository which may either be empty, or contain data/files already.","title":"Basic Usage"},{"content":"What are traits? Traits in Rust can basically be thought of as interfaces in C#. They can do everything that a C# interface can do except with a few more capabilities. We will start off by equating the common functionality of traits in Rust with C# interfaces, and then explore the additional capabilities we get with Rust traits.\nDescribes capabilities In C# interfaces, we can describe a set of function signatures which will tell the user the capabilities of that interface, such that they know when they call something what data to pass in, and what they should get back. The caller need not know how the function is implemented by a specific type, just that it does what is described on the tin.\nFor example, a C# interface which provides the capability to get an identifier through a GetIdentifier function which takes no arguments, and returns the ID of the instance as an integer can look as follows:\ninterface IGetIdentifier { int GetIdentifier(); } In Rust we can describe the exact same functionality. Note however a few changes in order to follow naming conventions or required by the language syntax:\n interface keyword is renamed to trait In Rust, the naming convention for a trait that has a single method is just the name of the method itself Rust has sized integer types so int is replaced with i32 (can be any of the other integer types too) Rust requires each member function to take explicitly the object we\u0026rsquo;re calling on. This allows us to tell the compiler/caller whether we\u0026rsquo;re taking an immutable reference, mutable reference, or taking ownership. In this case we only need an immutable reference to get an identifier Rust naming convention for functions and variables is snake_case. Therefore GetIdentifier method is renamed get_identifer.  The equivalent Rust definition is therefore:\ntrait GetIdentifier { fn get_identifier(\u0026amp;self) -\u0026gt; i32; } Generics In C# we are also able to make an interface generic. This is useful if we need to implement an interface multiple times for a given type for different situations. We can\u0026rsquo;t implement the same interface multiple times, but each different set of generic parameters is essentially a different interface.\nLet\u0026rsquo;s say we extend the above interface to work for any identifier type and not just integers. The C# snippet would be extended to look as follows:\ninterface IGetIdentifier\u0026lt;T\u0026gt; { T GetIdentifier(); } Likewise, the Rust snippet is extended with the exact same syntax:\ntrait GetIdentifier\u0026lt;T\u0026gt; { fn get_identifier(\u0026amp;self) -\u0026gt; T; } Bounded generics This is the ability to constrain generic parameter types to ones that only implement certain interfaces. In C# we have the ability to constrain based on interface or base class type, however in Rust we don\u0026rsquo;t have struct inheritance but do have trait inheritance. As a result, in Rust we can only constrain on interface. But this is good practice anyways as inheritance of behaviour is better than inheritance of state.\nIn C# if we want to bound the above interface to only allow T\u0026rsquo;s that implement an \u0026ldquo;IIdentifier\u0026rdquo; interface, that is an interface that allows the type to be used as an identifier, would look like this:\ninterface IGetIdentfier\u0026lt;T\u0026gt; where T : IIdentifier { T GetIdentifier(); } In Rust, we have two options for defining trait bounds, we can do it as above with a \u0026ldquo;where\u0026rdquo; syntax. This is useful when there are lots of bounds for a type and we can break them up over multiple lines which is more readable in most cases:\ntrait GetIdentifier\u0026lt;T\u0026gt; where T: Identifier { fn get_identifier(\u0026amp;self) -\u0026gt; T; } However we also have the ability to define these trait bounds inline, which for fewer trait bounds could be neater:\ntrait GetIdentifier\u0026lt;T: Identifier\u0026gt; { fn get_identifier(\u0026amp;self) -\u0026gt; T; } Default implementations Since C#8 we have the ability to provide default implementations for methods, to be used if the implementor doesn\u0026rsquo;t provide their own implementation. This lets us define some required methods that must be implemented, by not defining a default implementation, and provided methods (which can still be overridden, but don\u0026rsquo;t need to be) by giving a default.\nFor example in C#, if we assume that the definition of the \u0026ldquo;IIdentifier\u0026rdquo; interface is as follows:\ninterface Identifier { string GetString(); } Then we can add a provided method to the GetIdentifier interface which will print out the string identifier (note that we still require the GetIdentifier function to be implemented since there\u0026rsquo;s no possible way we can know how to get one). We get the resulting code:\ninterface IGetIdentifier\u0026lt;T\u0026gt; where T: IIdentifier { T GetIdentifier(); void PrintIdentifier() { System.Console.WriteLine($\u0026#34;{GetIdentifier().GetString()}\u0026#34;); } } We can do the same in Rust too in the same way as the following code snippet shows:\ntrait GetIdentifier\u0026lt;T: Identifier\u0026gt; { fn get_identifier(\u0026amp;self) -\u0026gt; T; fn print_identifier(\u0026amp;self) { println!(\u0026#34;{}\u0026#34;, self.get_identifier().get_string()); } } Implementing We can of course implement an interface or trait in both C# and Rust (what use would an interface be if we couldn\u0026rsquo;t!?). However the syntax is different, and this is where we start to see C# and Rust diverge quite dramatically.\nIn C# we have to provide the implementation of the interface at the same point as we define the implementing class/struct itself. For example, implementing the IIdentifier interface for a struct Foo:\nstruct Foo : IIdentifier { public int identifier; public string GetString() =\u0026gt; $\u0026#34;{identifier}\u0026#34;; } And implementing the IGetIdentifiertrait for a second struct FooGetter:\nstruct FooGetter : IGetIdentifier\u0026lt;Foo\u0026gt; { public Foo identifier; public Foo GetIdentifier() =\u0026gt; identifier; } In Rust however, the difference is that we define implementation blocks separate to the variables inside the struct itself. This allows us to break up behaviour/functions from the pure data contained in the structure. Each trait has its own implementation block so the implementation of the above structures and trait implementations will look as follows:\n#[derive(Clone)] struct Foo { pub i32 identifier; } impl Identifier for Foo { pub fn get_string(\u0026amp;self) -\u0026gt; String { format!(\u0026#34;{}\u0026#34;, self.identifier) } } struct FooGetter { pub Foo identifier; } impl GetIdentifier\u0026lt;Foo\u0026gt; for FooGetter { pub fn get_identifier(\u0026amp;self) -\u0026gt; Foo { self.identifier.clone() } } Note the Clone implementation required on Foo, and the clone function call in get_identifier. This is required because in Rust every type is movable, and clones are explicit. Adding the #[derive(Clone)] attribute to the struct allows us to automatically derive a deep clone implementation as long as all the struct fields implement Clone.\nNote that this is not idiomatic Rust, clones are rarely used as we can pass references around safely and the compiler will check the ownership and lifetime rules for us.\nIs that it? So you might look at the previous content and think that Rust traits are just C# interfaces with a different syntax. They can do everything C# interfaces can do right?. Well, yes, except that there are more capabilities that Rust gives us that just aren\u0026rsquo;t possible in C#\nThe following few sections then will only contain Rust snippets as there\u0026rsquo;s no valid way to represent them in C# (or C++, or most languages I\u0026rsquo;ve used - except Haskell, which makes traits similar to typeclasses).\nAssociated Types In the above code snippets, we had a generic trait GetIdentifier which was implemented on FooGetter with the generic parameter Foo. However this opens the way for us to have multiple implementations on FooGetter with different types. However what if we want to force the user to define a maximum of 1 implementation of GetIdentifier?\nWell, we have to remove the generics, and we end up with a trait as follows:\ntrait GetIdentifier { fn get_identifier(\u0026amp;self) -\u0026gt; ??? // what type goes here? } However, we have a problem here since we don\u0026rsquo;t know what the actual identifier type is now for any given implementation. We\u0026rsquo;ve removed the ability to specify it in a generic parameter, so in C# the only way to do this would be to fix the concrete type we return. That means all implementors of GetIdentifier returns the same type.\nTechnically in C# we can do it by returning the IIdenfier interface itself:\ninterface IGetIdentifier { IIdentifier GetIdentifier(); } Which indeed will allow each implementor to determine what the actual type they\u0026rsquo;re returning is, as long as it implements the IIdenfier interface.\nThe downside here is that we are forced to box the result which means a heap allocation, which means garbage collector tracking overhead.\nWe can do the same thing in Rust, we have to be explicit about returning a dynamic trait object in a box though:\ntrait GetIdentifier { fn get_identifier(\u0026amp;self) -\u0026gt; Box\u0026lt;dyn Identifier\u0026gt;; } However this still requires allocating heap storage and returning. An additional downside is type erasure. We\u0026rsquo;ve lost all information about the actual concrete type, all we know is the Box has an Identifier in it, so can only access the methods of the Identifier trait and nothing more.\nThere must be a better way!?. Enter associated types:\ntrait GetIdentifier { type IdentifierType: Identifier; fn get_identifier(\u0026amp;self) -\u0026gt; Self::IdentifierType; fn print_identifier(\u0026amp;self) { println!(\u0026#34;{}\u0026#34;, self.get_identifier().get_string()); } } Problems solved!. There\u0026rsquo;s a bit of new syntax here, but the main points are:\n We define an associated type on the trait with the type T syntax, allowing each implementor to specify a different concrete type We place a trait bound on it so that only concrete types implementing the Identifier trait can be used We return Self::IdentifierType from the get_identifier function. Importantly this is the concrete type, meaning no heap allocations and no type erasure  One further thing with associated types is that we can add trait bounds that force them to a specific concrete type. For example, say that we want to create a function that will take any GetIdentifier and print it, but only if the identifier type is an i32. We can do this as a trait bound with the following syntax:\nfn call_print_identifier_if_i32\u0026lt;T: GetIdentifier\u0026lt;IdentifierType = i32\u0026gt;\u0026gt;(t: \u0026amp;T) { t.print_identifier(); } We can also even place trait bounds on associated types within trait bounds!. For example if we want a function that will accept any GetIdentifier, but only if the IdentifierType implements Clone, we can do so:\nfn do_something\u0026lt;T\u0026gt;(t: \u0026amp;T) where T: GetIdentifier, \u0026lt;T as GetIdentifier\u0026gt;::IdentifierType: Clone { let c = t.get_identifier().clone(); // do something with cloned instance } Associated methods Unlike C# (and most other languages) interfaces which can only define methods tied to the specific instance of the implementing type, due to requiring dynamic dispatch and using a vtable, in Rust we can also define methods at the type level. These would be called static methods in other languages but in Rust, they are known as associated methods.\nA simple example of a trait making use of this functionality is the Default trait in the standard library. If we were to define it ourselves, we can do it like this:\ntrait Default { fn default() -\u0026gt; Self; } Self here is the implementing type, and notice how an associated method is indicated not by a keyword, but by the lack of self, \u0026amp;self, or \u0026amp;mut self in the first argument position.\nThese associated methods can be called with :: syntax, for example if our type Foo implements Default, we can call it as:\nlet default_foo = Foo::default(); Extension traits The next feature Rust provides us with respect to traits is as a side effect of having to implement them separate to the type we\u0026rsquo;re implementing on. This implies we can implement traits for types that we don\u0026rsquo;t actually own. This isn\u0026rsquo;t possible in C# or C++ where the implementation of a type is defined at the same time as the type itself.\nThis means that we are able to add functionality to existing types, even standard library types or primitive types by creating a trait and implementing it.\nFor example, say that we want to add a AsBytes trait which specifies that the type has a method called as_bytes which returns a vector of u8\u0026rsquo;s representing the bytes of the type.\nSuch a trait can be defined like:\ntrait AsBytes { fn as_bytes(\u0026amp;self) -\u0026gt; Vec\u0026lt;u8\u0026gt;; } And we can implement that for our own types, however, unlike in most other languages, we can implement this for existing types even primitives. For example on a u32:\nimpl AsBytes for u32 { fn as_bytes(\u0026amp;self) -\u0026gt; Vec\u0026lt;u8\u0026gt; { self.to_le_bytes().to_vec() } } to_le_bytes is a function that the standard library provides for us, that will give us an array of u8\u0026rsquo;s of length 4 with the bytes of the u32 in it. We can call to_vec on this to turn it into a dynamically sized vector instead to return.\nBlanket implementations The final feature for traits that we have with Rust is the ability to implement a trait for all types, optionally bounded with trait bounds.\nLet\u0026rsquo;s say we want to add a method to all iterators which will result in a new iterator that prints out the item (for all items that are displayable) as it iterates them.\nNote that we can do this with a map call to decorate a function, taking the input, printing it and returning it again to make a new iterator. This would look something like this:\nlet iter = (0..10).map(|elem| { println!(\u0026#34;{}\u0026#34;, elem); elem }); However this requires the user to roll the function themselves to print and return, and is a bit unwieldy. What we\u0026rsquo;d like is:\nlet iter = (0..).print(); We can do this with a blanket implementation that adds this print function to all iterators. First we need a structure to wrap the iterator that will step through and do the printing:\nstruct Print\u0026lt;T\u0026gt; { iterator: T } We will need to implement the Iterator trait here for the new structure, so that we can step over and print the elements. However we can only do this if the elements implement the Display trait. We can use trait bounds to ensure that:\n T is an Iterator The elements from T implement Display  This will look as follows:\nimpl\u0026lt;T: Iterator\u0026gt; Iterator for Print\u0026lt;T\u0026gt; where \u0026lt;T as Iterator\u0026gt;::Item: Display { type Item = \u0026lt;T as Iterator\u0026gt;::Item; // just passing the items through  fn next(\u0026amp;mut self) -\u0026gt; Option\u0026lt;Self::Item\u0026gt; { let item = self.iterator.next()?; println!(\u0026#34;{}\u0026#34;, item); Some(item) } } The little ? syntax when we call the next function of the iterator we\u0026rsquo;re wrapping is a little outside of the scope of the article, but the easiest way to think of it is if that call returns None, then we return None immediately. Otherwise item is set to the value inside the Some (which we then print and return).\nFinally we need to actually add the convenience function to all iterators. We can do this by creating an extension trait called IteratorPrint with the print function we want:\ntrait IteratorPrint where Self: Sized { fn print(self) -\u0026gt; Print\u0026lt;Self\u0026gt; { Print { iterator: self } } } We need to specify Self: Sized because traits in Rust can be implemented even for dynamically sized types which can\u0026rsquo;t exist on their own and must be boxed or put behind a reference.\nSince we need to put self into the Print structure, it will need to have a compile time known size, so we specify we can only use it with such types.\nNow we have all the boilerplate setup, we can actually do the blanket implementation. We\u0026rsquo;ll add it only to compatible iterators, otherwise we end up with a more cryptic compile error. The actual final code for this is as follows:\nimpl\u0026lt;T: Iterator\u0026gt; IteratorPrint for T where \u0026lt;T as Iterator\u0026gt;::Item: Display { } Then we can take any iterator that has elements that are displayable, and use this print function on it, even if we didn\u0026rsquo;t write the iterator type ourselves!. For example the following is valid:\n(0..10).print().for_each(|_| {}); The for_each call will just apply the closure to each element, in our case we just want to do nothing, but it will trigger the prints as it iterates.\n","permalink":"https://forgottenmaster.github.io/posts/rust/whyrust/traits/","summary":"What are traits? Traits in Rust can basically be thought of as interfaces in C#. They can do everything that a C# interface can do except with a few more capabilities. We will start off by equating the common functionality of traits in Rust with C# interfaces, and then explore the additional capabilities we get with Rust traits.\nDescribes capabilities In C# interfaces, we can describe a set of function signatures which will tell the user the capabilities of that interface, such that they know when they call something what data to pass in, and what they should get back.","title":"Traits"},{"content":"Move By Default In most programming languages, there is no one true \u0026ldquo;owner\u0026rdquo; of any given piece of data. Data can be allocated on the stack or the heap but references to it can be passed around as needed. There isn\u0026rsquo;t a way of the compiler to track ownership of a piece of data in most languages such as C++.\nAdditionally expensive copies of structures may be done without us realising, or being able to opt out of it. For example in C++ and C# the following code will result in making a copy of SomeLargeStruct\nSomeExpensiveStruct s1; SomeExpensiveStruct s2 = s1; // this will make a copy of s1  In Rust, each piece of data has a single owner at any one time. If the owning binding or function goes out of scope, the data is dropped and this gives an opportunity for the type to do any resources allocated. This is similar to a destructor in C++. Due to the single ownership model, Rust moves data by default on assigment, or when passing into and out of functions.\nAn example of the flow of ownership in Rust is the following\nlet v1 = vec![1, 2, 3]; // v1 is a binding that owns a vector with the integers 1, 2, and 3 let v2 = v1; // v1 is *moved* to binding v2. v2 is now the owner of the vector, v1 has relinquished control println!(\u0026#34;{}\u0026#34;, v1); // here we are trying to print out v1, but v1 isn\u0026#39;t the owner of any data and so can\u0026#39;t give out references, etc.  In the above code snippet, the binding v1 transfers ownership of the data to the binding v2, trying to use v1 afterwards results in the following compiler output\nerror[E0382]: use of moved value: `v1`\r--\u0026gt; src/main.rs:4:10\r|\r2 | let v1 = vec![1, 2, 3];\r| -- move occurs because `v1` has type `Vec\u0026lt;i32\u0026gt;`, which does not implement the `Copy` trait\r3 | let v2 = v1;\r| -- value moved here\r4 | dbg!(v1);\r| ^^ value used here after move\r Rust won\u0026rsquo;t let us compile a program which violates the ownership rules like this.\nThe above example is of a move that occurs when assigning from one binding to another, but the same will happen if we passed into a function, for example\nfn foo(v: Vec\u0026lt;i32\u0026gt;) { // v is a vector of integers, ownership is transferred into the function from outside  // the function is the owner of the data, so at the end of the function, the data is dropped } fn main() { let v = vec![1, 2, 3]; foo(v); // ownership is transferred into the function here  dbg!(v); } Will result in a similar compiler error as before:\nerror[E0382]: use of moved value: `v`\r--\u0026gt; src/main.rs:7:10\r|\r5 | let v = vec![1, 2, 3];\r| - move occurs because `v` has type `Vec\u0026lt;i32\u0026gt;`, which does not implement the `Copy` trait\r6 | foo(v);\r| - value moved here\r7 | dbg!(v);\r| ^ value used here after move\r Use After Free In languages such as C++, there are no mechanisms which prevent a use after free error. For example the following code is completely valid\nstruct SomeStruct { public: const char* name; }; SomeStruct\u0026amp; allocAndReturn() { SomeStruct s; s.name = \u0026#34;Hello, World!\u0026#34;; return s; } int main() { SomeStruct\u0026amp; s = allocAndReturn(); std::cout \u0026lt;\u0026lt; s.name \u0026lt;\u0026lt; std::endl; // Boom!, we\u0026#39;ve used an invalid reference  return 0; } As the C++ compiler doesn\u0026rsquo;t track ownership or lifetimes, it doesn\u0026rsquo;t prevent the function from returning a reference to an object that then goes out of scope, then when it tries to access s.name the program segfaults.\nContrast this in Rust, where the compiler tracks lifetimes, it is able to detect a use after free and will fail to compile. If we attempt to return a reference to an object created in a function as in the above program, we won\u0026rsquo;t be able to compile. As it\u0026rsquo;s difficult to do the above function in Rust without delving into lifetime annotations, a smaller program demonstrates the same issue\nfn main() { let v = { let v = vec![4, 5, 6]; \u0026amp;v }; dbg!(v); } As Rust is an expression based language, we can create an arbitrary scope or code block that ends in an expression, and use that to assign to a binding, or anywhere else an expression is accepted.\nIn the code snippet, we are creating a vector v inside the block, and then trying to return a reference to it, out of the block and bind it to the outer v binding.\nHowever Rust detects that we are trying to keep a reference for longer than the object is in scope and gives the following compiler error\nerror[E0597]: `v` does not live long enough\r--\u0026gt; src/main.rs:4:9\r|\r2 | let v = {\r| - borrow later stored here\r3 | let v = vec![4, 5, 6];\r4 | \u0026amp;v\r| ^^ borrowed value does not live long enough\r5 | };\r| - `v` dropped here while still borrowed\r This is the Rust\u0026rsquo;s borrow checker and lifetime rules at work.\nModification While Reading In other languages, it\u0026rsquo;s common for a mutable and immutable reference to exist at the same time. For example in C++ we may do the following:\nSomeStruct s; const SomeStruct \u0026amp;s1 = s; SomeStruct\u0026amp; s2 = s; The implications of this is that someone that is holding an immutable reference to an object will observe changes made to the object (through a mutable reference). This is contrary to what the definition should be of an immutable reference, the holder shouldn\u0026rsquo;t see any changes as it\u0026rsquo;s immutable.\nIf we attempt to do this in Rust, it will fail to compile as we cannot take a mutable and immutable reference at the same time (though we may take as many immutable references as we\u0026rsquo;d like since none will observe any changes).\nfn main() { let mut v = vec![1, 2, 3]; let v1 = \u0026amp;v; let v2 = \u0026amp;mut v; dbg!(v1); } We are greeted with the following compile error\nerror[E0502]: cannot borrow `v` as mutable because it is also borrowed as immutable\r--\u0026gt; src/main.rs:4:14\r|\r3 | let v1 = \u0026amp;v;\r| -- immutable borrow occurs here\r4 | let v2 = \u0026amp;mut v;\r| ^^^^^^ mutable borrow occurs here\r5 | dbg!(v1);\r| -- immutable borrow later used here\r Rust guarantees memory safety here by allowing either 0 or more immutable references OR 0 or 1 mutable reference. It is forbidden to have a mutable reference while ANY references are taken, and only 1 mutable reference can be taken at a time.\nThis means if you hold a mutable reference to an object, the compiler guarantees that only you can make changes to the object. It also guarantees that if you hold an immutable reference you will never see any state changes through that.\nThis isn\u0026rsquo;t strictly true\u0026hellip;.there are types in the standard library that allow for interior mutability, that is, mutating through an immutable reference. However, they are also perfectly safe to use because they perform the check at runtime instead. When using those types, you are only allowed to mutate a value if nothing else currently holds a borrow to it.\nIn conclusion, most programming languages have no real protections against multiple sources writing to an object, even when other sources have read-only access. Rust has a policy of only 1 writer at a time, and only when there are no readers in existence.\nThis does require some code restructuring to separate the reading from the writing, but results in much safer code and prevents common problems such as modifying a collection while iterating over it, which is impossible in Rust due to the borrow checker.\nThread Safety The last topic on memory safety in Rust will be a few words on how the safety rules also apply in a multithreaded context.\nMost languages don\u0026rsquo;t have any guarantees about whether an object is safe to be accessed from multiple threads at a time, and if an object is not safe, but is accessed concurrently from 2 threads, this is called a data race, and is not a good thing.\nRust provides a system by which the compiler will fail to compile a program if we try to use a non thread-safe type in a multithreaded context.\nThe way it achieves this is by using two core traits called Send and Sync\nThese are implemented (or not implemented) by types automatically based on the data inside the types. If all the members of a custom type are Send, or Sync then the type itself is Send or Sync.\nSend means that instances of this type can be transferred over to a different thread. This is transfer of ownership across a thread boundary.\nSync means that instances of this type can be accessed from multiple threads at the same time, that is references to the instance are Send.\nThe developer can implement Send and Sync manually on types if those types aren\u0026rsquo;t automatically deemed Send/Sync, however to do so is an unsafe operation as it requires that the developer has checked that the type is indeed thread-safe.\n","permalink":"https://forgottenmaster.github.io/posts/rust/whyrust/memorysafety/","summary":"Move By Default In most programming languages, there is no one true \u0026ldquo;owner\u0026rdquo; of any given piece of data. Data can be allocated on the stack or the heap but references to it can be passed around as needed. There isn\u0026rsquo;t a way of the compiler to track ownership of a piece of data in most languages such as C++.\nAdditionally expensive copies of structures may be done without us realising, or being able to opt out of it.","title":"Memory Safety"},{"content":"The final piece of the puzzle in the mathematical foundations needed is to determine how we can trace back a derivative with respect to matrix inputs.\nIn the previous post we saw that calculating the derivative of two vectors of equal length when passing through the dot product operation results in the transpose of the other.\nMatrix Multiplication Refresher The first step is to recall how we can multiply two matrices together. In deep learning typically this will be performed with a matrix of samples, and a matrix of weights to be applied. The result being a weighted sum of the samples with weights.\nIn order for the product of two matrices to be defined, the number of columns in the first matrix must equal the number of rows in the second. The resulting matrix will be of the outer dimensions.\nThat is, given a matrix X, of dimensions m x n and a matrix W, of dimensions n x p then the multiplication is defined, and the resulting matrix is of dimensions m x p.\nIn the resulting matrix, an element at row i and column j is the result of the dot product of the ith row of the first matrix, and the jth row of the second matrix.\nAs a concrete example, suppose we have\n$$ X = \\begin{bmatrix} X_{11} \u0026amp; X_{12} \u0026amp; X_{13} \\\\ X_{21} \u0026amp; X_{22} \u0026amp; X_{23} \\\\ X_{31} \u0026amp; X_{32} \u0026amp; X_{33} \\end{bmatrix} $$ $$ W = \\begin{bmatrix} W_{11} \u0026amp; W_{12} \\\\ W_{21} \u0026amp; W_{22} \\\\ W_{31} \u0026amp; W_{32} \\end{bmatrix} $$\nThen the resulting matrix can be represented as\n$$ X \\cdot W = \\begin{bmatrix} XW_{11} \u0026amp; XW_{12} \\\\ XW_{21} \u0026amp; XW_{22} \\\\ XW_{31} \u0026amp; XW_{32} \\end{bmatrix} $$\nWhere \\(XW_{ij}\\) is the dot product of the ith row of X and the jth row of W\nDerivative Of Matrices In order for us to be able to calculate the rate of change in the output of a function with respect to the elements of one of the input matrices we will need to have the output be either:\n A matrix of the same size as an input matrix - derivative can be calculated elementwise in that case between input and output matrices A scalar value - derivative can be calculated elementwise for each element in the input matrix to determine how this affects the single output  For deep learning, we want to be able to first multiply a matrix of samples (X) by a matrix of weights (W) in order to get the weighted sum of the records in a resulting matrix, then we would like to pass the resulting matrix to a function that produces a single value that could be used to activate a neuron for example.\nTherefore what we have is a function F which can be defined as\n$$ F = F(Y) $$\nThat is it takes some matrix Y and performs an operation on it (in our case likely summing the elements). The matrix Y will be produced by multiplying the two input matrices, that is:\n$$ Y = X \\cdot W $$\nIn order to calculate the total derivative with respect to the input matrices, we can apply the chain rule. The first step of which is easy, that is to take Y and calculate how a change in each element would affect the resulting single value. The derivative of F therefore is a matrix representing these partial derivatives. We will call this G, that is \\(G = F'(Y)\\)\nThe derivative of Y depends on two variables X and W which are multiplied together. The formula for the total derivative therefore is\n$$ dY = dX \\cdot W + X \\cdot dW $$\nThat is, changes in the elements of X would end up being multiplied by W, and also changes in the elements of W would end up being multiplied by X.\nThen, the derivative of the total function can be given (using the chain rule) as:\n$$ dF = G:dY $$\nAnd expanding out dY with the above formula gives\n$$ dF = G:dX \\cdot W + G:X \\cdot dW $$\nFor notation, X:Y means the elementwise multiplication of matrices X and Y, that must be the same dimensions (also known as frobenius inner product).\nIsolating dX and dY In the above formula, we have G being multiplied elementwise by a matrix that is the result of matrix multiplication between dX and W or X and dW.\nWhat we want to do is to isolate dX and dY so that they are multiplied elementwise with the other matrix. How can we get W and X onto the other side?\nWell,\n$$ G : (dX \\cdot W) = (G \\cdot W^T) : dX $$\nAnd\n$$ G : (X \\cdot dW) = (X^T \\cdot G) : dW $$\nThat is, the total derivative can be calculated as\n$$ dF = (G \\cdot W^T) : dX + (X^T \\cdot G) : dW $$\nPartial Derivatives Now from the above formula, we can easily calculate the partial derivatives of F by holding either X or W as constant, meaning dX or dW respectively is 0.\nDoing this will eliminate the term from the formula leaving only the other one. This shows us how the partial derivatives are\n$$ \\frac{\\partial F}{\\partial X} = G \\cdot W^T $$ $$ \\frac{\\partial F}{\\partial W} = X^T \\cdot W $$\nAdditional Notes The book at this point actually didn\u0026rsquo;t explain how we get to using the transpose matrices for derivatives, instead the book says in a handwavey fashion that \u0026ldquo;the way the mathematics works out\u0026rdquo;.\nI found the above explanation at This Page and above tried to break it down as best I could.\nI will likely need to revisit matrix multiplication in the future but for now understand it enough to move on to learning more about the structure of a neural network and applying these rules in practice.\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/matrixinputs/","summary":"The final piece of the puzzle in the mathematical foundations needed is to determine how we can trace back a derivative with respect to matrix inputs.\nIn the previous post we saw that calculating the derivative of two vectors of equal length when passing through the dot product operation results in the transpose of the other.\nMatrix Multiplication Refresher The first step is to recall how we can multiply two matrices together.","title":"Matrix Inputs"},{"content":"After learning what a derivative of a function is, and how to apply the chain rule to a composite function, we then learned how to calculate the derivative of a function with multiple inputs by tracing back through the chain of functions following the route of one of the parameters while holding the others constant.\nThe next step in the prerequisite mathematics we need to build the foundations of a neural network is to determine what the derivative of a function means when one or more of the inputs is a vector.\nGiven the following block diagram for a chain of functions\nThat is, a function, f which takes two inputs both of which are vectors (denoted by the bar above the name), and a function, g which operates on the resulting value.\nFurthermore, let\u0026rsquo;s say that f is actually the dot product function. This function is written as follows, if we assume that X and W are both vectors of length 3:\n$$ f(X, W) = X \\cdot W = X_1 \\times W_1 + X_2 \\times W_2 + X_3 \\times W_3 $$\nAs a reminder, the derivative of a function is the ratio of the change in the output given a change in the input, at a specific input value (point on the graph of the function). This is easy to determine when the inputs and outputs are plain values as it\u0026rsquo;s just a ratio of the two deltas.\nWhen an input is a vector though, what does a change in the input mean?. In fact, this is easily interpreted as a change in one of the components of the input.\nAs seen in the dot product formula (though the function can be any function on vectors), a vector can be decomposed into a list of individual numbers/components. Therefore we can calculate the derivative of the function with respect to an individual component by holding the others to be constant and varying the one we\u0026rsquo;re interested in.\nAfter applying this first function though, the second is operating on a single value and so the chain rule applies as before. In the case of the dot product, this gives us 6 partial derivatives: 3 with respect to the 3 components in the input vector X and 3 with respect to the components of W.\nThe formulas for calculating the derivatives then for the composite function will be as follows in accordance with the chain rule (where n is a valid index for the input vector):\n$$ (g \\circ f)_{X_n} = f_{X_n}(X, W) \\times g'(f(X, W)) $$ $$ (g \\circ f)_{W_n} = f_{W_n}(X, W) \\times g'(f(X, W)) $$\nLooking back at the formula for calculating the dot product we can see that holding all values constant except for a single component we are interested in causes a change in the output proportional to the matching component of the other vector. For example if we let \\(X_1\\) increase by 1 while holding all other components constant, we can see that the only part of the formula containing \\(X_1\\) is\n$$ X_1 \\times W_1 $$\nIncreasing \\(X_1\\) by 1 then increases the output only by \\(W_1\\)\nWhen we calculate the derivative for the other components then, we find out that elementwise, the derivatives of the dot product with respect to X can be represented by:\n$$ \\begin{bmatrix} W_1 \u0026amp; W_2 \u0026amp; W_3 \\end{bmatrix} $$\nand by the same token, the component wise derivatives of the dot product with respect to W is:\n$$ \\begin{bmatrix} X_1 \u0026amp; X_2 \u0026amp; X_3 \\end{bmatrix} $$\nWhen we write the dot product as row and column vectors in order to have the correct shapes for performing the dot product:\n$$ \\begin{bmatrix} X_1 \u0026amp; X_2 \u0026amp; X_3 \\end{bmatrix} \\cdot \\begin{bmatrix} W_1 \\\\ W_2 \\\\ W_3 \\end{bmatrix} $$\nWe can see that the component wise derivative with respect to X will be \\( \\begin{bmatrix} W_1 \u0026amp; W_2 \u0026amp; W_3 \\end{bmatrix} \\), that is \\(W^T\\) and the component wise derivative with respect to W will be \\( \\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\end{bmatrix} \\), that is \\(X^T\\)\nConclusion In conclusion, calculating the derivative of a function with vector inputs is just calculating the derivative of the function with respect to each component in the vector. Additionally, and most importantly for deep learning, the derivative of the dot product of a row vector X with a column vector W turns out to be \\(W^T\\) and \\(X^T\\) respectively.\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/vectorinputs/","summary":"After learning what a derivative of a function is, and how to apply the chain rule to a composite function, we then learned how to calculate the derivative of a function with multiple inputs by tracing back through the chain of functions following the route of one of the parameters while holding the others constant.\nThe next step in the prerequisite mathematics we need to build the foundations of a neural network is to determine what the derivative of a function means when one or more of the inputs is a vector.","title":"Vector Inputs"},{"content":"So far, we\u0026rsquo;ve learned how to chain functions together, and how to calculate the derivative of a function at a specific input value. We\u0026rsquo;ve also learned how to apply the chain rule when we are chaining multiple functions together. However, how do we calculate the derivative of a function, or chain of functions when a function has multiple inputs?.\nAs it turns out, we can calculate the derivative in the same way!, we just need to, in the case where there are multiple inputs, calculate the partial derivative with respect to the given parameter.\nLets start off with a single function, one that takes two inputs and returns a single output\nIn such a function, the change in the output can be affected by a change in either input (x or y). Because of this, calculating the derivative with respect to x at a given value might result in a different value to what is given when calculating the derivative for input y. These are the partial derivatives of the function, where each partial derivative is how the output changes with a given change of the input (while keeping the other inputs constant).\nThe formulas for these partial derivatives can be given as:\n$$ \\frac {\\partial f} {\\partial x} = \\lim_{\\Delta \\to 0} \\frac {f(x + \\Delta, y) - f(x - \\Delta, y)} {2 \\times \\Delta} $$ $$ \\frac {\\partial f} {\\partial y} = \\lim_{\\Delta \\to 0} \\frac {f(x, y + \\Delta) - f(x, y - \\Delta)} {2 \\times \\Delta} $$\nApplying the chain rule We can apply the chain rule in the same way when calculating the partial derivative of a composite function with respect to one of the inputs. Since the change in input causes a change in the input to the next function, which then causes a change in the input to the next, and so on, we will still do a backward pass the same way as we would with a single input. We just follow it back to the point where the input is given. For example with the following\nWe can see that the first function has two inputs whereas g and h have only 1 input. So there will be two partial derivatives for this composite function. These can be given as follows (applying the chain rule):\n$$ (f \\circ g \\circ h)_x = f_x(x, y) \\times g'(f(x, y)) \\times h'(g(f(x, y))) $$ $$ (f \\circ g \\circ h)_y = f_y(x, y) \\times g'(f(x, y)) \\times h'(g(f(x, y))) $$\nNote that here we are using Legrange\u0026rsquo;s Notation as it can be cleaner than the Leibniz notation. In this notation we can use \\(f'(x)\\) to denote the derivative of function f taking a single input, at value x.\nWith multiple inputs, the input we\u0026rsquo;re describing the partial derivative of can be given as a subscript. e.g. \\(f_x(x, y)\\) would be saying we are interested in how much a change in x will cause a change in the output of the function, at the point defined by the given values of x and y.\nOverall the chain rule works the same way as a single input, except we are defining the input we\u0026rsquo;re interested in when back propagating to work out the derivative.\nLet\u0026rsquo;s assume the following functions to calculate the derivative of a given 2 input function with respect to each of the inputs:\nfn derivative_x(f: impl Fn(f64, f64) -\u0026gt; f64, x: f64, y: f64, delta: f64) -\u0026gt; f64 { (f(x + delta, y) - f(x - delta, y)) / (2.0 * delta) } fn derivative_y(f: impl Fn(f64, f64) -\u0026gt; f64, x: f64, y: f64, delta: f64) -\u0026gt; f64 { (f(x, y + delta) - f(x, y - delta)) / (2.0 * delta) } Along with the existence of the previous function, \u0026ldquo;derivative\u0026rdquo; which performs the same calculation but on a single input function. We can then calculate the derivatives of the composite function as shown above with the following functions:\nfn derivative_x_chain(f: impl Fn(f64, f64) -\u0026gt; f64, g: impl Fn(f64) -\u0026gt; f64, h: impl Fn(f64) -\u0026gt; f64, x: f64, y: f64, delta: f64) -\u0026gt; f64 { // forward pass to calculate inputs  let f_of_xy = f(x, y); let g_of_f_of_xy = g(f_of_xy); // backward pass to calculate partial derivatives  let derivative_f = derivative_x(f, x, y, delta); let derivative_g = derivative(g, f_of_xy, delta); let derivative_h = derivative(h, g_of_f_of_xy, delta); // total derivative with respect to x of compound function  derivative_f * derivative_g * derivative_h } fn derivative_y_chain(f: impl Fn(f64, f64) -\u0026gt; f64, g: impl Fn(f64) -\u0026gt; f64, h: impl Fn(f64) -\u0026gt; f64, x: f64, y: f64, delta: f64) -\u0026gt; f64 { // forward pass to calculate inputs  let f_of_xy = f(x, y); let g_of_f_of_xy = g(f_of_xy); // backward pass to calculate partial derivatives  let derivative_f = derivative_y(f, x, y, delta); let derivative_g = derivative(g, f_of_xy, delta); let derivative_h = derivative(h, g_of_f_of_xy, delta); // total derivative with respect to x of compound function  derivative_f * derivative_g * derivative_h } For a runnable example of comparing calculating the derivative of a composite function both directly and via the chain rule, I have written a simple example on the Rust Playground which shows that the derivative calculated for a composite function directly results in the same value as a derivative calculated using the chain rule (both single and multiple input functions are tested).\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/multipleinputs/","summary":"So far, we\u0026rsquo;ve learned how to chain functions together, and how to calculate the derivative of a function at a specific input value. We\u0026rsquo;ve also learned how to apply the chain rule when we are chaining multiple functions together. However, how do we calculate the derivative of a function, or chain of functions when a function has multiple inputs?.\nAs it turns out, we can calculate the derivative in the same way!","title":"Multiple Inputs"},{"content":"C Style Enums In C#, C++, and a lot of other popular programming languages, we have access to a type called an \u0026ldquo;enumeration\u0026rdquo; (or enum for short). This is simply a type safe collection of named constant values.\nFor example in C++, making an enum whose variants represent a set of allowed colors for a hypothetical UI framework could be written as (with the values of the variants explicitly typed out for transparency):\nenum Color { Red = 1, Green = 2, Blue = 3 }; A function can then go ahead and accept a \u0026ldquo;Color\u0026rdquo; and the user will be able to pass only the named colors. Except that in C++, this is not true. Nothing stops the caller from casting an arbitrary integer as a \u0026ldquo;Color\u0026rdquo;. For example calling a SetColor function that takes a Color, the caller can do:\nwidget.SetColor(static_cast\u0026lt;Color\u0026gt;(10)); // what even is color with value 10???. It hasn\u0026#39;t been defined so likely won\u0026#39;t be correctly handled.  This is not desired as SetColor can\u0026rsquo;t assume that the given Color is only one that was specified in the enumeration. If someone can arbitrarily cast an integer to Color, what is the function supposed to do with it?.\nIn Rust, we can have value type enums the same way:\nenum Color { Red = 1, Green = 2, Blue = 3 } And casting such an enum value into an integer is totally fine, the following snippet will print \u0026ldquo;Selected color is: 3\u0026rdquo;:\n// enum variant to integral value is safely supported because it\u0026#39;s a total function - all enum variants in this style of enumeration // can be cast to the respective integer value. println!(\u0026#34;Selected color is: {}\u0026#34;, Color::Blue as u8); This is totally fine and allowed by Rust because all variants of this C-style enumeration can be casted safely to an integer. We say it\u0026rsquo;s infallible\nHowever, casting an integer to an enumeration type is not infallible because not all possible integral values have a variant in the enumeration, we can\u0026rsquo;t do the following - it simply does not compile:\n// does not compile as integral to enum conversion is not implemented since it can fail for certain values of integer. let int_as_color = 10 as Blue; Rust is a safe and cautious language and the compiler will just not allow operations that could fail, therefore converting from enum to integral isn\u0026rsquo;t supported by default, however the enum creator can implement the TryFromtrait for any integral types.\nHowever this is boilerplate that\u0026rsquo;s already been done and available in a crate. Therefore to allow for C-style enums in Rust with safe conversions in both directions, it\u0026rsquo;s best to use https://crates.io/crates/num_enum\nTuple Enums In C++, the above is all you get, loosely typed integers that aren\u0026rsquo;t even that safe. With Rust, enums become more powerful with the ability to store different data inside of each variant.\nThese are similar to an algebraic data type such as Haskell has. It could be thought of similar to a union in C++ in that an element of the enum type takes up the amount of space required for the biggest variant (allowing it to store in an array), but strongly typed so you can\u0026rsquo;t access data you shouldn\u0026rsquo;t.\nAs an example, suppose we want to have an \u0026ldquo;Angle\u0026rdquo; enumeration. An angle could be stored in either Degrees or Radians, but both are stored as floats. In this case the tuple enum would look as follows:\nenum Angle { Degrees(f32), Radians(f32) } In both of these variants, we store an f32, but behind the scenes each instance of Angle is tagged with its discriminant (Degrees or Radians) and the only way to access the data inside is through pattern matching. This means we literally can\u0026rsquo;t access data that we shouldn\u0026rsquo;t for the variant we have. An example of implementing the Intotrait for this would be:\nimpl Into\u0026lt;f32\u0026gt; for Angle { fn into(self) -\u0026gt; f32 { match self { Self::Degrees(val) =\u0026gt; val, Self::Radians(val) =\u0026gt; val } } } An example of an enumeration with differing types could be a Color, where we can choose between different color formats:\nenum Color { RGBF32(f32, f32, f32), RGBAF32(f32, f32, f32, f32), RGBU8(u8, u8, u8), RGBAU8(u8, u8, u8, u8) } That is, we can choose between colors with RGB or RGBA components, and can choose the type of the components we\u0026rsquo;re storing. However because this is essentially a strongly typed union, and Rust requires all types to have a defined size to be stored, the largest size would still be picked, in this case each Color would be 16 bytes large (corresponding to the size of RGBAF32 which is largest).\nPattern matching works the exact same way. For example, a method on Color which can return whether the color supports transparency could be written as follows:\nimpl Color { fn supports_transparency(\u0026amp;self) -\u0026gt; bool { match self { Self::RGBF32(..) =\u0026gt; false, Self::RGBAF32(..) =\u0026gt; true, Self::RGBU8(..) =\u0026gt; false, Self::RGBAU8(..) =\u0026gt; true } } } Named Field Enums A variant in an enum can use the tuple syntax for defining the types it contains, and pattern matching as described above, however we can also store values associated with an enum variant by name in a record/struct like syntax. We can freely mix and match these on a per-variant basis. For example an enumeration which represents an Error. We might support storing an ErrorMessage, ErrorCode, or both. This might look as follows:\nenum Error { Message(String), Code(i32), Both { message: String, code: i32 } } When pattern matching on tuple types, we need to use the tuple patterns. When matching on record types, we need to use that syntax. An example of a function to try to get an error code from an Error would be:\nimpl Error { fn try_get_code(\u0026amp;self) -\u0026gt; Option\u0026lt;i32\u0026gt; { match self { Self::Message(..) =\u0026gt; None, Self::Code(c) =\u0026gt; Some(*c), Self::Both{code: c, ..} =\u0026gt; Some(*c) } } } Empty Enums!? Empty enums can\u0026rsquo;t be constructed. This may sound kind of pointless, what does\nenum Void { } Even mean if it can\u0026rsquo;t be constructed?\nAs it turns out this can be very useful for statically proving that we can\u0026rsquo;t ever take a particular branch of code in some cases, and is sometimes seen in generic code.\nFor example, in Rust we have the Result type which has two type parameters. One is the success type, and one is the error type. Say that a trait requires a return type of Result\u0026lt;SuccessType, ErrorType\u0026gt; from a function\ntrait TryOperation { type SuccessType; type ErrorType; fn try_operation(\u0026amp;mut self) -\u0026gt; Result\u0026lt;Self::SuccessType, Self::ErrorType\u0026gt; } In order to implement such a trait, we must provide an ErrorType to satisfy the signature of the trait, but for an infallible operation which is guaranteed to not fail, what do we choose for an ErrorType?. Any type is as good as any other type if we never need to construct it and we never return it:\nstruct InfallibleOperation { } impl TryOperation for InfallibleOperation { type SuccessType = (); // Unit type is like \u0026#34;void\u0026#34; in other languages, it\u0026#39;s a type we can use when we don\u0026#39;t need to return any information.  type ErrorType = ???; // What do we put here if this operation never fails?  fn try_operation(\u0026amp;mut self) -\u0026gt; Result\u0026lt;Self::SuccessType, Self::ErrorType\u0026gt; { println!(\u0026#34;Hello, World!\u0026#34;); } } The implementation of this function simply prints to the console and never fails, we\u0026rsquo;re \u0026ldquo;trying\u0026rdquo; to perform the operation but it will always succeed. It turns out in these cases we can communicate this at the type level to the caller by using the empty enum as the ErrorType (e.g. Void). If the caller sees that the signature for this is:\nfn try_operation(\u0026amp;mut self) -\u0026gt; Result\u0026lt;(), Void\u0026gt; Then they can easily see that the error case can never possibly happen (because an instance of Void physically cannot be constructed). In this case, the caller knows it\u0026rsquo;s safe to not even handle the possibility of error as this is ensured by the compiler in the types.\n","permalink":"https://forgottenmaster.github.io/posts/rust/whyrust/enums/","summary":"C Style Enums In C#, C++, and a lot of other popular programming languages, we have access to a type called an \u0026ldquo;enumeration\u0026rdquo; (or enum for short). This is simply a type safe collection of named constant values.\nFor example in C++, making an enum whose variants represent a set of allowed colors for a hypothetical UI framework could be written as (with the values of the variants explicitly typed out for transparency):","title":"Enums"},{"content":"The chain rule allows us to determine the derivative of a composite function as a product of the derivatives of each of the individual functions.\nThe reason this is a product is because, say you had a function \u0026ldquo;f\u0026rdquo; which has a derivative of 3 at a particular value of x. That means, when you increase the input by 1, the output increases by 3.\nThen say you have a second function \u0026ldquo;g\u0026rdquo; which has a derivative of 5 at the value output by \u0026ldquo;f\u0026rdquo; for x. This again means that when you increase the input by 1, then the output increases proportionally, this time by 5.\nHowever, the compound function \\( g \\circ f \\) will chain these two together in such a way that increasing the input to f increases the output of f by 3, and because they were chained, this is the same as increasing the input to g by 3.\nSince the gradient of g is 5 meaning that the output change is 5 times the change of the input, then raising the input to that function by 3 must result in a raise of the output by 15.\nSince derivatives are calculated as the gradient at a particular value, we need to know the inputs and outputs of both functions in order to calculate the partial derivatives.\nOnce we have these, we can just multiply them together.\nThe formula for the chain rule in this situation will be:\n$$ (g \\circ f)'(x) = g'(f(x)) \\times f'(x) $$\nThat is, calculating the rate of change (gradient) of the initial function f at the given value of x. After this, calculating the gradient of the second function, g, at the value output by f.\nTherefore in order to calculate these compound derivatives, we need to run two passes.\nThe first pass, called the forward pass, is where we simply are obtaining the input and output values for all functions involved. The second pass, called the backward pass, is where we use the inputs and outputs of the functions in order to calculate their gradients at that point. The final step is then just to multiply together to get the gradient of the composite function.\nThis two-pass sequence can be visualised with the following diagram. In it, we have three functions and an x value that\u0026rsquo;s passed in. we run the x value through the functions in order to get \\( f(x) \\), then \\( g(f(x)) \\), and finally \\( h(g(f(x))) \\).\nThe dashed lines represents the backward pass where we take the calculated values to determine the derivatives of f, g, and h at the appropriate input values.\n We can code up the calculation of the derivative of such a chain of functions as displayed in the diagram. For this section of code, we\u0026rsquo;ll assume the existence of a helper function called \u0026ldquo;derivative\u0026rdquo; which, given a function and a value at which the calculate the derivative, will approximate the derivative using the logic described in the previous post.\n// forward pass, calculating all inputs/outputs let x = 42.0; // initial input let f_of_x = f(x); // output from f (also input to g) let g_of_f_of_x = g(f_of_x); // output from g (also input to h) let h_of_g_of_f_of_x = h(g_of_f_of_x); output from h which is the final output // backward pass, calculating the derivatives of the functions at the calculated inputs let deriv_h = derivative(h, g_of_f_of_x); // calculate the derivative of h at the value that was output from g let deriv_g = derivative(g, f_of_x); // calculate derivative of g at the value that was output from f let deriv_f = derivative(f, x); // calculate derivative of f at the value of x  // multiply together to get the final rate of change of the output with change to x deriv_h * deriv_g * deriv_f ","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/chainrule/","summary":"The chain rule allows us to determine the derivative of a composite function as a product of the derivatives of each of the individual functions.\nThe reason this is a product is because, say you had a function \u0026ldquo;f\u0026rdquo; which has a derivative of 3 at a particular value of x. That means, when you increase the input by 1, the output increases by 3.\nThen say you have a second function \u0026ldquo;g\u0026rdquo; which has a derivative of 5 at the value output by \u0026ldquo;f\u0026rdquo; for x.","title":"Chain Rule"},{"content":"Maths The derivative of a function is the rate at which the output changes with respect to a change in the input at a specific value for the input. This last part is important as the derivative of a function is essentially the gradient, or tangent of the graph of that function at a specific point which can of course change depending on where you are on the number line.\nThe formula for calculating the derivative of a given function \u0026ldquo;f\u0026rdquo; with respect to it\u0026rsquo;s input parameter \u0026ldquo;x\u0026rdquo;, at a given value of x which we call \u0026ldquo;a\u0026rdquo; here, can be written as:\n$$ \\frac{\\partial f}{\\partial x}(a) = \\lim_{\\Delta \\to 0} \\frac{f(a + \\Delta) - f(a - \\Delta)}{2 \\times \\Delta} $$\nLet\u0026rsquo;s break this down a little.\nWe\u0026rsquo;ll take the left hand side of the formula first, that is \\( \\frac{\\partial f}{\\partial x}(a) \\) which is the partial derivative of f with respect to x, at the given value of a. If we wanted to take another partial derivative of f, for example if the function took multiple parameters, the parameter we\u0026rsquo;re taking the partial derivative with respect to will appear as the denominator. For example, in a function such as:\n$$ f(x, y, z) = x + y + z $$\nThen the partial derivatives could be written as: \\( \\frac{\\partial f}{\\partial x} \\), \\( \\frac{\\partial f}{\\partial y} \\), and \\( \\frac{\\partial f}{\\partial z} \\)\nWhat\u0026rsquo;s a limit?\nThe first symbol in the right hand side is this \\( \\lim_{\\Delta \\to 0} \\) which means \u0026ldquo;as \\(\\Delta\\) approaches 0\u0026rdquo;. Limits are a way of talking about the way the function reacts to bringing certain parameters closer to a given limit. Essentially, the closer the parameter is to the limit, the more accurate the approximation is. In our case we talk about the function being as \\(\\Delta\\) approaches 0, the right hand side becomes more accurately the correct value for the derivative.\nOf course, \\(\\Delta\\) can never be 0, as this would result in a divide by zero operation which is undefined, but we can get arbitrarily close.\nWhat\u0026rsquo;s delta?\nThe symbol \\(\\Delta\\) is the greek symbol \u0026ldquo;Delta\u0026rdquo; which we use here to mean a change. Since to calculate the derivative we\u0026rsquo;re applying a small change to the value, and measuring how the output is affected by this small change.\nHow is the derivative calculated?\nThe rest of the right hand side is simply calculating the actual derivative at the value a, with the given \\(\\Delta\\) value. For a pretty close approximation of the true derivative, we can choose a very small value of delta, for example 0.001. We first add the small value to the value at which we\u0026rsquo;re calculating the derivative, this is the \\( f(a + \\Delta) \\)\nThis gives us the output of the function at a point ever so slightly in front of the test value (a). In order to measure a rate of change, two samples are required. We could have simply applied the function to a itself, however in order to account for asymmetry in the graph, we can get a better test by applying the function to the value located slightly behind the test value, this is \\( f(a - \\Delta) \\).\nFinally we take the difference of these two sample points, that is the difference in their outputs. This gives us the difference in the function output \\( f(a + \\Delta) - f(a - \\Delta) \\).\nIn order to get the gradient, once we have the change in the output of the function, we must divide by the change in the input. Since we both added and subtracted \\( \\Delta \\) to get our sample input points, the range (change in input) is \\( 2 \\times \\Delta \\)\n Code We can code up a function that can calculate the derivative of another function at a given input value, and given the value of the small delta we\u0026rsquo;re applying.\nThe function we write here will take a float in and output a float for simplicity. We could of course use generics to allow this to work for various types. With floats being the data type used, it would look as follows\nfn derivative(f: impl Fn(f64) -\u0026gt; f64, a: f64, delta: f64) -\u0026gt; f64 { let front_result = f(a + delta); let back_result = f(a - delta); let input_change = delta * 2.0; let output_change = front_result - back_result; output_change / input_change } An example call of finding the derivative of a function:\n$$ f(x) = x^2 $$\nat the input value 42 might look as follows:\nlet f = |x| x * x; let a = 42.0; let delta = 0.001; derivative(f, a, delta)  Diagram A derivative of a function being the rate of change of the output with change in the input can be visualised by the following diagram. This diagram shows a function f, which maps \u0026ldquo;x\u0026rdquo; to \u0026ldquo;y\u0026rdquo;, and shows a change in the input (dx) producing a change in the output (dy). The ratio of \\( \\frac{dy}{dx} \\) gives us the derivative\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/derivatives/","summary":"Maths The derivative of a function is the rate at which the output changes with respect to a change in the input at a specific value for the input. This last part is important as the derivative of a function is essentially the gradient, or tangent of the graph of that function at a specific point which can of course change depending on where you are on the number line.","title":"Derivatives"},{"content":"There isn\u0026rsquo;t too much to say for what a function actually is, since being a programmer, we use them every day. However for completeness I\u0026rsquo;ll include a post here.\nFor our purposes it will help to think of a function as a black box, that takes one or more inputs and returns an output. We can then chain these functions together by taking the output of function 1, and passing it to the next function and so on.\nThe advantage of thinking of them as a chain like this rather than a stack as programmers are used to thinking of them, is that this chain will easily map to the concept of the forward pass of a neural network later on.\nAssuming the existence of the following two functions, each of which takes a single parameter:\n$$ f(x) = x^2 $$ $$ g(x) = x + 10 $$\nWe can code these functions as below, along with how they\u0026rsquo;re chained together to act as one big composite function that takes input into the first, and extracts output from the last:\nlet f = |x: f64| x * x; let g = |x: f64| x + 10.0; let input = 42.0; // input into the first function in the chain let intermediate = f(input); // after invoking function \u0026#34;f\u0026#34;, the output is an intermediate result let output = g(intermediate); // to get the final input, we can pass this intermediate result through \u0026#34;g\u0026#34;  A diagram showing function omposition would look something like this, where the chain of two functions results in the same as running through a single function that is the composite of the two\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/functions/","summary":"There isn\u0026rsquo;t too much to say for what a function actually is, since being a programmer, we use them every day. However for completeness I\u0026rsquo;ll include a post here.\nFor our purposes it will help to think of a function as a black box, that takes one or more inputs and returns an output. We can then chain these functions together by taking the output of function 1, and passing it to the next function and so on.","title":"Functions"},{"content":" Ubisoft Reflections\nSenior Gameplay Programmer\nApril 2020 - Present\nAs a senior gameplay programmer I have been responsible for architecting and implementing large systems in Assassin\u0026rsquo;s Creed VR. Where the product statement isn\u0026rsquo;t clear or is incomplete, I have worked with other disciplines to ensure the final design does what is required. During this time I have gained experience in Unity3D including DOTS and best practices for efficient programs. Additionally, I attempt to always share my knowledge as I develop it myself so as to allow others to also build their skills.\nUbisoft Reflections\nGameplay Programmer\nMarch 2018 - April 2020\nAs a gameplay programmer I have helped design and implement some fairly large systems for \u0026ldquo;Tom Clancy\u0026rsquo;s The Division 2\u0026rdquo; with the main feature being clans. As part of the clans feature I worked with designers, as well as the online team in order to develop clan missions and rewards, and clan spaces.\nUbisoft Reflections\nJunior Gameplay Programmer\nNovember 2014 - March 2018\nIn this position I worked on \u0026ldquo;Tom Clancy\u0026rsquo;s The Division\u0026rdquo; as well as the associated expansion packs and DLC. I gained industry experience using C++ in a large codebase, and also with the in-house engine used to develop these (Snowdrop). I gained experience in using visual scripting and node graph systems.\n Eutechnyx Ltd.\nProgrammer\nJuly 2010 - November 2014\nWhile working at Eutechnyx I was part of the team developing \u0026ldquo;Auto Club Revolution\u0026rdquo;, a social network and gaming site revolving around car enthusiasts. I gained experience with front and back end web technologies using HTML/CSS/JavaScript for the frontend, and Python for the backend. Additional technologies used were MongoDB for the database management software, along with Redis for caching. Being a dynamic website, I gained experience interfacing with popular APIs including Facebook, and payment providers.\n Newcastle University\nMSc, Computer Games Engineering\n2008-2009\nDissertation titled \u0026ldquo;Games with a purpose\u0026rdquo;\nGraduated with merit\nNewcastle University\nBSc, Computing Science\n2005-2008\nDissertation titled \u0026ldquo;Video records of everyday life\u0026rdquo;\nGraduated with first class degree\n","permalink":"https://forgottenmaster.github.io/resume/","summary":"Ubisoft Reflections\nSenior Gameplay Programmer\nApril 2020 - Present\nAs a senior gameplay programmer I have been responsible for architecting and implementing large systems in Assassin\u0026rsquo;s Creed VR. Where the product statement isn\u0026rsquo;t clear or is incomplete, I have worked with other disciplines to ensure the final design does what is required. During this time I have gained experience in Unity3D including DOTS and best practices for efficient programs. Additionally, I attempt to always share my knowledge as I develop it myself so as to allow others to also build their skills.","title":"Résumé"}]