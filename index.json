[{"content":"This series of posts is intended to be a set of reasons I love using the Rust programming language. This isn\u0026rsquo;t a statement to say that you should use it, but hopefully it can bring some light on the differences between languages such as C++/C# and Rust, and show what Rust could bring to the table.\nEach post will just be a self-contained entry about a single feature of Rust that I appreciate, so feel free to flick through as needed.\n","permalink":"https://forgottenmaster.github.io/posts/rust/whyrust/introduction/","summary":"This series of posts is intended to be a set of reasons I love using the Rust programming language. This isn\u0026rsquo;t a statement to say that you should use it, but hopefully it can bring some light on the differences between languages such as C++/C# and Rust, and show what Rust could bring to the table.\nEach post will just be a self-contained entry about a single feature of Rust that I appreciate, so feel free to flick through as needed.","title":"Introduction"},{"content":"There isn\u0026rsquo;t too much to say for what a function actually is, since being a programmer, we use them every day. However for completeness I\u0026rsquo;ll include a post here.\nFor our purposes it will help to think of a function as a black box, that takes one or more inputs and returns an output. We can then chain these functions together by taking the output of function 1, and passing it to the next function and so on.\nThe advantage of thinking of them as a chain like this rather than a stack as programmers are used to thinking of them, is that this chain will easily map to the concept of the forward pass of a neural network later on.\nAssuming the existence of the following two functions, each of which takes a single parameter:\n$$ f(x) = x^2 $$ $$ g(x) = x + 10 $$\nWe can code these functions as below, along with how they\u0026rsquo;re chained together to act as one big composite function that takes input into the first, and extracts output from the last:\nlet f = |x: f64| x * x; let g = |x: f64| x + 10.0; let input = 42.0; // input into the first function in the chain let intermediate = f(input); // after invoking function \u0026#34;f\u0026#34;, the output is an intermediate result let output = g(intermediate); // to get the final input, we can pass this intermediate result through \u0026#34;g\u0026#34;  A diagram showing function omposition would look something like this, where the chain of two functions results in the same as running through a single function that is the composite of the two\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/functions/","summary":"There isn\u0026rsquo;t too much to say for what a function actually is, since being a programmer, we use them every day. However for completeness I\u0026rsquo;ll include a post here.\nFor our purposes it will help to think of a function as a black box, that takes one or more inputs and returns an output. We can then chain these functions together by taking the output of function 1, and passing it to the next function and so on.","title":"Functions"},{"content":"This series of posts will be my notes from the following book \nThe main reason for this series of posts will be to allow me to create notes in my own words in order to understand the concepts being taught in this book.\nOne thing to note is that any code snippets I include in these posts will be in Rust, rather than Python. I will be using the Rust crate ndarray as my data structure, in lieu of numpy\u0026rsquo;s ndarray.\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/introduction/","summary":"This series of posts will be my notes from the following book \nThe main reason for this series of posts will be to allow me to create notes in my own words in order to understand the concepts being taught in this book.\nOne thing to note is that any code snippets I include in these posts will be in Rust, rather than Python. I will be using the Rust crate ndarray as my data structure, in lieu of numpy\u0026rsquo;s ndarray.","title":"Introduction"},{"content":"C Style Enums In C#, C++, and a lot of other popular programming languages, we have access to a type called an \u0026ldquo;enumeration\u0026rdquo; (or enum for short). This is simply a type safe collection of named constant values.\nFor example in C++, making an enum whose variants represent a set of allowed colors for a hypothetical UI framework could be written as (with the values of the variants explicitly typed out for transparency):\nenum Color { Red = 1, Green = 2, Blue = 3 }; A function can then go ahead and accept a \u0026ldquo;Color\u0026rdquo; and the user will be able to pass only the named colors. Except that in C++, this is not true. Nothing stops the caller from casting an arbitrary integer as a \u0026ldquo;Color\u0026rdquo;. For example calling a SetColor function that takes a Color, the caller can do:\nwidget.SetColor(static_cast\u0026lt;Color\u0026gt;(10)); // what even is color with value 10???. It hasn\u0026#39;t been defined so likely won\u0026#39;t be correctly handled.  This is not desired as SetColor can\u0026rsquo;t assume that the given Color is only one that was specified in the enumeration. If someone can arbitrarily cast an integer to Color, what is the function supposed to do with it?.\nIn Rust, we can have value type enums the same way:\nenum Color { Red = 1, Green = 2, Blue = 3 } And casting such an enum value into an integer is totally fine, the following snippet will print \u0026ldquo;Selected color is: 3\u0026rdquo;:\n// enum variant to integral value is safely supported because it\u0026#39;s a total function - all enum variants in this style of enumeration // can be cast to the respective integer value. println!(\u0026#34;Selected color is: {}\u0026#34;, Color::Blue as u8); This is totally fine and allowed by Rust because all variants of this C-style enumeration can be casted safely to an integer. We say it\u0026rsquo;s infallible\nHowever, casting an integer to an enumeration type is not infallible because not all possible integral values have a variant in the enumeration, we can\u0026rsquo;t do the following - it simply does not compile:\n// does not compile as integral to enum conversion is not implemented since it can fail for certain values of integer. let int_as_color = 10 as Blue; Rust is a safe and cautious language and the compiler will just not allow operations that could fail, therefore converting from enum to integral isn\u0026rsquo;t supported by default, however the enum creator can implement the TryFromtrait for any integral types.\nHowever this is boilerplate that\u0026rsquo;s already been done and available in a crate. Therefore to allow for C-style enums in Rust with safe conversions in both directions, it\u0026rsquo;s best to use https://crates.io/crates/num_enum\nTuple Enums In C++, the above is all you get, loosely typed integers that aren\u0026rsquo;t even that safe. With Rust, enums become more powerful with the ability to store different data inside of each variant.\nThese are similar to an algebraic data type such as Haskell has. It could be thought of similar to a union in C++ in that an element of the enum type takes up the amount of space required for the biggest variant (allowing it to store in an array), but strongly typed so you can\u0026rsquo;t access data you shouldn\u0026rsquo;t.\nAs an example, suppose we want to have an \u0026ldquo;Angle\u0026rdquo; enumeration. An angle could be stored in either Degrees or Radians, but both are stored as floats. In this case the tuple enum would look as follows:\nenum Angle { Degrees(f32), Radians(f32) } In both of these variants, we store an f32, but behind the scenes each instance of Angle is tagged with its discriminant (Degrees or Radians) and the only way to access the data inside is through pattern matching. This means we literally can\u0026rsquo;t access data that we shouldn\u0026rsquo;t for the variant we have. An example of implementing the Intotrait for this would be:\nimpl Into\u0026lt;f32\u0026gt; for Angle { fn into(self) -\u0026gt; f32 { match self { Self::Degrees(val) =\u0026gt; val, Self::Radians(val) =\u0026gt; val } } } An example of an enumeration with differing types could be a Color, where we can choose between different color formats:\nenum Color { RGBF32(f32, f32, f32), RGBAF32(f32, f32, f32, f32), RGBU8(u8, u8, u8), RGBAU8(u8, u8, u8, u8) } That is, we can choose between colors with RGB or RGBA components, and can choose the type of the components we\u0026rsquo;re storing. However because this is essentially a strongly typed union, and Rust requires all types to have a defined size to be stored, the largest size would still be picked, in this case each Color would be 16 bytes large (corresponding to the size of RGBAF32 which is largest).\nPattern matching works the exact same way. For example, a method on Color which can return whether the color supports transparency could be written as follows:\nimpl Color { fn supports_transparency(\u0026amp;self) -\u0026gt; bool { match self { Self::RGBF32(..) =\u0026gt; false, Self::RGBAF32(..) =\u0026gt; true, Self::RGBU8(..) =\u0026gt; false, Self::RGBAU8(..) =\u0026gt; true } } } Named Field Enums A variant in an enum can use the tuple syntax for defining the types it contains, and pattern matching as described above, however we can also store values associated with an enum variant by name in a record/struct like syntax. We can freely mix and match these on a per-variant basis. For example an enumeration which represents an Error. We might support storing an ErrorMessage, ErrorCode, or both. This might look as follows:\nenum Error { Message(String), Code(i32), Both { message: String, code: i32 } } When pattern matching on tuple types, we need to use the tuple patterns. When matching on record types, we need to use that syntax. An example of a function to try to get an error code from an Error would be:\nimpl Error { fn try_get_code(\u0026amp;self) -\u0026gt; Option\u0026lt;i32\u0026gt; { match self { Self::Message(..) =\u0026gt; None, Self::Code(c) =\u0026gt; Some(*c), Self::Both{code: c, ..} =\u0026gt; Some(*c) } } } Empty Enums!? Empty enums can\u0026rsquo;t be constructed. This may sound kind of pointless, what does\nenum Void { } Even mean if it can\u0026rsquo;t be constructed?\nAs it turns out this can be very useful for statically proving that we can\u0026rsquo;t ever take a particular branch of code in some cases, and is sometimes seen in generic code.\nFor example, in Rust we have the Result type which has two type parameters. One is the success type, and one is the error type. Say that a trait requires a return type of Result\u0026lt;SuccessType, ErrorType\u0026gt; from a function\ntrait TryOperation { type SuccessType; type ErrorType; fn try_operation(\u0026amp;mut self) -\u0026gt; Result\u0026lt;Self::SuccessType, Self::ErrorType\u0026gt; } In order to implement such a trait, we must provide an ErrorType to satisfy the signature of the trait, but for an infallible operation which is guaranteed to not fail, what do we choose for an ErrorType?. Any type is as good as any other type if we never need to construct it and we never return it:\nstruct InfallibleOperation { } impl TryOperation for InfallibleOperation { type SuccessType = (); // Unit type is like \u0026#34;void\u0026#34; in other languages, it\u0026#39;s a type we can use when we don\u0026#39;t need to return any information.  type ErrorType = ???; // What do we put here if this operation never fails?  fn try_operation(\u0026amp;mut self) -\u0026gt; Result\u0026lt;Self::SuccessType, Self::ErrorType\u0026gt; { println!(\u0026#34;Hello, World!\u0026#34;); } } The implementation of this function simply prints to the console and never fails, we\u0026rsquo;re \u0026ldquo;trying\u0026rdquo; to perform the operation but it will always succeed. It turns out in these cases we can communicate this at the type level to the caller by using the empty enum as the ErrorType (e.g. Void). If the caller sees that the signature for this is:\nfn try_operation(\u0026amp;mut self) -\u0026gt; Result\u0026lt;(), Void\u0026gt; Then they can easily see that the error case can never possibly happen (because an instance of Void physically cannot be constructed). In this case, the caller knows it\u0026rsquo;s safe to not even handle the possibility of error as this is ensured by the compiler in the types.\n","permalink":"https://forgottenmaster.github.io/posts/rust/whyrust/enums/","summary":"C Style Enums In C#, C++, and a lot of other popular programming languages, we have access to a type called an \u0026ldquo;enumeration\u0026rdquo; (or enum for short). This is simply a type safe collection of named constant values.\nFor example in C++, making an enum whose variants represent a set of allowed colors for a hypothetical UI framework could be written as (with the values of the variants explicitly typed out for transparency):","title":"Enums"},{"content":"Maths The derivative of a function is the rate at which the output changes with respect to a change in the input at a specific value for the input. This last part is important as the derivative of a function is essentially the gradient, or tangent of the graph of that function at a specific point which can of course change depending on where you are on the number line.\nThe formula for calculating the derivative of a given function \u0026ldquo;f\u0026rdquo; with respect to it\u0026rsquo;s input parameter \u0026ldquo;x\u0026rdquo;, at a given value of x which we call \u0026ldquo;a\u0026rdquo; here, can be written as:\n$$ \\frac{\\partial f}{\\partial x}(a) = \\lim_{\\Delta \\to 0} \\frac{f(a + \\Delta) - f(a - \\Delta)}{2 \\times \\Delta} $$\nLet\u0026rsquo;s break this down a little.\nWe\u0026rsquo;ll take the left hand side of the formula first, that is \\( \\frac{\\partial f}{\\partial x}(a) \\) which is the partial derivative of f with respect to x, at the given value of a. If we wanted to take another partial derivative of f, for example if the function took multiple parameters, the parameter we\u0026rsquo;re taking the partial derivative with respect to will appear as the denominator. For example, in a function such as:\n$$ f(x, y, z) = x + y + z $$\nThen the partial derivatives could be written as: \\( \\frac{\\partial f}{\\partial x} \\), \\( \\frac{\\partial f}{\\partial y} \\), and \\( \\frac{\\partial f}{\\partial z} \\)\nWhat\u0026rsquo;s a limit?\nThe first symbol in the right hand side is this \\( \\lim_{\\Delta \\to 0} \\) which means \u0026ldquo;as \\(\\Delta\\) approaches 0\u0026rdquo;. Limits are a way of talking about the way the function reacts to bringing certain parameters closer to a given limit. Essentially, the closer the parameter is to the limit, the more accurate the approximation is. In our case we talk about the function being as \\(\\Delta\\) approaches 0, the right hand side becomes more accurately the correct value for the derivative.\nOf course, \\(\\Delta\\) can never be 0, as this would result in a divide by zero operation which is undefined, but we can get arbitrarily close.\nWhat\u0026rsquo;s delta?\nThe symbol \\(\\Delta\\) is the greek symbol \u0026ldquo;Delta\u0026rdquo; which we use here to mean a change. Since to calculate the derivative we\u0026rsquo;re applying a small change to the value, and measuring how the output is affected by this small change.\nHow is the derivative calculated?\nThe rest of the right hand side is simply calculating the actual derivative at the value a, with the given \\(\\Delta\\) value. For a pretty close approximation of the true derivative, we can choose a very small value of delta, for example 0.001. We first add the small value to the value at which we\u0026rsquo;re calculating the derivative, this is the \\( f(a + \\Delta) \\)\nThis gives us the output of the function at a point ever so slightly in front of the test value (a). In order to measure a rate of change, two samples are required. We could have simply applied the function to a itself, however in order to account for asymmetry in the graph, we can get a better test by applying the function to the value located slightly behind the test value, this is \\( f(a - \\Delta) \\).\nFinally we take the difference of these two sample points, that is the difference in their outputs. This gives us the difference in the function output \\( f(a + \\Delta) - f(a - \\Delta) \\).\nIn order to get the gradient, once we have the change in the output of the function, we must divide by the change in the input. Since we both added and subtracted \\( \\Delta \\) to get our sample input points, the range (change in input) is \\( 2 \\times \\Delta \\)\n Code We can code up a function that can calculate the derivative of another function at a given input value, and given the value of the small delta we\u0026rsquo;re applying.\nThe function we write here will take a float in and output a float for simplicity. We could of course use generics to allow this to work for various types. With floats being the data type used, it would look as follows\nfn derivative(f: impl Fn(f64) -\u0026gt; f64, a: f64, delta: f64) -\u0026gt; f64 { let front_result = f(a + delta); let back_result = f(a - delta); let input_change = delta * 2.0; let output_change = front_result - back_result; output_change / input_change } An example call of finding the derivative of a function:\n$$ f(x) = x^2 $$\nat the input value 42 might look as follows:\nlet f = |x| x * x; let a = 42.0; let delta = 0.001; derivative(f, a, delta)  Diagram A derivative of a function being the rate of change of the output with change in the input can be visualised by the following diagram. This diagram shows a function f, which maps \u0026ldquo;x\u0026rdquo; to \u0026ldquo;y\u0026rdquo;, and shows a change in the input (dx) producing a change in the output (dy). The ratio of \\( \\frac{dy}{dx} \\) gives us the derivative\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/derivatives/","summary":"Maths The derivative of a function is the rate at which the output changes with respect to a change in the input at a specific value for the input. This last part is important as the derivative of a function is essentially the gradient, or tangent of the graph of that function at a specific point which can of course change depending on where you are on the number line.","title":"Derivatives"},{"content":"Move By Default In most programming languages, there is no one true \u0026ldquo;owner\u0026rdquo; of any given piece of data. Data can be allocated on the stack or the heap but references to it can be passed around as needed. There isn\u0026rsquo;t a way of the compiler to track ownership of a piece of data in most languages such as C++.\nAdditionally expensive copies of structures may be done without us realising, or being able to opt out of it. For example in C++ and C# the following code will result in making a copy of SomeLargeStruct\nSomeExpensiveStruct s1; SomeExpensiveStruct s2 = s1; // this will make a copy of s1  In Rust, each piece of data has a single owner at any one time. If the owning binding or function goes out of scope, the data is dropped and this gives an opportunity for the type to do any resources allocated. This is similar to a destructor in C++. Due to the single ownership model, Rust moves data by default on assigment, or when passing into and out of functions.\nAn example of the flow of ownership in Rust is the following\nlet v1 = vec![1, 2, 3]; // v1 is a binding that owns a vector with the integers 1, 2, and 3 let v2 = v1; // v1 is *moved* to binding v2. v2 is now the owner of the vector, v1 has relinquished control println!(\u0026#34;{}\u0026#34;, v1); // here we are trying to print out v1, but v1 isn\u0026#39;t the owner of any data and so can\u0026#39;t give out references, etc.  In the above code snippet, the binding v1 transfers ownership of the data to the binding v2, trying to use v1 afterwards results in the following compiler output\nerror[E0382]: use of moved value: `v1` --\u0026gt; src/main.rs:4:10 | 2 | let v1 = vec![1, 2, 3]; | -- move occurs because `v1` has type `Vec\u0026lt;i32\u0026gt;`, which does not implement the `Copy` trait 3 | let v2 = v1; | -- value moved here 4 | dbg!(v1); | ^^ value used here after move  Rust won\u0026rsquo;t let us compile a program which violates the ownership rules like this.\nThe above example is of a move that occurs when assigning from one binding to another, but the same will happen if we passed into a function, for example\nfn foo(v: Vec\u0026lt;i32\u0026gt;) { // v is a vector of integers, ownership is transferred into the function from outside  // the function is the owner of the data, so at the end of the function, the data is dropped } fn main() { let v = vec![1, 2, 3]; foo(v); // ownership is transferred into the function here  dbg!(v); } Will result in a similar compiler error as before:\nerror[E0382]: use of moved value: `v` --\u0026gt; src/main.rs:7:10 | 5 | let v = vec![1, 2, 3]; | - move occurs because `v` has type `Vec\u0026lt;i32\u0026gt;`, which does not implement the `Copy` trait 6 | foo(v); | - value moved here 7 | dbg!(v); | ^ value used here after move  Use After Free In languages such as C++, there are no mechanisms which prevent a use after free error. For example the following code is completely valid\nstruct SomeStruct { public: const char* name; }; SomeStruct\u0026amp; allocAndReturn() { SomeStruct s; s.name = \u0026#34;Hello, World!\u0026#34;; return s; } int main() { SomeStruct\u0026amp; s = allocAndReturn(); std::cout \u0026lt;\u0026lt; s.name \u0026lt;\u0026lt; std::endl; // Boom!, we\u0026#39;ve used an invalid reference  return 0; } As the C++ compiler doesn\u0026rsquo;t track ownership or lifetimes, it doesn\u0026rsquo;t prevent the function from returning a reference to an object that then goes out of scope, then when it tries to access s.name the program segfaults.\nContrast this in Rust, where the compiler tracks lifetimes, it is able to detect a use after free and will fail to compile. If we attempt to return a reference to an object created in a function as in the above program, we won\u0026rsquo;t be able to compile. As it\u0026rsquo;s difficult to do the above function in Rust without delving into lifetime annotations, a smaller program demonstrates the same issue\nfn main() { let v = { let v = vec![4, 5, 6]; \u0026amp;v }; dbg!(v); } As Rust is an expression based language, we can create an arbitrary scope or code block that ends in an expression, and use that to assign to a binding, or anywhere else an expression is accepted.\nIn the code snippet, we are creating a vector v inside the block, and then trying to return a reference to it, out of the block and bind it to the outer v binding.\nHowever Rust detects that we are trying to keep a reference for longer than the object is in scope and gives the following compiler error\nerror[E0597]: `v` does not live long enough --\u0026gt; src/main.rs:4:9 | 2 | let v = { | - borrow later stored here 3 | let v = vec![4, 5, 6]; 4 | \u0026amp;v | ^^ borrowed value does not live long enough 5 | }; | - `v` dropped here while still borrowed  This is the Rust\u0026rsquo;s borrow checker and lifetime rules at work.\nModification While Reading In other languages, it\u0026rsquo;s common for a mutable and immutable reference to exist at the same time. For example in C++ we may do the following:\nSomeStruct s; const SomeStruct \u0026amp;s1 = s; SomeStruct\u0026amp; s2 = s; The implications of this is that someone that is holding an immutable reference to an object will observe changes made to the object (through a mutable reference). This is contrary to what the definition should be of an immutable reference, the holder shouldn\u0026rsquo;t see any changes as it\u0026rsquo;s immutable.\nIf we attempt to do this in Rust, it will fail to compile as we cannot take a mutable and immutable reference at the same time (though we may take as many immutable references as we\u0026rsquo;d like since none will observe any changes).\nfn main() { let mut v = vec![1, 2, 3]; let v1 = \u0026amp;v; let v2 = \u0026amp;mut v; dbg!(v1); } We are greeted with the following compile error\nerror[E0502]: cannot borrow `v` as mutable because it is also borrowed as immutable --\u0026gt; src/main.rs:4:14 | 3 | let v1 = \u0026amp;v; | -- immutable borrow occurs here 4 | let v2 = \u0026amp;mut v; | ^^^^^^ mutable borrow occurs here 5 | dbg!(v1); | -- immutable borrow later used here  Rust guarantees memory safety here by allowing either 0 or more immutable references OR 0 or 1 mutable reference. It is forbidden to have a mutable reference while ANY references are taken, and only 1 mutable reference can be taken at a time.\nThis means if you hold a mutable reference to an object, the compiler guarantees that only you can make changes to the object. It also guarantees that if you hold an immutable reference you will never see any state changes through that.\nThis isn\u0026rsquo;t strictly true\u0026hellip;.there are types in the standard library that allow for interior mutability, that is, mutating through an immutable reference. However, they are also perfectly safe to use because they perform the check at runtime instead. When using those types, you are only allowed to mutate a value if nothing else currently holds a borrow to it.\nIn conclusion, most programming languages have no real protections against multiple sources writing to an object, even when other sources have read-only access. Rust has a policy of only 1 writer at a time, and only when there are no readers in existence.\nThis does require some code restructuring to separate the reading from the writing, but results in much safer code and prevents common problems such as modifying a collection while iterating over it, which is impossible in Rust due to the borrow checker.\nThread Safety The last topic on memory safety in Rust will be a few words on how the safety rules also apply in a multithreaded context.\nMost languages don\u0026rsquo;t have any guarantees about whether an object is safe to be accessed from multiple threads at a time, and if an object is not safe, but is accessed concurrently from 2 threads, this is called a data race, and is not a good thing.\nRust provides a system by which the compiler will fail to compile a program if we try to use a non thread-safe type in a multithreaded context.\nThe way it achieves this is by using two core traits called Send and Sync\nThese are implemented (or not implemented) by types automatically based on the data inside the types. If all the members of a custom type are Send, or Sync then the type itself is Send or Sync.\nSend means that instances of this type can be transferred over to a different thread. This is transfer of ownership across a thread boundary.\nSync means that instances of this type can be accessed from multiple threads at the same time, that is references to the instance are Send.\nThe developer can implement Send and Sync manually on types if those types aren\u0026rsquo;t automatically deemed Send/Sync, however to do so is an unsafe operation as it requires that the developer has checked that the type is indeed thread-safe.\n","permalink":"https://forgottenmaster.github.io/posts/rust/whyrust/memorysafety/","summary":"Move By Default In most programming languages, there is no one true \u0026ldquo;owner\u0026rdquo; of any given piece of data. Data can be allocated on the stack or the heap but references to it can be passed around as needed. There isn\u0026rsquo;t a way of the compiler to track ownership of a piece of data in most languages such as C++.\nAdditionally expensive copies of structures may be done without us realising, or being able to opt out of it.","title":"Memory Safety"},{"content":"The chain rule allows us to determine the derivative of a composite function as a product of the derivatives of each of the individual functions.\nThe reason this is a product is because, say you had a function \u0026ldquo;f\u0026rdquo; which has a derivative of 3 at a particular value of x. That means, when you increase the input by 1, the output increases by 3.\nThen say you have a second function \u0026ldquo;g\u0026rdquo; which has a derivative of 5 at the value output by \u0026ldquo;f\u0026rdquo; for x. This again means that when you increase the input by 1, then the output increases proportionally, this time by 5.\nHowever, the compound function \\( g \\circ f \\) will chain these two together in such a way that increasing the input to f increases the output of f by 3, and because they were chained, this is the same as increasing the input to g by 3.\nSince the gradient of g is 5 meaning that the output change is 5 times the change of the input, then raising the input to that function by 3 must result in a raise of the output by 15.\nSince derivatives are calculated as the gradient at a particular value, we need to know the inputs and outputs of both functions in order to calculate the partial derivatives.\nOnce we have these, we can just multiply them together.\nThe formula for the chain rule in this situation will be:\n$$ (g \\circ f)'(x) = g'(f(x)) \\times f'(x) $$\nThat is, calculating the rate of change (gradient) of the initial function f at the given value of x. After this, calculating the gradient of the second function, g, at the value output by f.\nTherefore in order to calculate these compound derivatives, we need to run two passes.\nThe first pass, called the forward pass, is where we simply are obtaining the input and output values for all functions involved. The second pass, called the backward pass, is where we use the inputs and outputs of the functions in order to calculate their gradients at that point. The final step is then just to multiply together to get the gradient of the composite function.\nThis two-pass sequence can be visualised with the following diagram. In it, we have three functions and an x value that\u0026rsquo;s passed in. we run the x value through the functions in order to get \\( f(x) \\), then \\( g(f(x)) \\), and finally \\( h(g(f(x))) \\).\nThe dashed lines represents the backward pass where we take the calculated values to determine the derivatives of f, g, and h at the appropriate input values.\n We can code up the calculation of the derivative of such a chain of functions as displayed in the diagram. For this section of code, we\u0026rsquo;ll assume the existence of a helper function called \u0026ldquo;derivative\u0026rdquo; which, given a function and a value at which the calculate the derivative, will approximate the derivative using the logic described in the previous post.\n// forward pass, calculating all inputs/outputs let x = 42.0; // initial input let f_of_x = f(x); // output from f (also input to g) let g_of_f_of_x = g(f_of_x); // output from g (also input to h) let h_of_g_of_f_of_x = h(g_of_f_of_x); output from h which is the final output // backward pass, calculating the derivatives of the functions at the calculated inputs let deriv_h = derivative(h, g_of_f_of_x); // calculate the derivative of h at the value that was output from g let deriv_g = derivative(g, f_of_x); // calculate derivative of g at the value that was output from f let deriv_f = derivative(f, x); // calculate derivative of f at the value of x  // multiply together to get the final rate of change of the output with change to x deriv_h * deriv_g * deriv_f ","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/chainrule/","summary":"The chain rule allows us to determine the derivative of a composite function as a product of the derivatives of each of the individual functions.\nThe reason this is a product is because, say you had a function \u0026ldquo;f\u0026rdquo; which has a derivative of 3 at a particular value of x. That means, when you increase the input by 1, the output increases by 3.\nThen say you have a second function \u0026ldquo;g\u0026rdquo; which has a derivative of 5 at the value output by \u0026ldquo;f\u0026rdquo; for x.","title":"Chain Rule"},{"content":"What are traits? Traits in Rust can basically be thought of as interfaces in C#. They can do everything that a C# interface can do except with a few more capabilities. We will start off by equating the common functionality of traits in Rust with C# interfaces, and then explore the additional capabilities we get with Rust traits.\nDescribes capabilities In C# interfaces, we can describe a set of function signatures which will tell the user the capabilities of that interface, such that they know when they call something what data to pass in, and what they should get back. The caller need not know how the function is implemented by a specific type, just that it does what is described on the tin.\nFor example, a C# interface which provides the capability to get an identifier through a GetIdentifier function which takes no arguments, and returns the ID of the instance as an integer can look as follows:\ninterface IGetIdentifier { int GetIdentifier(); } In Rust we can describe the exact same functionality. Note however a few changes in order to follow naming conventions or required by the language syntax:\n interface keyword is renamed to trait In Rust, the naming convention for a trait that has a single method is just the name of the method itself Rust has sized integer types so int is replaced with i32 (can be any of the other integer types too) Rust requires each member function to take explicitly the object we\u0026rsquo;re calling on. This allows us to tell the compiler/caller whether we\u0026rsquo;re taking an immutable reference, mutable reference, or taking ownership. In this case we only need an immutable reference to get an identifier Rust naming convention for functions and variables is snake_case. Therefore GetIdentifier method is renamed get_identifer.  The equivalent Rust definition is therefore:\ntrait GetIdentifier { fn get_identifier(\u0026amp;self) -\u0026gt; i32; } Generics In C# we are also able to make an interface generic. This is useful if we need to implement an interface multiple times for a given type for different situations. We can\u0026rsquo;t implement the same interface multiple times, but each different set of generic parameters is essentially a different interface.\nLet\u0026rsquo;s say we extend the above interface to work for any identifier type and not just integers. The C# snippet would be extended to look as follows:\ninterface IGetIdentifier\u0026lt;T\u0026gt; { T GetIdentifier(); } Likewise, the Rust snippet is extended with the exact same syntax:\ntrait GetIdentifier\u0026lt;T\u0026gt; { fn get_identifier(\u0026amp;self) -\u0026gt; T; } Bounded generics This is the ability to constrain generic parameter types to ones that only implement certain interfaces. In C# we have the ability to constrain based on interface or base class type, however in Rust we don\u0026rsquo;t have struct inheritance but do have trait inheritance. As a result, in Rust we can only constrain on interface. But this is good practice anyways as inheritance of behaviour is better than inheritance of state.\nIn C# if we want to bound the above interface to only allow T\u0026rsquo;s that implement an \u0026ldquo;IIdentifier\u0026rdquo; interface, that is an interface that allows the type to be used as an identifier, would look like this:\ninterface IGetIdentfier\u0026lt;T\u0026gt; where T : IIdentifier { T GetIdentifier(); } In Rust, we have two options for defining trait bounds, we can do it as above with a \u0026ldquo;where\u0026rdquo; syntax. This is useful when there are lots of bounds for a type and we can break them up over multiple lines which is more readable in most cases:\ntrait GetIdentifier\u0026lt;T\u0026gt; where T: Identifier { fn get_identifier(\u0026amp;self) -\u0026gt; T; } However we also have the ability to define these trait bounds inline, which for fewer trait bounds could be neater:\ntrait GetIdentifier\u0026lt;T: Identifier\u0026gt; { fn get_identifier(\u0026amp;self) -\u0026gt; T; } Default implementations Since C#8 we have the ability to provide default implementations for methods, to be used if the implementor doesn\u0026rsquo;t provide their own implementation. This lets us define some required methods that must be implemented, by not defining a default implementation, and provided methods (which can still be overridden, but don\u0026rsquo;t need to be) by giving a default.\nFor example in C#, if we assume that the definition of the \u0026ldquo;IIdentifier\u0026rdquo; interface is as follows:\ninterface Identifier { string GetString(); } Then we can add a provided method to the GetIdentifier interface which will print out the string identifier (note that we still require the GetIdentifier function to be implemented since there\u0026rsquo;s no possible way we can know how to get one). We get the resulting code:\ninterface IGetIdentifier\u0026lt;T\u0026gt; where T: IIdentifier { T GetIdentifier(); void PrintIdentifier() { System.Console.WriteLine($\u0026#34;{GetIdentifier().GetString()}\u0026#34;); } } We can do the same in Rust too in the same way as the following code snippet shows:\ntrait GetIdentifier\u0026lt;T: Identifier\u0026gt; { fn get_identifier(\u0026amp;self) -\u0026gt; T; fn print_identifier(\u0026amp;self) { println!(\u0026#34;{}\u0026#34;, self.get_identifier().get_string()); } } Implementing We can of course implement an interface or trait in both C# and Rust (what use would an interface be if we couldn\u0026rsquo;t!?). However the syntax is different, and this is where we start to see C# and Rust diverge quite dramatically.\nIn C# we have to provide the implementation of the interface at the same point as we define the implementing class/struct itself. For example, implementing the IIdentifier interface for a struct Foo:\nstruct Foo : IIdentifier { public int identifier; public string GetString() =\u0026gt; $\u0026#34;{identifier}\u0026#34;; } And implementing the IGetIdentifiertrait for a second struct FooGetter:\nstruct FooGetter : IGetIdentifier\u0026lt;Foo\u0026gt; { public Foo identifier; public Foo GetIdentifier() =\u0026gt; identifier; } In Rust however, the difference is that we define implementation blocks separate to the variables inside the struct itself. This allows us to break up behaviour/functions from the pure data contained in the structure. Each trait has its own implementation block so the implementation of the above structures and trait implementations will look as follows:\n#[derive(Clone)] struct Foo { pub i32 identifier; } impl Identifier for Foo { pub fn get_string(\u0026amp;self) -\u0026gt; String { format!(\u0026#34;{}\u0026#34;, self.identifier) } } struct FooGetter { pub Foo identifier; } impl GetIdentifier\u0026lt;Foo\u0026gt; for FooGetter { pub fn get_identifier(\u0026amp;self) -\u0026gt; Foo { self.identifier.clone() } } Note the Clone implementation required on Foo, and the clone function call in get_identifier. This is required because in Rust every type is movable, and clones are explicit. Adding the #[derive(Clone)] attribute to the struct allows us to automatically derive a deep clone implementation as long as all the struct fields implement Clone.\nNote that this is not idiomatic Rust, clones are rarely used as we can pass references around safely and the compiler will check the ownership and lifetime rules for us.\nIs that it? So you might look at the previous content and think that Rust traits are just C# interfaces with a different syntax. They can do everything C# interfaces can do right?. Well, yes, except that there are more capabilities that Rust gives us that just aren\u0026rsquo;t possible in C#\nThe following few sections then will only contain Rust snippets as there\u0026rsquo;s no valid way to represent them in C# (or C++, or most languages I\u0026rsquo;ve used - except Haskell, which makes traits similar to typeclasses).\nAssociated Types In the above code snippets, we had a generic trait GetIdentifier which was implemented on FooGetter with the generic parameter Foo. However this opens the way for us to have multiple implementations on FooGetter with different types. However what if we want to force the user to define a maximum of 1 implementation of GetIdentifier?\nWell, we have to remove the generics, and we end up with a trait as follows:\ntrait GetIdentifier { fn get_identifier(\u0026amp;self) -\u0026gt; ??? // what type goes here? } However, we have a problem here since we don\u0026rsquo;t know what the actual identifier type is now for any given implementation. We\u0026rsquo;ve removed the ability to specify it in a generic parameter, so in C# the only way to do this would be to fix the concrete type we return. That means all implementors of GetIdentifier returns the same type.\nTechnically in C# we can do it by returning the IIdenfier interface itself:\ninterface IGetIdentifier { IIdentifier GetIdentifier(); } Which indeed will allow each implementor to determine what the actual type they\u0026rsquo;re returning is, as long as it implements the IIdenfier interface.\nThe downside here is that we are forced to box the result which means a heap allocation, which means garbage collector tracking overhead.\nWe can do the same thing in Rust, we have to be explicit about returning a dynamic trait object in a box though:\ntrait GetIdentifier { fn get_identifier(\u0026amp;self) -\u0026gt; Box\u0026lt;dyn Identifier\u0026gt;; } However this still requires allocating heap storage and returning. An additional downside is type erasure. We\u0026rsquo;ve lost all information about the actual concrete type, all we know is the Box has an Identifier in it, so can only access the methods of the Identifier trait and nothing more.\nThere must be a better way!?. Enter associated types:\ntrait GetIdentifier { type IdentifierType: Identifier; fn get_identifier(\u0026amp;self) -\u0026gt; Self::IdentifierType; fn print_identifier(\u0026amp;self) { println!(\u0026#34;{}\u0026#34;, self.get_identifier().get_string()); } } Problems solved!. There\u0026rsquo;s a bit of new syntax here, but the main points are:\n We define an associated type on the trait with the type T syntax, allowing each implementor to specify a different concrete type We place a trait bound on it so that only concrete types implementing the Identifier trait can be used We return Self::IdentifierType from the get_identifier function. Importantly this is the concrete type, meaning no heap allocations and no type erasure  One further thing with associated types is that we can add trait bounds that force them to a specific concrete type. For example, say that we want to create a function that will take any GetIdentifier and print it, but only if the identifier type is an i32. We can do this as a trait bound with the following syntax:\nfn call_print_identifier_if_i32\u0026lt;T: GetIdentifier\u0026lt;IdentifierType = i32\u0026gt;\u0026gt;(t: \u0026amp;T) { t.print_identifier(); } We can also even place trait bounds on associated types within trait bounds!. For example if we want a function that will accept any GetIdentifier, but only if the IdentifierType implements Clone, we can do so:\nfn do_something\u0026lt;T\u0026gt;(t: \u0026amp;T) where T: GetIdentifier, \u0026lt;T as GetIdentifier\u0026gt;::IdentifierType: Clone { let c = t.get_identifier().clone(); // do something with cloned instance } Associated methods Unlike C# (and most other languages) interfaces which can only define methods tied to the specific instance of the implementing type, due to requiring dynamic dispatch and using a vtable, in Rust we can also define methods at the type level. These would be called static methods in other languages but in Rust, they are known as associated methods.\nA simple example of a trait making use of this functionality is the Default trait in the standard library. If we were to define it ourselves, we can do it like this:\ntrait Default { fn default() -\u0026gt; Self; } Self here is the implementing type, and notice how an associated method is indicated not by a keyword, but by the lack of self, \u0026amp;self, or \u0026amp;mut self in the first argument position.\nThese associated methods can be called with :: syntax, for example if our type Foo implements Default, we can call it as:\nlet default_foo = Foo::default(); Extension traits The next feature Rust provides us with respect to traits is as a side effect of having to implement them separate to the type we\u0026rsquo;re implementing on. This implies we can implement traits for types that we don\u0026rsquo;t actually own. This isn\u0026rsquo;t possible in C# or C++ where the implementation of a type is defined at the same time as the type itself.\nThis means that we are able to add functionality to existing types, even standard library types or primitive types by creating a trait and implementing it.\nFor example, say that we want to add a AsBytes trait which specifies that the type has a method called as_bytes which returns a vector of u8\u0026rsquo;s representing the bytes of the type.\nSuch a trait can be defined like:\ntrait AsBytes { fn as_bytes(\u0026amp;self) -\u0026gt; Vec\u0026lt;u8\u0026gt;; } And we can implement that for our own types, however, unlike in most other languages, we can implement this for existing types even primitives. For example on a u32:\nimpl AsBytes for u32 { fn as_bytes(\u0026amp;self) -\u0026gt; Vec\u0026lt;u8\u0026gt; { self.to_le_bytes().to_vec() } } to_le_bytes is a function that the standard library provides for us, that will give us an array of u8\u0026rsquo;s of length 4 with the bytes of the u32 in it. We can call to_vec on this to turn it into a dynamically sized vector instead to return.\nBlanket implementations The final feature for traits that we have with Rust is the ability to implement a trait for all types, optionally bounded with trait bounds.\nLet\u0026rsquo;s say we want to add a method to all iterators which will result in a new iterator that prints out the item (for all items that are displayable) as it iterates them.\nNote that we can do this with a map call to decorate a function, taking the input, printing it and returning it again to make a new iterator. This would look something like this:\nlet iter = (0..10).map(|elem| { println!(\u0026#34;{}\u0026#34;, elem); elem }); However this requires the user to roll the function themselves to print and return, and is a bit unwieldy. What we\u0026rsquo;d like is:\nlet iter = (0..).print(); We can do this with a blanket implementation that adds this print function to all iterators. First we need a structure to wrap the iterator that will step through and do the printing:\nstruct Print\u0026lt;T\u0026gt; { iterator: T } We will need to implement the Iterator trait here for the new structure, so that we can step over and print the elements. However we can only do this if the elements implement the Display trait. We can use trait bounds to ensure that:\n T is an Iterator The elements from T implement Display  This will look as follows:\nimpl\u0026lt;T: Iterator\u0026gt; Iterator for Print\u0026lt;T\u0026gt; where \u0026lt;T as Iterator\u0026gt;::Item: Display { type Item = \u0026lt;T as Iterator\u0026gt;::Item; // just passing the items through  fn next(\u0026amp;mut self) -\u0026gt; Option\u0026lt;Self::Item\u0026gt; { let item = self.iterator.next()?; println!(\u0026#34;{}\u0026#34;, item); Some(item) } } The little ? syntax when we call the next function of the iterator we\u0026rsquo;re wrapping is a little outside of the scope of the article, but the easiest way to think of it is if that call returns None, then we return None immediately. Otherwise item is set to the value inside the Some (which we then print and return).\nFinally we need to actually add the convenience function to all iterators. We can do this by creating an extension trait called IteratorPrint with the print function we want:\ntrait IteratorPrint where Self: Sized { fn print(self) -\u0026gt; Print\u0026lt;Self\u0026gt; { Print { iterator: self } } } We need to specify Self: Sized because traits in Rust can be implemented even for dynamically sized types which can\u0026rsquo;t exist on their own and must be boxed or put behind a reference.\nSince we need to put self into the Print structure, it will need to have a compile time known size, so we specify we can only use it with such types.\nNow we have all the boilerplate setup, we can actually do the blanket implementation. We\u0026rsquo;ll add it only to compatible iterators, otherwise we end up with a more cryptic compile error. The actual final code for this is as follows:\nimpl\u0026lt;T: Iterator\u0026gt; IteratorPrint for T where \u0026lt;T as Iterator\u0026gt;::Item: Display { } Then we can take any iterator that has elements that are displayable, and use this print function on it, even if we didn\u0026rsquo;t write the iterator type ourselves!. For example the following is valid:\n(0..10).print().for_each(|_| {}); The for_each call will just apply the closure to each element, in our case we just want to do nothing, but it will trigger the prints as it iterates.\n","permalink":"https://forgottenmaster.github.io/posts/rust/whyrust/traits/","summary":"What are traits? Traits in Rust can basically be thought of as interfaces in C#. They can do everything that a C# interface can do except with a few more capabilities. We will start off by equating the common functionality of traits in Rust with C# interfaces, and then explore the additional capabilities we get with Rust traits.\nDescribes capabilities In C# interfaces, we can describe a set of function signatures which will tell the user the capabilities of that interface, such that they know when they call something what data to pass in, and what they should get back.","title":"Traits"},{"content":"So far, we\u0026rsquo;ve learned how to chain functions together, and how to calculate the derivative of a function at a specific input value. We\u0026rsquo;ve also learned how to apply the chain rule when we are chaining multiple functions together. However, how do we calculate the derivative of a function, or chain of functions when a function has multiple inputs?.\nAs it turns out, we can calculate the derivative in the same way!, we just need to, in the case where there are multiple inputs, calculate the partial derivative with respect to the given parameter.\nLets start off with a single function, one that takes two inputs and returns a single output\nIn such a function, the change in the output can be affected by a change in either input (x or y). Because of this, calculating the derivative with respect to x at a given value might result in a different value to what is given when calculating the derivative for input y. These are the partial derivatives of the function, where each partial derivative is how the output changes with a given change of the input (while keeping the other inputs constant).\nThe formulas for these partial derivatives can be given as:\n$$ \\frac {\\partial f} {\\partial x} = \\lim_{\\Delta \\to 0} \\frac {f(x + \\Delta, y) - f(x - \\Delta, y)} {2 \\times \\Delta} $$ $$ \\frac {\\partial f} {\\partial y} = \\lim_{\\Delta \\to 0} \\frac {f(x, y + \\Delta) - f(x, y - \\Delta)} {2 \\times \\Delta} $$\nApplying the chain rule We can apply the chain rule in the same way when calculating the partial derivative of a composite function with respect to one of the inputs. Since the change in input causes a change in the input to the next function, which then causes a change in the input to the next, and so on, we will still do a backward pass the same way as we would with a single input. We just follow it back to the point where the input is given. For example with the following\nWe can see that the first function has two inputs whereas g and h have only 1 input. So there will be two partial derivatives for this composite function. These can be given as follows (applying the chain rule):\n$$ (f \\circ g \\circ h)_x = f_x(x, y) \\times g'(f(x, y)) \\times h'(g(f(x, y))) $$ $$ (f \\circ g \\circ h)_y = f_y(x, y) \\times g'(f(x, y)) \\times h'(g(f(x, y))) $$\nNote that here we are using Legrange\u0026rsquo;s Notation as it can be cleaner than the Leibniz notation. In this notation we can use \\(f'(x)\\) to denote the derivative of function f taking a single input, at value x.\nWith multiple inputs, the input we\u0026rsquo;re describing the partial derivative of can be given as a subscript. e.g. \\(f_x(x, y)\\) would be saying we are interested in how much a change in x will cause a change in the output of the function, at the point defined by the given values of x and y.\nOverall the chain rule works the same way as a single input, except we are defining the input we\u0026rsquo;re interested in when back propagating to work out the derivative.\nLet\u0026rsquo;s assume the following functions to calculate the derivative of a given 2 input function with respect to each of the inputs:\nfn derivative_x(f: impl Fn(f64, f64) -\u0026gt; f64, x: f64, y: f64, delta: f64) -\u0026gt; f64 { (f(x + delta, y) - f(x - delta, y)) / (2.0 * delta) } fn derivative_y(f: impl Fn(f64, f64) -\u0026gt; f64, x: f64, y: f64, delta: f64) -\u0026gt; f64 { (f(x, y + delta) - f(x, y - delta)) / (2.0 * delta) } Along with the existence of the previous function, \u0026ldquo;derivative\u0026rdquo; which performs the same calculation but on a single input function. We can then calculate the derivatives of the composite function as shown above with the following functions:\nfn derivative_x_chain(f: impl Fn(f64, f64) -\u0026gt; f64, g: impl Fn(f64) -\u0026gt; f64, h: impl Fn(f64) -\u0026gt; f64, x: f64, y: f64, delta: f64) -\u0026gt; f64 { // forward pass to calculate inputs  let f_of_xy = f(x, y); let g_of_f_of_xy = g(f_of_xy); // backward pass to calculate partial derivatives  let derivative_f = derivative_x(f, x, y, delta); let derivative_g = derivative(g, f_of_xy, delta); let derivative_h = derivative(h, g_of_f_of_xy, delta); // total derivative with respect to x of compound function  derivative_f * derivative_g * derivative_h } fn derivative_y_chain(f: impl Fn(f64, f64) -\u0026gt; f64, g: impl Fn(f64) -\u0026gt; f64, h: impl Fn(f64) -\u0026gt; f64, x: f64, y: f64, delta: f64) -\u0026gt; f64 { // forward pass to calculate inputs  let f_of_xy = f(x, y); let g_of_f_of_xy = g(f_of_xy); // backward pass to calculate partial derivatives  let derivative_f = derivative_y(f, x, y, delta); let derivative_g = derivative(g, f_of_xy, delta); let derivative_h = derivative(h, g_of_f_of_xy, delta); // total derivative with respect to x of compound function  derivative_f * derivative_g * derivative_h } For a runnable example of comparing calculating the derivative of a composite function both directly and via the chain rule, I have written a simple example on the Rust Playground which shows that the derivative calculated for a composite function directly results in the same value as a derivative calculated using the chain rule (both single and multiple input functions are tested).\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/multipleinputs/","summary":"So far, we\u0026rsquo;ve learned how to chain functions together, and how to calculate the derivative of a function at a specific input value. We\u0026rsquo;ve also learned how to apply the chain rule when we are chaining multiple functions together. However, how do we calculate the derivative of a function, or chain of functions when a function has multiple inputs?.\nAs it turns out, we can calculate the derivative in the same way!","title":"Multiple Inputs"},{"content":"After learning what a derivative of a function is, and how to apply the chain rule to a composite function, we then learned how to calculate the derivative of a function with multiple inputs by tracing back through the chain of functions following the route of one of the parameters while holding the others constant.\nThe next step in the prerequisite mathematics we need to build the foundations of a neural network is to determine what the derivative of a function means when one or more of the inputs is a vector.\nGiven the following block diagram for a chain of functions\nThat is, a function, f which takes two inputs both of which are vectors (denoted by the bar above the name), and a function, g which operates on the resulting value.\nFurthermore, let\u0026rsquo;s say that f is actually the dot product function. This function is written as follows, if we assume that X and W are both vectors of length 3:\n$$ f(X, W) = X \\cdot W = X_1 \\times W_1 + X_2 \\times W_2 + X_3 \\times W_3 $$\nAs a reminder, the derivative of a function is the ratio of the change in the output given a change in the input, at a specific input value (point on the graph of the function). This is easy to determine when the inputs and outputs are plain values as it\u0026rsquo;s just a ratio of the two deltas.\nWhen an input is a vector though, what does a change in the input mean?. In fact, this is easily interpreted as a change in one of the components of the input.\nAs seen in the dot product formula (though the function can be any function on vectors), a vector can be decomposed into a list of individual numbers/components. Therefore we can calculate the derivative of the function with respect to an individual component by holding the others to be constant and varying the one we\u0026rsquo;re interested in.\nAfter applying this first function though, the second is operating on a single value and so the chain rule applies as before. In the case of the dot product, this gives us 6 partial derivatives: 3 with respect to the 3 components in the input vector X and 3 with respect to the components of W.\nThe formulas for calculating the derivatives then for the composite function will be as follows in accordance with the chain rule (where n is a valid index for the input vector):\n$$ (g \\circ f)_{X_n} = f_{X_n}(X, W) \\times g'(f(X, W)) $$ $$ (g \\circ f)_{W_n} = f_{W_n}(X, W) \\times g'(f(X, W)) $$\nLooking back at the formula for calculating the dot product we can see that holding all values constant except for a single component we are interested in causes a change in the output proportional to the matching component of the other vector. For example if we let \\(X_1\\) increase by 1 while holding all other components constant, we can see that the only part of the formula containing \\(X_1\\) is\n$$ X_1 \\times W_1 $$\nIncreasing \\(X_1\\) by 1 then increases the output only by \\(W_1\\)\nWhen we calculate the derivative for the other components then, we find out that elementwise, the derivatives of the dot product with respect to X can be represented by:\n$$ \\begin{bmatrix} W_1 \u0026amp; W_2 \u0026amp; W_3 \\end{bmatrix} $$\nand by the same token, the component wise derivatives of the dot product with respect to W is:\n$$ \\begin{bmatrix} X_1 \u0026amp; X_2 \u0026amp; X_3 \\end{bmatrix} $$\nWhen we write the dot product as row and column vectors in order to have the correct shapes for performing the dot product:\n$$ \\begin{bmatrix} X_1 \u0026amp; X_2 \u0026amp; X_3 \\end{bmatrix} \\cdot \\begin{bmatrix} W_1 \\\\ W_2 \\\\ W_3 \\end{bmatrix} $$\nWe can see that the component wise derivative with respect to X will be \\( \\begin{bmatrix} W_1 \u0026amp; W_2 \u0026amp; W_3 \\end{bmatrix} \\), that is \\(W^T\\) and the component wise derivative with respect to W will be \\( \\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\end{bmatrix} \\), that is \\(X^T\\)\nConclusion In conclusion, calculating the derivative of a function with vector inputs is just calculating the derivative of the function with respect to each component in the vector. Additionally, and most importantly for deep learning, the derivative of the dot product of a row vector X with a column vector W turns out to be \\(W^T\\) and \\(X^T\\) respectively.\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/vectorinputs/","summary":"After learning what a derivative of a function is, and how to apply the chain rule to a composite function, we then learned how to calculate the derivative of a function with multiple inputs by tracing back through the chain of functions following the route of one of the parameters while holding the others constant.\nThe next step in the prerequisite mathematics we need to build the foundations of a neural network is to determine what the derivative of a function means when one or more of the inputs is a vector.","title":"Vector Inputs"},{"content":"The final piece of the puzzle in the mathematical foundations needed is to determine how we can trace back a derivative with respect to matrix inputs.\nIn the previous post we saw that calculating the derivative of two vectors of equal length when passing through the dot product operation results in the transpose of the other.\nMatrix Multiplication Refresher The first step is to recall how we can multiply two matrices together. In deep learning typically this will be performed with a matrix of samples, and a matrix of weights to be applied. The result being a weighted sum of the samples with weights.\nIn order for the product of two matrices to be defined, the number of columns in the first matrix must equal the number of rows in the second. The resulting matrix will be of the outer dimensions.\nThat is, given a matrix X, of dimensions m x n and a matrix W, of dimensions n x p then the multiplication is defined, and the resulting matrix is of dimensions m x p.\nIn the resulting matrix, an element at row i and column j is the result of the dot product of the ith row of the first matrix, and the jth row of the second matrix.\nAs a concrete example, suppose we have\n$$ X = \\begin{bmatrix} X_{11} \u0026amp; X_{12} \u0026amp; X_{13} \\\\ X_{21} \u0026amp; X_{22} \u0026amp; X_{23} \\\\ X_{31} \u0026amp; X_{32} \u0026amp; X_{33} \\end{bmatrix} $$ $$ W = \\begin{bmatrix} W_{11} \u0026amp; W_{12} \\\\ W_{21} \u0026amp; W_{22} \\\\ W_{31} \u0026amp; W_{32} \\end{bmatrix} $$\nThen the resulting matrix can be represented as\n$$ X \\cdot W = \\begin{bmatrix} XW_{11} \u0026amp; XW_{12} \\\\ XW_{21} \u0026amp; XW_{22} \\\\ XW_{31} \u0026amp; XW_{32} \\end{bmatrix} $$\nWhere \\(XW_{ij}\\) is the dot product of the ith row of X and the jth row of W\nDerivative Of Matrices In order for us to be able to calculate the rate of change in the output of a function with respect to the elements of one of the input matrices we will need to have the output be either:\n A matrix of the same size as an input matrix - derivative can be calculated elementwise in that case between input and output matrices A scalar value - derivative can be calculated elementwise for each element in the input matrix to determine how this affects the single output  For deep learning, we want to be able to first multiply a matrix of samples (X) by a matrix of weights (W) in order to get the weighted sum of the records in a resulting matrix, then we would like to pass the resulting matrix to a function that produces a single value that could be used to activate a neuron for example.\nTherefore what we have is a function F which can be defined as\n$$ F = F(Y) $$\nThat is it takes some matrix Y and performs an operation on it (in our case likely summing the elements). The matrix Y will be produced by multiplying the two input matrices, that is:\n$$ Y = X \\cdot W $$\nIn order to calculate the total derivative with respect to the input matrices, we can apply the chain rule. The first step of which is easy, that is to take Y and calculate how a change in each element would affect the resulting single value. The derivative of F therefore is a matrix representing these partial derivatives. We will call this G, that is \\(G = F'(Y)\\)\nThe derivative of Y depends on two variables X and W which are multiplied together. The formula for the total derivative therefore is\n$$ dY = dX \\cdot W + X \\cdot dW $$\nThat is, changes in the elements of X would end up being multiplied by W, and also changes in the elements of W would end up being multiplied by X.\nThen, the derivative of the total function can be given (using the chain rule) as:\n$$ dF = G:dY $$\nAnd expanding out dY with the above formula gives\n$$ dF = G:dX \\cdot W + G:X \\cdot dW $$\nFor notation, X:Y means the elementwise multiplication of matrices X and Y, that must be the same dimensions (also known as frobenius inner product).\nIsolating dX and dY In the above formula, we have G being multiplied elementwise by a matrix that is the result of matrix multiplication between dX and W or X and dW.\nWhat we want to do is to isolate dX and dY so that they are multiplied elementwise with the other matrix. How can we get W and X onto the other side?\nWell,\n$$ G : (dX \\cdot W) = (G \\cdot W^T) : dX $$\nAnd\n$$ G : (X \\cdot dW) = (X^T \\cdot G) : dW $$\nThat is, the total derivative can be calculated as\n$$ dF = (G \\cdot W^T) : dX + (X^T \\cdot G) : dW $$\nPartial Derivatives Now from the above formula, we can easily calculate the partial derivatives of F by holding either X or W as constant, meaning dX or dW respectively is 0.\nDoing this will eliminate the term from the formula leaving only the other one. This shows us how the partial derivatives are\n$$ \\frac{\\partial F}{\\partial X} = G \\cdot W^T $$ $$ \\frac{\\partial F}{\\partial W} = X^T \\cdot W $$\nAdditional Notes The book at this point actually didn\u0026rsquo;t explain how we get to using the transpose matrices for derivatives, instead the book says in a handwavey fashion that \u0026ldquo;the way the mathematics works out\u0026rdquo;.\nI found the above explanation at This Page and above tried to break it down as best I could.\nI will likely need to revisit matrix multiplication in the future but for now understand it enough to move on to learning more about the structure of a neural network and applying these rules in practice.\n","permalink":"https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter1/matrixinputs/","summary":"The final piece of the puzzle in the mathematical foundations needed is to determine how we can trace back a derivative with respect to matrix inputs.\nIn the previous post we saw that calculating the derivative of two vectors of equal length when passing through the dot product operation results in the transpose of the other.\nMatrix Multiplication Refresher The first step is to recall how we can multiply two matrices together.","title":"Matrix Inputs"},{"content":" Ubisoft Reflections\nSenior Gameplay Programmer\nApril 2020 - Present\nAs a senior gameplay programmer I have been responsible for architecting and implementing large systems in Assassin\u0026rsquo;s Creed VR. Where the product statement isn\u0026rsquo;t clear or is incomplete, I have worked with other disciplines to ensure the final design does what is required. During this time I have gained experience in Unity3D including DOTS and best practices for efficient programs. Additionally, I attempt to always share my knowledge as I develop it myself so as to allow others to also build their skills.\nUbisoft Reflections\nGameplay Programmer\nMarch 2018 - April 2020\nAs a gameplay programmer I have helped design and implement some fairly large systems for \u0026ldquo;Tom Clancy\u0026rsquo;s The Division 2\u0026rdquo; with the main feature being clans. As part of the clans feature I worked with designers, as well as the online team in order to develop clan missions and rewards, and clan spaces.\nUbisoft Reflections\nJunior Gameplay Programmer\nNovember 2014 - March 2018\nIn this position I worked on \u0026ldquo;Tom Clancy\u0026rsquo;s The Division\u0026rdquo; as well as the associated expansion packs and DLC. I gained industry experience using C++ in a large codebase, and also with the in-house engine used to develop these (Snowdrop). I gained experience in using visual scripting and node graph systems.\n Eutechnyx Ltd.\nProgrammer\nJuly 2010 - November 2014\nWhile working at Eutechnyx I was part of the team developing \u0026ldquo;Auto Club Revolution\u0026rdquo;, a social network and gaming site revolving around car enthusiasts. I gained experience with front and back end web technologies using HTML/CSS/JavaScript for the frontend, and Python for the backend. Additional technologies used were MongoDB for the database management software, along with Redis for caching. Being a dynamic website, I gained experience interfacing with popular APIs including Facebook, and payment providers.\n Newcastle University\nMSc, Computer Games Engineering\n2008-2009\nDissertation titled \u0026ldquo;Games with a purpose\u0026rdquo;\nGraduated with merit\nNewcastle University\nBSc, Computing Science\n2005-2008\nDissertation titled \u0026ldquo;Video records of everyday life\u0026rdquo;\nGraduated with first class degree\n","permalink":"https://forgottenmaster.github.io/resume/","summary":"Ubisoft Reflections\nSenior Gameplay Programmer\nApril 2020 - Present\nAs a senior gameplay programmer I have been responsible for architecting and implementing large systems in Assassin\u0026rsquo;s Creed VR. Where the product statement isn\u0026rsquo;t clear or is incomplete, I have worked with other disciplines to ensure the final design does what is required. During this time I have gained experience in Unity3D including DOTS and best practices for efficient programs. Additionally, I attempt to always share my knowledge as I develop it myself so as to allow others to also build their skills.","title":"Résumé"}]