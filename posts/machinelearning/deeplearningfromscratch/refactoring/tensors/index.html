<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Part 2 - Tensors | Robin Firth</title>
<meta name="keywords" content="" />
<meta name="description" content="A &ldquo;tensor&rdquo; is just a fancy name for &ldquo;n-dimensional array&rdquo; (AKA ndarray) and provides a way of thinking about scalars, vectors, matrices, etc. in a uniform way. We refactor Eidetic to use this concept because we want operations to be able to specify how many dimensions are in the input and output data. This post will provide a brief overview of what a tensor is, and how we implement it in Eidetic.">
<meta name="author" content="">
<link rel="canonical" href="https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/refactoring/tensors/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.6f60056d44d3f7eb69a4bc6c332b59960f3a995802bded244750232f33713c49.css" integrity="sha256-b2AFbUTT9&#43;tppLxsMytZlg86mVgCve0kR1AjLzNxPEk=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://forgottenmaster.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://forgottenmaster.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://forgottenmaster.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://forgottenmaster.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://forgottenmaster.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.92.2" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:title" content="Part 2 - Tensors" />
<meta property="og:description" content="A &ldquo;tensor&rdquo; is just a fancy name for &ldquo;n-dimensional array&rdquo; (AKA ndarray) and provides a way of thinking about scalars, vectors, matrices, etc. in a uniform way. We refactor Eidetic to use this concept because we want operations to be able to specify how many dimensions are in the input and output data. This post will provide a brief overview of what a tensor is, and how we implement it in Eidetic." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/refactoring/tensors/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-24T12:48:11&#43;01:00" />
<meta property="article:modified_time" content="2022-07-24T12:48:11&#43;01:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Part 2 - Tensors"/>
<meta name="twitter:description" content="A &ldquo;tensor&rdquo; is just a fancy name for &ldquo;n-dimensional array&rdquo; (AKA ndarray) and provides a way of thinking about scalars, vectors, matrices, etc. in a uniform way. We refactor Eidetic to use this concept because we want operations to be able to specify how many dimensions are in the input and output data. This post will provide a brief overview of what a tensor is, and how we implement it in Eidetic."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://forgottenmaster.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Machine Learning",
      "item": "https://forgottenmaster.github.io/posts/machinelearning/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Deep Learning From Scratch",
      "item": "https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "Refactoring Eidetic",
      "item": "https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/refactoring/"
    }, 
    {
      "@type": "ListItem",
      "position":  5 ,
      "name": "Part 2 - Tensors",
      "item": "https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/refactoring/tensors/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Part 2 - Tensors",
  "name": "Part 2 - Tensors",
  "description": "A \u0026ldquo;tensor\u0026rdquo; is just a fancy name for \u0026ldquo;n-dimensional array\u0026rdquo; (AKA ndarray) and provides a way of thinking about scalars, vectors, matrices, etc. in a uniform way. We refactor Eidetic to use this concept because we want operations to be able to specify how many dimensions are in the input and output data. This post will provide a brief overview of what a tensor is, and how we implement it in Eidetic.",
  "keywords": [
    
  ],
  "articleBody": "A “tensor” is just a fancy name for “n-dimensional array” (AKA ndarray) and provides a way of thinking about scalars, vectors, matrices, etc. in a uniform way. We refactor Eidetic to use this concept because we want operations to be able to specify how many dimensions are in the input and output data. This post will provide a brief overview of what a tensor is, and how we implement it in Eidetic.\nWhat is a tensor? As mentioned in the introduction blurb, a tensor is just simply an array with N dimensions. In tensor terminology the N here is known as it’s rank. For ease of understanding, there’s a few ranks of tensor below with common terminology for that particular data type.\n Rank 0 = “Scalar”. A rank 0 tensor has no dimensions and is a single point. In terms of elements this means it only has a single element contained within which is known as a scalar in mathematics. Rank 1 = “Vector”. A rank 1 tensor has only a single dimension which represents its length. All elements are on this 1 dimension and the overal data structure is commonly referred to as a vector (list of things). Rank 2 = “Matrix”. A rank 2 tensor has two dimensions which represent the width and height (alternatively rows and columns). Such a tensor is commonly referred to as a matrix.  Higher ranked tensors exist but don’t have common names for them and are harder to think about or draw in a diagram. A rank 3 tensor can be thought of as a “cube” or a “stack” of matrices stacked on top of one another and is commonly used to represent the layers in an image for example.\nAfter this they start to become more abstract - a rank 4 tensor can be thought of as a “vector of cubes” perhaps.\nWhy we need a tensor? We need a tensor type in the API because we want to constrain operations and layers to using the same type but allow them to be generic over the rank of the tensor. Using a common type allows us to avoid having to have separate types for scalars, vectors, matrices, etc.\nThe Tensor type Now we have a brief explanation of what tensors are, we can look at how they’re implemented inside Eidetic. The following are points that we’re trying to satisfy with our implementation:\n Tensors must be generic over a rank indicating its dimensionality. Tensors must hide all implementation details of how they’re stored internally. Tensors should be constructible through a new function which may or may not be fallible. The data inside a Tensor should be iterable.  The type that we settled upon for a Tensor is as follows:\npub struct TensorR: Rank(pub(crate) ArrayElementType, R::Internal); This is generic over a parameter type R which MUST implement the Rank trait. This is because we need to access the Internal associated type which allows us to define the ndarray::Array type we’re using to store the data internally.\nThis internal state is hidden from the public API by the pub(crate) visibility modifier which means that the public API has no reference at all to the ndarray crate or the Array type. We would easily be able to swap out the implementation for something else as long as the public API continues to use the Tensor type.\npub(crate) gives the crate the ability to work with the ndarray::Array type stored inside however which allows us to internally use all the methods provided by the ndarray crate for calculations while leaving it an implementation detail.\nConstructing a tensor type In order to construct the tensor type in Eidetic we need to provide a “new” function for each rank of tensor we’re constructing. This is due to the parameters and return type being different depending on the rank of the tensor we’re constructing (since some ranks are infallible).\nFor rank 0 tensors (scalars) they will take as input a single element, and return a Tensor - this is infallible because we can always create a tensor with a single element from a single element. The code for this look as such:\nimpl Tensorrank::Zero { pub fn new(elem: ElementType) - Self { Self(arr0(elem)) } } For rank 1 tensors (vectors) they will take some type that we can get an iterator of elements from, and will put all those elements into a single dimension in the tensor (it’s length). This is infallible because we are simply taking the number of elements in the iterable as the length of the tensor:\nimpl Tensorrank::One { pub fn new(iter: impl IntoIteratorItem = ElementType) - Self { Self(Array::from_iter(iter)) } } Rank 2 and higher tensors are not infallible because this is where we have to take a flat iterator of elements, and reshape it to fit a desired shape. If there aren’t enough elements inside the iterator for the requested shape then this will be an error.\nI’ll only show one implementation here, but they will all follow the same format:\n Take the iterator provided and make a 1-dimensional array from it Reshape the array into an n-dimensional one using the provided/requested shape If this is an error from ndarray (invalid number of elements) then map the error type to our own Eidetic error type  The code for example for a rank 2 tensor looks like this:\nimpl Tensorrank::Two { pub fn new(shape: (usize, usize), iter: impl IntoIteratorItem = ElementType) - ResultSelf { let array: ArrayElementType, Ix1 = Array::from_iter(iter); let array: ArrayElementType, Ix2 = array.into_shape(shape).map_err(|_| Error(()))?; Ok(Self(array)) } } Note that we’re using the eidetic::Result type alias here since all results output by Eidetic will use the error type of eidetic::Error.\nReading from a tensor type Now that we have the ability to construct a tensor from an iterator, we need the ability to go the other way and iterate the values in a tensor which will allow us to interpret the output data from Eidetic as required.\nIn order to do this we will need to implement the IntoIterator trait provided by Rust, which will iterate over elements of the type eidetic::ElementType (f64 by default, f32 if Cargo feature is enabled). The definition of this trait looks like follows:\nimplR: Rank IntoIterator for TensorR { type Item = ElementType; type IntoIter = TensorIteratorR; fn into_iter(self) - Self::IntoIter { TensorIterator(self.0.into_iter()) } } The iterator type is a new type TensorIterator which simply wraps our ndarray::Array type’s iterator and delegates the next method. Taking the struct definition and the Iterator trait implementation together we get:\npub struct TensorIteratorR: Rank(ArrayElementType, R::Internal as IntoIterator::IntoIter); implR: Rank Iterator for TensorIteratorR { type Item = ElementType; fn next(\u0026mut self) - OptionSelf::Item { self.0.next() } } Again, the wrapped iterator from ndarray is kept private so it doesn’t leak into the public API.\nThe Rank type The other part of the Tensor type is the Rank types which are required for 2 reasons:\n A type for Tensors to be generic over indicating their dimensionality/rank A way to access the associated ndarray type indicating dimensionality as an implementation detail (e.g. Ix0, Ix1, Ix2, etc.)  We use a trait so that we can apply it as a trait bound for tensors. However we make sure to hide the internal type from the public documentation:\npub trait Rank: Clone + Sealed { #[doc(hidden)] type Internal: Dimension; } We are using the Sealed Traits pattern here because we have an implementation detail inside the trait and we don’t want to expose this to the public API. If this trait were allowed to be implemented by foreign types then they would have to be aware that ndarray is in use, etc. and changing this later would be a breaking change.\nFor the implementation, all of our rank types (0 through 5) follow the same structure, so here is the definition of rank 0 as an example:\n#[derive(Clone, Debug, Default, Eq, PartialEq)] pub struct Zero; impl Rank for Zero { type Internal = Ix0; } impl Sealed for Zero {} ",
  "wordCount" : "1334",
  "inLanguage": "en",
  "datePublished": "2022-07-24T12:48:11+01:00",
  "dateModified": "2022-07-24T12:48:11+01:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/refactoring/tensors/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Robin Firth",
    "logo": {
      "@type": "ImageObject",
      "url": "https://forgottenmaster.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://forgottenmaster.github.io/" accesskey="h" title="Robin Firth (Alt + H)">Robin Firth</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://forgottenmaster.github.io/resume/" title="Résumé">
                    <span>Résumé</span>
                </a>
            </li>
            <li>
                <a href="https://forgottenmaster.github.io/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://forgottenmaster.github.io/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://forgottenmaster.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/">Posts</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/machinelearning/">Machine Learning</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/">Deep Learning From Scratch</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/refactoring/">Refactoring Eidetic</a></div>
    <h1 class="post-title">
      Part 2 - Tensors
    </h1>
    <div class="post-meta"><span title='2022-07-24 12:48:11 +0100 BST'>July 24, 2022</span>&nbsp;·&nbsp;7 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#what-is-a-tensor" aria-label="What is a tensor?">What is a tensor?</a></li>
                <li>
                    <a href="#why-we-need-a-tensor" aria-label="Why we need a tensor?">Why we need a tensor?</a></li>
                <li>
                    <a href="#the-tensor-type" aria-label="The Tensor type">The Tensor type</a><ul>
                        
                <li>
                    <a href="#constructing-a-tensor-type" aria-label="Constructing a tensor type">Constructing a tensor type</a></li>
                <li>
                    <a href="#reading-from-a-tensor-type" aria-label="Reading from a tensor type">Reading from a tensor type</a></li></ul>
                </li>
                <li>
                    <a href="#the-rank-type" aria-label="The Rank type">The Rank type</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>A &ldquo;tensor&rdquo; is just a fancy name for &ldquo;n-dimensional array&rdquo; (AKA ndarray) and provides a way of thinking about scalars, vectors, matrices, etc. in a uniform way. We refactor Eidetic to use this concept because we want operations to be able to specify how many dimensions are in the input and output data. This post will provide a brief overview of what a tensor is, and how we implement it in Eidetic.</p>
<h1 id="what-is-a-tensor">What is a tensor?<a hidden class="anchor" aria-hidden="true" href="#what-is-a-tensor">#</a></h1>
<p>As mentioned in the introduction blurb, a tensor is just simply an array with N dimensions. In tensor terminology the N here is known as it&rsquo;s <strong>rank</strong>. For ease of understanding, there&rsquo;s a few ranks of tensor below with common terminology for that particular data type.</p>
<ul>
<li><strong>Rank 0</strong> =&gt; &ldquo;Scalar&rdquo;. A rank 0 tensor has no dimensions and is a single point. In terms of elements this means it only has a single element contained within which is known as a scalar in mathematics.</li>
<li><strong>Rank 1</strong> =&gt; &ldquo;Vector&rdquo;. A rank 1 tensor has only a single dimension which represents its length. All elements are on this 1 dimension and the overal data structure is commonly referred to as a vector (list of things).</li>
<li><strong>Rank 2</strong> =&gt; &ldquo;Matrix&rdquo;. A rank 2 tensor has two dimensions which represent the width and height (alternatively rows and columns). Such a tensor is commonly referred to as a matrix.</li>
</ul>
<p>Higher ranked tensors exist but don&rsquo;t have common names for them and are harder to think about or draw in a diagram. A rank 3 tensor can be thought of as a &ldquo;cube&rdquo; or a &ldquo;stack&rdquo; of matrices stacked on top of one another and is commonly used to represent the layers in an image for example.</p>
<p>After this they start to become more abstract - a rank 4 tensor can be thought of as a &ldquo;vector of cubes&rdquo; perhaps.</p>
<h1 id="why-we-need-a-tensor">Why we need a tensor?<a hidden class="anchor" aria-hidden="true" href="#why-we-need-a-tensor">#</a></h1>
<p>We need a tensor type in the API because we want to constrain operations and layers to using the same type but allow them to be generic over the rank of the tensor. Using a common type allows us to avoid having to have separate types for scalars, vectors, matrices, etc.</p>
<h1 id="the-tensor-type">The Tensor type<a hidden class="anchor" aria-hidden="true" href="#the-tensor-type">#</a></h1>
<p>Now we have a brief explanation of what tensors are, we can look at how they&rsquo;re implemented inside Eidetic. The following are points that we&rsquo;re trying to satisfy with our implementation:</p>
<ol>
<li>Tensors must be generic over a rank indicating its dimensionality.</li>
<li>Tensors must hide all implementation details of how they&rsquo;re stored internally.</li>
<li>Tensors should be constructible through a new function which may or may not be fallible.</li>
<li>The data inside a Tensor should be iterable.</li>
</ol>
<p>The type that we settled upon for a Tensor is as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">Tensor</span><span style="color:#f92672">&lt;</span>R: <span style="color:#a6e22e">Rank</span><span style="color:#f92672">&gt;</span>(<span style="color:#66d9ef">pub</span>(<span style="color:#66d9ef">crate</span>) Array<span style="color:#f92672">&lt;</span>ElementType, R::Internal<span style="color:#f92672">&gt;</span>);</code></pre></div>
<p>This is generic over a parameter type R which <strong>MUST</strong> implement the Rank trait. This is because we need to access the Internal associated type which allows us to define the ndarray::Array type we&rsquo;re using to store the data internally.</p>
<p>This internal state is hidden from the public API by the pub(crate) visibility modifier which means that the public API has no reference at all to the ndarray crate or the Array type. We would easily be able to swap out the implementation for something else as long as the public API continues to use the Tensor type.</p>
<p>pub(crate) gives the crate the ability to work with the ndarray::Array type stored inside however which allows us to internally use all the methods provided by the ndarray crate for calculations while leaving it an implementation detail.</p>
<h2 id="constructing-a-tensor-type">Constructing a tensor type<a hidden class="anchor" aria-hidden="true" href="#constructing-a-tensor-type">#</a></h2>
<p>In order to construct the tensor type in Eidetic we need to provide a &ldquo;new&rdquo; function for each rank of tensor we&rsquo;re constructing. This is due to the parameters and return type being different depending on the rank of the tensor we&rsquo;re constructing (since some ranks are infallible).</p>
<p>For rank 0 tensors (scalars) they will take as input a single element, and return a Tensor - this is infallible because we can always create a tensor with a single element from a single element. The code for this look as such:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#66d9ef">impl</span> Tensor<span style="color:#f92672">&lt;</span>rank::Zero<span style="color:#f92672">&gt;</span> {
    <span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">new</span>(elem: <span style="color:#a6e22e">ElementType</span>) -&gt; <span style="color:#a6e22e">Self</span> {
        Self(arr0(elem))
    }
}</code></pre></div>
<p>For rank 1 tensors (vectors) they will take some type that we can get an iterator of elements from, and will put all those elements into a single dimension in the tensor (it&rsquo;s length). This is infallible because we are simply taking the number of elements in the iterable as the length of the tensor:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#66d9ef">impl</span> Tensor<span style="color:#f92672">&lt;</span>rank::One<span style="color:#f92672">&gt;</span> {
    <span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">new</span>(iter: <span style="color:#a6e22e">impl</span> IntoIterator<span style="color:#f92672">&lt;</span>Item <span style="color:#f92672">=</span> ElementType<span style="color:#f92672">&gt;</span>) -&gt; <span style="color:#a6e22e">Self</span> {
        Self(Array::from_iter(iter))
    }
}</code></pre></div>
<p>Rank 2 and higher tensors are not infallible because this is where we have to take a flat iterator of elements, and reshape it to fit a desired shape. If there aren&rsquo;t enough elements inside the iterator for the requested shape then this will be an error.</p>
<p>I&rsquo;ll only show one implementation here, but they will all follow the same format:</p>
<ol>
<li>Take the iterator provided and make a 1-dimensional array from it</li>
<li>Reshape the array into an n-dimensional one using the provided/requested shape</li>
<li>If this is an error from ndarray (invalid number of elements) then map the error type to our own Eidetic error type</li>
</ol>
<p>The code for example for a rank 2 tensor looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#66d9ef">impl</span> Tensor<span style="color:#f92672">&lt;</span>rank::Two<span style="color:#f92672">&gt;</span> {
    <span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">new</span>(shape: (<span style="color:#66d9ef">usize</span>, <span style="color:#66d9ef">usize</span>), iter: <span style="color:#a6e22e">impl</span> IntoIterator<span style="color:#f92672">&lt;</span>Item <span style="color:#f92672">=</span> ElementType<span style="color:#f92672">&gt;</span>) -&gt; Result<span style="color:#f92672">&lt;</span>Self<span style="color:#f92672">&gt;</span> {
        <span style="color:#66d9ef">let</span> array: <span style="color:#a6e22e">Array</span><span style="color:#f92672">&lt;</span>ElementType, Ix1<span style="color:#f92672">&gt;</span> <span style="color:#f92672">=</span> Array::from_iter(iter);
        <span style="color:#66d9ef">let</span> array: <span style="color:#a6e22e">Array</span><span style="color:#f92672">&lt;</span>ElementType, Ix2<span style="color:#f92672">&gt;</span> <span style="color:#f92672">=</span> array.into_shape(shape).map_err(<span style="color:#f92672">|</span>_<span style="color:#f92672">|</span> Error(()))<span style="color:#f92672">?</span>;
        Ok(Self(array))
    }
}</code></pre></div>
<p>Note that we&rsquo;re using the eidetic::Result type alias here since all results output by Eidetic will use the error type of eidetic::Error.</p>
<h2 id="reading-from-a-tensor-type">Reading from a tensor type<a hidden class="anchor" aria-hidden="true" href="#reading-from-a-tensor-type">#</a></h2>
<p>Now that we have the ability to construct a tensor from an iterator, we need the ability to go the other way and iterate the values in a tensor which will allow us to interpret the output data from Eidetic as required.</p>
<p>In order to do this we will need to implement the IntoIterator trait provided by Rust, which will iterate over elements of the type eidetic::ElementType (f64 by default, f32 if Cargo feature is enabled). The definition of this trait looks like follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#66d9ef">impl</span><span style="color:#f92672">&lt;</span>R: <span style="color:#a6e22e">Rank</span><span style="color:#f92672">&gt;</span> IntoIterator <span style="color:#66d9ef">for</span> Tensor<span style="color:#f92672">&lt;</span>R<span style="color:#f92672">&gt;</span> {
    <span style="color:#66d9ef">type</span> <span style="color:#a6e22e">Item</span> <span style="color:#f92672">=</span> ElementType;
    <span style="color:#66d9ef">type</span> <span style="color:#a6e22e">IntoIter</span> <span style="color:#f92672">=</span> TensorIterator<span style="color:#f92672">&lt;</span>R<span style="color:#f92672">&gt;</span>;

    <span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">into_iter</span>(self) -&gt; <span style="color:#a6e22e">Self</span>::IntoIter {
        TensorIterator(self.<span style="color:#ae81ff">0.</span>into_iter())
    }
}</code></pre></div>
<p>The iterator type is a new type TensorIterator which simply wraps our ndarray::Array type&rsquo;s iterator and delegates the next method. Taking the struct definition and the Iterator trait implementation together we get:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">TensorIterator</span><span style="color:#f92672">&lt;</span>R: <span style="color:#a6e22e">Rank</span><span style="color:#f92672">&gt;</span>(<span style="color:#f92672">&lt;</span>Array<span style="color:#f92672">&lt;</span>ElementType, R::Internal<span style="color:#f92672">&gt;</span> <span style="color:#66d9ef">as</span> IntoIterator<span style="color:#f92672">&gt;</span>::IntoIter);

<span style="color:#66d9ef">impl</span><span style="color:#f92672">&lt;</span>R: <span style="color:#a6e22e">Rank</span><span style="color:#f92672">&gt;</span> Iterator <span style="color:#66d9ef">for</span> TensorIterator<span style="color:#f92672">&lt;</span>R<span style="color:#f92672">&gt;</span> {
    <span style="color:#66d9ef">type</span> <span style="color:#a6e22e">Item</span> <span style="color:#f92672">=</span> ElementType;
    <span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">next</span>(<span style="color:#f92672">&amp;</span><span style="color:#66d9ef">mut</span> self) -&gt; Option<span style="color:#f92672">&lt;</span>Self::Item<span style="color:#f92672">&gt;</span> {
        self.<span style="color:#ae81ff">0.</span>next()
    }
}</code></pre></div>
<p>Again, the wrapped iterator from ndarray is kept private so it doesn&rsquo;t leak into the public API.</p>
<h1 id="the-rank-type">The Rank type<a hidden class="anchor" aria-hidden="true" href="#the-rank-type">#</a></h1>
<p>The other part of the Tensor type is the Rank types which are required for 2 reasons:</p>
<ol>
<li>A type for Tensors to be generic over indicating their dimensionality/rank</li>
<li>A way to access the associated ndarray type indicating dimensionality as an implementation detail (e.g. Ix0, Ix1, Ix2, etc.)</li>
</ol>
<p>We use a trait so that we can apply it as a trait bound for tensors. However we make sure to hide the internal type from the public documentation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">trait</span> Rank: Clone <span style="color:#f92672">+</span> Sealed {
    <span style="color:#75715e">#[doc(hidden)]</span>
    <span style="color:#66d9ef">type</span> <span style="color:#a6e22e">Internal</span>: <span style="color:#a6e22e">Dimension</span>;
}</code></pre></div>
<p>We are using the <a href="https://rust-lang.github.io/api-guidelines/future-proofing.html#sealed-traits-protect-against-downstream-implementations-c-sealed">Sealed Traits</a> pattern here because we have an implementation detail inside the trait and we don&rsquo;t want to expose this to the public API. If this trait were allowed to be implemented by foreign types then they would have to be aware that ndarray is in use, etc. and changing this later would be a breaking change.</p>
<p>For the implementation, all of our rank types (0 through 5) follow the same structure, so here is the definition of rank 0 as an example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#75715e">#[derive(Clone, Debug, Default, Eq, PartialEq)]</span>
<span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">Zero</span>;
<span style="color:#66d9ef">impl</span> Rank <span style="color:#66d9ef">for</span> Zero {
    <span style="color:#66d9ef">type</span> <span style="color:#a6e22e">Internal</span> <span style="color:#f92672">=</span> Ix0;
}
<span style="color:#66d9ef">impl</span> Sealed <span style="color:#66d9ef">for</span> Zero {}</code></pre></div>


  </div>

  <footer class="post-footer">
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://forgottenmaster.github.io/">Robin Firth</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
