<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>4.1 - Overview | Robin Firth</title>
<meta name="keywords" content="" />
<meta name="description" content="Although we have managed to put together a working neural network library that allows us to build various topologies of networks and to train them to fit a non-specified mathematical function that is represented by the input data and targets, the initial implementation is only somewhat successful. We can do better in a few ways, we will explore 5 such extensions to the basic approach in the following notes.
High level review We can imagine a neural network at a high level as a black box which consists of a bunch of weights internally (grouped into layers, but we can consider this as an implementation detail), taking a bunch of input data records and producing a bunch of predictions for those records.">
<meta name="author" content="">
<link rel="canonical" href="https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter4/overview/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.6f60056d44d3f7eb69a4bc6c332b59960f3a995802bded244750232f33713c49.css" integrity="sha256-b2AFbUTT9&#43;tppLxsMytZlg86mVgCve0kR1AjLzNxPEk=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js" integrity="sha256-uVus3DnjejMqn4g7Hni&#43;Srwf3KK8HyZB9V4809q9TWE="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://forgottenmaster.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://forgottenmaster.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://forgottenmaster.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://forgottenmaster.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://forgottenmaster.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.110.0">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:title" content="4.1 - Overview" />
<meta property="og:description" content="Although we have managed to put together a working neural network library that allows us to build various topologies of networks and to train them to fit a non-specified mathematical function that is represented by the input data and targets, the initial implementation is only somewhat successful. We can do better in a few ways, we will explore 5 such extensions to the basic approach in the following notes.
High level review We can imagine a neural network at a high level as a black box which consists of a bunch of weights internally (grouped into layers, but we can consider this as an implementation detail), taking a bunch of input data records and producing a bunch of predictions for those records." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter4/overview/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-26T23:54:29&#43;01:00" />
<meta property="article:modified_time" content="2022-04-26T23:54:29&#43;01:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="4.1 - Overview"/>
<meta name="twitter:description" content="Although we have managed to put together a working neural network library that allows us to build various topologies of networks and to train them to fit a non-specified mathematical function that is represented by the input data and targets, the initial implementation is only somewhat successful. We can do better in a few ways, we will explore 5 such extensions to the basic approach in the following notes.
High level review We can imagine a neural network at a high level as a black box which consists of a bunch of weights internally (grouped into layers, but we can consider this as an implementation detail), taking a bunch of input data records and producing a bunch of predictions for those records."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://forgottenmaster.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Machine Learning",
      "item": "https://forgottenmaster.github.io/posts/machinelearning/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Deep Learning From Scratch",
      "item": "https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "Chapter 4 - Extensions",
      "item": "https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter4/"
    }, 
    {
      "@type": "ListItem",
      "position":  5 ,
      "name": "4.1 - Overview",
      "item": "https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter4/overview/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "4.1 - Overview",
  "name": "4.1 - Overview",
  "description": "Although we have managed to put together a working neural network library that allows us to build various topologies of networks and to train them to fit a non-specified mathematical function that is represented by the input data and targets, the initial implementation is only somewhat successful. We can do better in a few ways, we will explore 5 such extensions to the basic approach in the following notes.\nHigh level review We can imagine a neural network at a high level as a black box which consists of a bunch of weights internally (grouped into layers, but we can consider this as an implementation detail), taking a bunch of input data records and producing a bunch of predictions for those records.",
  "keywords": [
    
  ],
  "articleBody": "Although we have managed to put together a working neural network library that allows us to build various topologies of networks and to train them to fit a non-specified mathematical function that is represented by the input data and targets, the initial implementation is only somewhat successful. We can do better in a few ways, we will explore 5 such extensions to the basic approach in the following notes.\nHigh level review We can imagine a neural network at a high level as a black box which consists of a bunch of weights internally (grouped into layers, but we can consider this as an implementation detail), taking a bunch of input data records and producing a bunch of predictions for those records. These predictions are then compared with the known targets during the training process to see how close they are (using the loss function).\nTherefore this high level intuition can be represented by the following diagram\nA more accurate representation The above diagram is good for seeing at a high level that neural networks are treated as black boxes to produce predictions and can be trained to produce better predictions, however what is really happening under the hood is that we’re tweaking the weights in such a way as to represent the complex mathematical function between the set of weights and the output loss that those weights produce (given a static set of inputs and outputs).\nThis graph between the weights and the loss can be shown as follows\nTraining With the above graph representation we can see that as the set of weights vary along the horizontal axis, the loss, or error, of the network can be greater or lower (actually the set of weights isn’t a single value to be plotted on an axis, but it helps intuition to think of it as a single dimension on which a single point is a set of values for all weights in the network).\nThe training process is then represented as starting from one point, or set of weights and using the learning rate, determining a new set of weights and continuing until we settle on the set of weights producing the lowest loss.\nWe can view this process as the following diagram\nIn the above diagram, the blue arrows show the process with a small learning rate, that is we move only slightly to the next set of weights. The red arrows represent a large learning rate which causes the set of weights and resulting loss to “bounce around” more than it might want to.\nThe problem As we can see from the diagram, we would like to find the set of weights that gives the lowest global loss across all sets of weights, however with a very small learning rate we risk the chance of falling into a local minima and accepting a sub-optimal solution.\nIf the steps we take are too large (the red arrows), then we might be near the global minimum but we might end up “skipping over” it repeatedly and again accepting a sub-optimal solution.\nThe tricks and tweaks described and implemented in the coming posts serve as to allow us to efficiently locate this global minimum without falling into a false, local minimum.\n",
  "wordCount" : "541",
  "inLanguage": "en",
  "datePublished": "2022-04-26T23:54:29+01:00",
  "dateModified": "2022-04-26T23:54:29+01:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter4/overview/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Robin Firth",
    "logo": {
      "@type": "ImageObject",
      "url": "https://forgottenmaster.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://forgottenmaster.github.io/" accesskey="h" title="Robin Firth (Alt + H)">Robin Firth</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://forgottenmaster.github.io/resume/" title="Résumé">
                    <span>Résumé</span>
                </a>
            </li>
            <li>
                <a href="https://forgottenmaster.github.io/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://forgottenmaster.github.io/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://forgottenmaster.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/">Posts</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/machinelearning/">Machine Learning</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/">Deep Learning From Scratch</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/machinelearning/deeplearningfromscratch/chapter4/">Chapter 4 - Extensions</a></div>
    <h1 class="post-title">
      4.1 - Overview
    </h1>
    <div class="post-meta"><span title='2022-04-26 23:54:29 +0100 BST'>April 26, 2022</span>&nbsp;·&nbsp;3 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#high-level-review" aria-label="High level review">High level review</a></li>
                <li>
                    <a href="#a-more-accurate-representation" aria-label="A more accurate representation">A more accurate representation</a></li>
                <li>
                    <a href="#training" aria-label="Training">Training</a></li>
                <li>
                    <a href="#the-problem" aria-label="The problem">The problem</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Although we have managed to put together a working neural network library that allows us to build various topologies of networks and to train them to fit a non-specified mathematical function that is represented by the input data and targets, the initial implementation is only somewhat successful. We can do better in a few ways, we will explore 5 such extensions to the basic approach in the following notes.</p>
<h3 id="high-level-review">High level review<a hidden class="anchor" aria-hidden="true" href="#high-level-review">#</a></h3>
<p>We can imagine a neural network at a high level as a black box which consists of a bunch of weights internally (grouped into layers, but we can consider this as an implementation detail), taking a bunch of input data records and producing a bunch of predictions for those records. These predictions are then compared with the known targets during the training process to see how close they are (using the loss function).</p>
<p>Therefore this high level intuition can be represented by the following diagram</p>
<p><img loading="lazy" src="high_level.PNG" alt="High level neural net diagram"  />
</p>
<h3 id="a-more-accurate-representation">A more accurate representation<a hidden class="anchor" aria-hidden="true" href="#a-more-accurate-representation">#</a></h3>
<p>The above diagram is good for seeing at a high level that neural networks are treated as black boxes to produce predictions and can be trained to produce better predictions, however what is really happening under the hood is that we&rsquo;re tweaking the weights in such a way as to represent the complex mathematical function between the set of weights and the output loss that those weights produce (given a static set of inputs and outputs).</p>
<p>This graph between the weights and the loss can be shown as follows</p>
<p><img loading="lazy" src="mathematical_representation.PNG" alt="Lower level diagram"  />
</p>
<h3 id="training">Training<a hidden class="anchor" aria-hidden="true" href="#training">#</a></h3>
<p>With the above graph representation we can see that as the set of weights vary along the horizontal axis, the loss, or error, of the network can be greater or lower (actually the set of weights isn&rsquo;t a single value to be plotted on an axis, but it helps intuition to think of it as a single dimension on which a single point is a set of values for all weights in the network).</p>
<p>The training process is then represented as starting from one point, or set of weights and using the learning rate, determining a new set of weights and continuing until we settle on the set of weights producing the lowest loss.</p>
<p>We can view this process as the following diagram</p>
<p><img loading="lazy" src="training.PNG" alt="Training illustration"  />
</p>
<p>In the above diagram, the blue arrows show the process with a small learning rate, that is we move only slightly to the next set of weights. The red arrows represent a large learning rate which causes the set of weights and resulting loss to &ldquo;bounce around&rdquo; more than it might want to.</p>
<h3 id="the-problem">The problem<a hidden class="anchor" aria-hidden="true" href="#the-problem">#</a></h3>
<p>As we can see from the diagram, we would like to find the set of weights that gives the lowest <strong>global</strong> loss across all sets of weights, however with a very small learning rate we risk the chance of falling into a <strong>local</strong> minima and accepting a sub-optimal solution.</p>
<p>If the steps we take are too large (the red arrows), then we might be near the global minimum but we might end up &ldquo;skipping over&rdquo; it repeatedly and again accepting a sub-optimal solution.</p>
<p>The tricks and tweaks described and implemented in the coming posts serve as to allow us to efficiently locate this global minimum without falling into a false, local minimum.</p>


  </div>

  <footer class="post-footer">
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://forgottenmaster.github.io/">Robin Firth</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
