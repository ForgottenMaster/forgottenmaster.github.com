<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>11. Staging Buffers | Robin Smith</title>
<meta name="keywords" content="">
<meta name="description" content="Currently our vertex buffer is residing on the GPU but in a section of memory that is visible to the CPU. This incurs an overhead on the GPU so that it&rsquo;s not able to process that memory as fast as it could if it knew the CPU could not see it.
Memory Types In Vulkan there are various pools of memory with different properties that we can use to allocate buffer memory.">
<meta name="author" content="">
<link rel="canonical" href="https://forgottenmaster.github.io/posts/vulkan/lets-learn-vulkan/staging-buffers/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://forgottenmaster.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://forgottenmaster.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://forgottenmaster.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://forgottenmaster.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://forgottenmaster.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://forgottenmaster.github.io/posts/vulkan/lets-learn-vulkan/staging-buffers/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="11. Staging Buffers" />
<meta property="og:description" content="Currently our vertex buffer is residing on the GPU but in a section of memory that is visible to the CPU. This incurs an overhead on the GPU so that it&rsquo;s not able to process that memory as fast as it could if it knew the CPU could not see it.
Memory Types In Vulkan there are various pools of memory with different properties that we can use to allocate buffer memory." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://forgottenmaster.github.io/posts/vulkan/lets-learn-vulkan/staging-buffers/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-04T19:56:24+00:00" />
<meta property="article:modified_time" content="2023-03-04T19:56:24+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="11. Staging Buffers"/>
<meta name="twitter:description" content="Currently our vertex buffer is residing on the GPU but in a section of memory that is visible to the CPU. This incurs an overhead on the GPU so that it&rsquo;s not able to process that memory as fast as it could if it knew the CPU could not see it.
Memory Types In Vulkan there are various pools of memory with different properties that we can use to allocate buffer memory."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://forgottenmaster.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Vulkan",
      "item": "https://forgottenmaster.github.io/posts/vulkan/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Let's Learn Vulkan",
      "item": "https://forgottenmaster.github.io/posts/vulkan/lets-learn-vulkan/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "11. Staging Buffers",
      "item": "https://forgottenmaster.github.io/posts/vulkan/lets-learn-vulkan/staging-buffers/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "11. Staging Buffers",
  "name": "11. Staging Buffers",
  "description": "Currently our vertex buffer is residing on the GPU but in a section of memory that is visible to the CPU. This incurs an overhead on the GPU so that it\u0026rsquo;s not able to process that memory as fast as it could if it knew the CPU could not see it.\nMemory Types In Vulkan there are various pools of memory with different properties that we can use to allocate buffer memory.",
  "keywords": [
    
  ],
  "articleBody": "Currently our vertex buffer is residing on the GPU but in a section of memory that is visible to the CPU. This incurs an overhead on the GPU so that it’s not able to process that memory as fast as it could if it knew the CPU could not see it.\nMemory Types In Vulkan there are various pools of memory with different properties that we can use to allocate buffer memory. This diagram shows a relationship between the various areas that memory and caching can reside\nMemory Types\rFaster than life\nThe fastest area for memory, as mentioned already, is the area labelled “device local”. The GPU can run this memory as fast as it can because it knows it’s in sole charge of the data and the CPU cannot see, nor modify it without going through the GPU first.\nBut how can we get data into that memory if we can’t see it? This is where staging buffers come in.\nStaging Buffers A staging buffer is a (potentially) temporary buffer that is host visible, that we can write our data into from the application side. From there, we tell Vulkan to transfer our data from that buffer, into a buffer backed by device local memory where it’ll be used longer term.\nThe sequence of operations therefore to get data onto device local memory is as follows:\nAllocate a buffer of the appropriate size, with the usage type of TRANSFER_SRC set. Allocate memory of the correct size from a supported type, with the properties HOST_VISIBLE and HOST_COHERENT set. Bind the memory allocated in step 2, to the buffer allocated in step 1. Map, write the data, and unmap the staging buffer to get the data into this memory from the application. Allocate a buffer of the appropriate size, with the usage type of TRANSFER_DST set. Allocate memory of the correct size from a supported type, with the property DEVICE_LOCAL set. Bind the memory allocated in step 6, to the buffer allocated in step 5. Allocate a command buffer. Record a copy operation into the command buffer. Submit the command buffer to a queue capable of transfer operations. (Optional) Free the command buffer. (Optional) Free the staging buffer memory. (Optional) Free the staging buffer. Note that steps 11, 12, and 13 are marked as optional because they may be reused through the lifetime of an application. They’ll need to be freed/destroyed by the application teardown stage though.\nWe’ll then go ahead and implement this sequence of steps, assuming that the staging buffer and copy command buffer are only good for one staging operation, meaning we’ll clean them up after the copy is finished.\nFunction to Make a Buffer The first step will be to take our code that we had in our create_vertex_buffer function and make it generic, so that we can make any kind of buffer with it.\nThis is mostly a simple exercise, the signature will look as follows\nfn create_buffer( instance: \u0026Instance, device: \u0026Device, physical_device: PhysicalDevice, usage: BufferUsageFlags, memory_property_flags: MemoryPropertyFlags, size: DeviceSize, ) -\u003e Result\u003c(Buffer, DeviceMemory)\u003e We pass into the generic function the information it needs\nusage: This is the buffer usage, such as VERTEX_BUFFER, TRANSFER_SRC, etc. memory_property_flags: Indicates the type of memory we want to allocate from, for example DEVICE_LOCAL, HOST_VISIBLE, etc. size: The size (in bytes) of the buffer to allocate. There isn’t much to write home about on this function - it’s the same as we had for our vertex buffer, but with some hard-coded things replaced with parameters. As such, I’ll just list the entire code\nunsafe { // create a buffer handle of the right size and type. let buffer = device.create_buffer( \u0026BufferCreateInfo::builder() .size(size) .usage(usage) .sharing_mode(SharingMode::EXCLUSIVE), None, )?; // get buffer memory requirements plus the memory properties of our physical device. let memory_requirements = device.get_buffer_memory_requirements(buffer); let memory_properties = instance.get_physical_device_memory_properties(physical_device); // find a valid memory type index to use. let memory_type_index = find_valid_memory_type_index( memory_properties, memory_requirements, memory_property_flags, ) .ok_or_else(|| anyhow!(\"Failed to get a valid memory type for buffer.\"))?; // allocate memory. let buffer_memory = device .allocate_memory( \u0026MemoryAllocateInfo::builder() .allocation_size(memory_requirements.size) .memory_type_index(memory_type_index as u32), None, ) .context(\"Failed to allocate buffer memory.\")?; // bind buffer memory. device .bind_buffer_memory(buffer, buffer_memory, 0) .context(\"Failed to bind buffer memory to the buffer.\")?; // return. Ok::\u003c_, Error\u003e((buffer, buffer_memory)) } .context(\"Error when trying to create a buffer of some type.\") Function to Make a Staged Buffer Next, we’ll make a reusable function that will be able to take a list of some data type T as a slice, and will push that data to a buffer residing on device local memory via a staging buffer.\nWe’ll essentially be implementing steps 1-13 above in code.\nFirstly let’s take a look at the signature of this function\nfn create_staged_buffer\u003cT\u003e( instance: \u0026Instance, device: \u0026Device, physical_device: PhysicalDevice, elements: \u0026[T], usage: BufferUsageFlags, transfer_command_pool: CommandPool, transfer_queue: Queue, ) -\u003e Result\u003c(Buffer, DeviceMemory)\u003e Notably this function is generic over any type T, and takes a slice of T’s to push to the GPU. Additionally the caller must provide a command pool created on a queue family that supports transfer operations, and a specific queue to push the copy command buffer to.\nThe first thing required is to determine how many bytes we need to allocate. This is quite simple as we can get the size of a T from std::mem::size_of, and we know how many T’s there are. We must, however also convert this to a DeviceSize, which is a type alias for u64, because size_of returns a usize.\nlet size = (mem::size_of::\u003cT\u003e() * elements.len()) as DeviceSize; Next we need to create 2 buffers, and backing memory storage. One will be for the staging buffer and will be dropped after copying the data, which will require a usage flag of TRANSFER_SRC, and will require a memory type that is HOST_VISIBLE and HOST_COHERENT.\nThe device local buffer we will be returning needs to have TRANSFER_DST, and the memory type needs to be DEVICE_LOCAL. Written as code this would be\nlet (staging_buffer, staging_buffer_memory) = create_buffer( instance, device, physical_device, usage | BufferUsageFlags::TRANSFER_SRC, MemoryPropertyFlags::HOST_VISIBLE | MemoryPropertyFlags::HOST_COHERENT, size, ) .context(\"Failed to create staging buffer.\")?; let (gpu_buffer, gpu_buffer_memory) = create_buffer( instance, device, physical_device, usage | BufferUsageFlags::TRANSFER_DST, MemoryPropertyFlags::DEVICE_LOCAL, size, ) .context(\"Failed to create GPU buffer.\")?; We then go ahead and copy the data from our slice of T’s to the allocated staging buffer memory using the method that we previously used for our vertex buffer (map, write, unmap)\nlet write_ptr = device .map_memory(staging_buffer_memory, 0, size, MemoryMapFlags::empty()) .context(\"Failed to map the staging buffer memory.\")? as *mut T; ptr::copy_nonoverlapping(elements.as_ptr(), write_ptr, elements.len()); device.unmap_memory(staging_buffer_memory); Our data is now residing in our staging buffer so we can tell Vulkan to transfer it to our device local buffer. To do this we first need to allocate a command buffer to record the copy operation into. This needs to be a primary command buffer because we will be submitting it directly to the queue.\nlet command_buffer = device .allocate_command_buffers( \u0026CommandBufferAllocateInfo::builder() .command_pool(transfer_command_pool) .level(CommandBufferLevel::PRIMARY) .command_buffer_count(1), ) .context(\"Failed to allocate a staging transfer command buffer.\")?[0]; Before we can record any commands to the buffer, we need to tell Vulkan we are starting to record to that particular buffer. In this case we will use the ONE_TIME_SUBMIT flag since we will be returning the command buffer to the pool once the copy operation is over.\ndevice .begin_command_buffer( command_buffer, \u0026CommandBufferBeginInfo::builder().flags(CommandBufferUsageFlags::ONE_TIME_SUBMIT), ) .context(\"Failed to begin recording the command buffer.\")?; Now that we’ve told Vulkan we’re recording our commands into that buffer, we can go ahead and issue our command. In this case we have only a single command to do a buffer copy operation.\nVulkan expects the source buffer, and the destination buffer, but also we can specify offsets in each to copy with. In our case though, we copy from the beginning of the source buffer (our staging buffer), to the beginning of the destination buffer (our device local buffer).\ndevice.cmd_copy_buffer( command_buffer, staging_buffer, gpu_buffer, \u0026[*BufferCopy::builder().size(size)], ); With that, we can tell Vulkan we’re done recording commands into the command buffer\ndevice .end_command_buffer(command_buffer) .context(\"Failed to end recording the command buffer.\")?; We will now submit the buffer to the transfer queue, much like we submitted our drawing buffer to the graphics queue for rendering. We could provide a fence or semaphore to this operation if needed, but in our case we will push the buffer to the queue, and then wait until the queue is finished processing.\nBlocking the CPU like this isn’t necessarily a good idea, but it makes the code simpler in this case!\n// submit the copy operation to the transfer queue. let command_buffers = [command_buffer]; let submit_infos = [*SubmitInfo::builder().command_buffers(\u0026command_buffers)]; device .queue_submit(transfer_queue, \u0026submit_infos, Fence::null()) .context(\"Failed to submit the command buffer to the queue.\")?; // block the thread until the copy operation is finished. device .queue_wait_idle(transfer_queue) .context(\"Failed to wait for the transfer to finish.\")?; After the copy operation is finished we have no more need for the transfer command buffer, nor for the staging buffer/memory so we free those. Note that we might want to keep these around for re-use in a bigger application but for now, we are just pushing the data to the GPU once and never changing it, so we can do that at the beginning an drop the staging buffers.\ndevice.free_command_buffers(transfer_command_pool, \u0026[command_buffer]); device.free_memory(staging_buffer_memory, None); device.destroy_buffer(staging_buffer, None); Modifying the Vertex Shader Function Finally, we can go ahead and just modify the create_vertex_shader function to simply use the staged buffer function we just created, with a buffer usage type of VERTEX_BUFFER. Since the function is so simple I’ll just drop all the code here.\nfn create_vertex_buffer( instance: \u0026Instance, device: \u0026Device, physical_device: PhysicalDevice, vertices: \u0026[Vertex], transfer_command_pool: CommandPool, transfer_queue: Queue, ) -\u003e Result\u003c(Buffer, DeviceMemory)\u003e { create_staged_buffer( instance, device, physical_device, vertices, BufferUsageFlags::VERTEX_BUFFER, transfer_command_pool, transfer_queue, ) .context(\"Failed to create a vertex buffer.\") } Testing We’ll go ahead and test that after making tese changes our program still works as before.\nIndeed it does! (and now our vertex data resides in the much faster GPU-only memory section :D)\n",
  "wordCount" : "1644",
  "inLanguage": "en",
  "datePublished": "2023-03-04T19:56:24Z",
  "dateModified": "2023-03-04T19:56:24Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://forgottenmaster.github.io/posts/vulkan/lets-learn-vulkan/staging-buffers/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Robin Smith",
    "logo": {
      "@type": "ImageObject",
      "url": "https://forgottenmaster.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://forgottenmaster.github.io/" accesskey="h" title="Robin Smith (Alt + H)">Robin Smith</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://forgottenmaster.github.io/resume/" title="Résumé">
                    <span>Résumé</span>
                </a>
            </li>
            <li>
                <a href="https://forgottenmaster.github.io/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://forgottenmaster.github.io/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://forgottenmaster.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/">Posts</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/vulkan/">Vulkan</a>&nbsp;»&nbsp;<a href="https://forgottenmaster.github.io/posts/vulkan/lets-learn-vulkan/">Let&#39;s Learn Vulkan</a></div>
    <h1 class="post-title entry-hint-parent">
      11. Staging Buffers
    </h1>
    <div class="post-meta"><span title='2023-03-04 19:56:24 +0000 UTC'>March 4, 2023</span>&nbsp;·&nbsp;8 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#memory-types" aria-label="Memory Types">Memory Types</a></li>
                <li>
                    <a href="#staging-buffers" aria-label="Staging Buffers">Staging Buffers</a></li>
                <li>
                    <a href="#function-to-make-a-buffer" aria-label="Function to Make a Buffer">Function to Make a Buffer</a></li>
                <li>
                    <a href="#function-to-make-a-staged-buffer" aria-label="Function to Make a Staged Buffer">Function to Make a Staged Buffer</a></li>
                <li>
                    <a href="#modifying-the-vertex-shader-function" aria-label="Modifying the Vertex Shader Function">Modifying the Vertex Shader Function</a></li>
                <li>
                    <a href="#testing" aria-label="Testing">Testing</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Currently our vertex buffer is residing on the GPU but in a section of memory that is visible to the CPU. This incurs an overhead on the GPU so that it&rsquo;s not able to process that memory as fast as it could if it knew the CPU could not see it.</p>
<h1 id="memory-types">Memory Types<a hidden class="anchor" aria-hidden="true" href="#memory-types">#</a></h1>
<p>In Vulkan there are various pools of memory with different properties that we can use to allocate buffer memory. This diagram shows a relationship between the various areas that memory and caching can reside</p>
<figure class="align-center ">
    <img loading="lazy" src="memory-types.jpeg#center"/> <figcaption>
            Memory Types<p>
                    <a href="https://www.fasterthan.life/blog/2017/7/13/i-am-graphics-and-so-can-you-part-4-">Faster than life</a></p>
        </figcaption>
</figure>

<p>The fastest area for memory, as mentioned already, is the area labelled &ldquo;device local&rdquo;. The GPU can run this memory as fast as it can because it knows it&rsquo;s in sole charge of the data and the CPU cannot see, nor modify it without going through the GPU first.</p>
<p>But how can we get data into that memory if we can&rsquo;t see it? This is where <strong>staging buffers</strong> come in.</p>
<h1 id="staging-buffers">Staging Buffers<a hidden class="anchor" aria-hidden="true" href="#staging-buffers">#</a></h1>
<p>A staging buffer is a (potentially) temporary buffer that <em>is</em> host visible, that we can write our data into from the application side. From there, we tell Vulkan to transfer our data from that buffer, into a buffer backed by device local memory where it&rsquo;ll be used longer term.</p>
<p>The sequence of operations therefore to get data onto device local memory is as follows:</p>
<ol>
<li>Allocate a buffer of the appropriate size, with the usage type of <strong>TRANSFER_SRC</strong> set.</li>
<li>Allocate memory of the correct size from a supported type, with the properties <strong>HOST_VISIBLE</strong> and <strong>HOST_COHERENT</strong> set.</li>
<li>Bind the memory allocated in step 2, to the buffer allocated in step 1.</li>
<li>Map, write the data, and unmap the staging buffer to get the data into this memory from the application.</li>
<li>Allocate a buffer of the appropriate size, with the usage type of <strong>TRANSFER_DST</strong> set.</li>
<li>Allocate memory of the correct size from a supported type, with the property <strong>DEVICE_LOCAL</strong> set.</li>
<li>Bind the memory allocated in step 6, to the buffer allocated in step 5.</li>
<li>Allocate a command buffer.</li>
<li>Record a copy operation into the command buffer.</li>
<li>Submit the command buffer to a queue capable of transfer operations.</li>
<li>(Optional) Free the command buffer.</li>
<li>(Optional) Free the staging buffer memory.</li>
<li>(Optional) Free the staging buffer.</li>
</ol>
<p>Note that steps 11, 12, and 13 are marked as optional because they may be reused through the lifetime of an application. They&rsquo;ll need to be freed/destroyed by the application teardown stage though.</p>
<p>We&rsquo;ll then go ahead and implement this sequence of steps, assuming that the staging buffer and copy command buffer are only good for one staging operation, meaning we&rsquo;ll clean them up after the copy is finished.</p>
<h1 id="function-to-make-a-buffer">Function to Make a Buffer<a hidden class="anchor" aria-hidden="true" href="#function-to-make-a-buffer">#</a></h1>
<p>The first step will be to take our code that we had in our <strong>create_vertex_buffer</strong> function and make it generic, so that we can make any kind of buffer with it.</p>
<p>This is mostly a simple exercise, the signature will look as follows</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">create_buffer</span>(
</span></span><span style="display:flex;"><span>    instance: <span style="color:#66d9ef">&amp;</span><span style="color:#a6e22e">Instance</span>,
</span></span><span style="display:flex;"><span>    device: <span style="color:#66d9ef">&amp;</span><span style="color:#a6e22e">Device</span>,
</span></span><span style="display:flex;"><span>    physical_device: <span style="color:#a6e22e">PhysicalDevice</span>,
</span></span><span style="display:flex;"><span>    usage: <span style="color:#a6e22e">BufferUsageFlags</span>,
</span></span><span style="display:flex;"><span>    memory_property_flags: <span style="color:#a6e22e">MemoryPropertyFlags</span>,
</span></span><span style="display:flex;"><span>    size: <span style="color:#a6e22e">DeviceSize</span>,
</span></span><span style="display:flex;"><span>) -&gt; Result<span style="color:#f92672">&lt;</span>(Buffer, DeviceMemory)<span style="color:#f92672">&gt;</span></span></span></code></pre></div>
<p>We pass into the generic function the information it needs</p>
<ul>
<li><strong>usage</strong>: This is the buffer usage, such as VERTEX_BUFFER, TRANSFER_SRC, etc.</li>
<li><strong>memory_property_flags</strong>: Indicates the type of memory we want to allocate from, for example DEVICE_LOCAL, HOST_VISIBLE, etc.</li>
<li><strong>size</strong>: The size (in bytes) of the buffer to allocate.</li>
</ul>
<p>There isn&rsquo;t much to write home about on this function - it&rsquo;s the same as we had for our vertex buffer, but with some hard-coded things replaced with parameters. As such, I&rsquo;ll just list the entire code</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">unsafe</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// create a buffer handle of the right size and type.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">let</span> buffer <span style="color:#f92672">=</span> device.create_buffer(
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&amp;</span>BufferCreateInfo::builder()
</span></span><span style="display:flex;"><span>            .size(size)
</span></span><span style="display:flex;"><span>            .usage(usage)
</span></span><span style="display:flex;"><span>            .sharing_mode(SharingMode::<span style="color:#66d9ef">EXCLUSIVE</span>),
</span></span><span style="display:flex;"><span>        None,
</span></span><span style="display:flex;"><span>    )<span style="color:#f92672">?</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// get buffer memory requirements plus the memory properties of our physical device.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">let</span> memory_requirements <span style="color:#f92672">=</span> device.get_buffer_memory_requirements(buffer);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> memory_properties <span style="color:#f92672">=</span> instance.get_physical_device_memory_properties(physical_device);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// find a valid memory type index to use.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">let</span> memory_type_index <span style="color:#f92672">=</span> find_valid_memory_type_index(
</span></span><span style="display:flex;"><span>        memory_properties,
</span></span><span style="display:flex;"><span>        memory_requirements,
</span></span><span style="display:flex;"><span>        memory_property_flags,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    .ok_or_else(<span style="color:#f92672">||</span> anyhow!(<span style="color:#e6db74">&#34;Failed to get a valid memory type for buffer.&#34;</span>))<span style="color:#f92672">?</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// allocate memory.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">let</span> buffer_memory <span style="color:#f92672">=</span> device
</span></span><span style="display:flex;"><span>        .allocate_memory(
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&amp;</span>MemoryAllocateInfo::builder()
</span></span><span style="display:flex;"><span>                .allocation_size(memory_requirements.size)
</span></span><span style="display:flex;"><span>                .memory_type_index(memory_type_index <span style="color:#66d9ef">as</span> <span style="color:#66d9ef">u32</span>),
</span></span><span style="display:flex;"><span>            None,
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        .context(<span style="color:#e6db74">&#34;Failed to allocate buffer memory.&#34;</span>)<span style="color:#f92672">?</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// bind buffer memory.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    device
</span></span><span style="display:flex;"><span>        .bind_buffer_memory(buffer, buffer_memory, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>        .context(<span style="color:#e6db74">&#34;Failed to bind buffer memory to the buffer.&#34;</span>)<span style="color:#f92672">?</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// return.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    Ok::<span style="color:#f92672">&lt;</span>_, Error<span style="color:#f92672">&gt;</span>((buffer, buffer_memory))
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>.context(<span style="color:#e6db74">&#34;Error when trying to create a buffer of some type.&#34;</span>)</span></span></code></pre></div>
<h1 id="function-to-make-a-staged-buffer">Function to Make a Staged Buffer<a hidden class="anchor" aria-hidden="true" href="#function-to-make-a-staged-buffer">#</a></h1>
<p>Next, we&rsquo;ll make a reusable function that will be able to take a list of some data type T as a slice, and will push that data to a buffer residing on device local memory via a staging buffer.</p>
<p>We&rsquo;ll essentially be implementing steps 1-13 above in code.</p>
<p>Firstly let&rsquo;s take a look at the signature of this function</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">create_staged_buffer</span><span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span>(
</span></span><span style="display:flex;"><span>    instance: <span style="color:#66d9ef">&amp;</span><span style="color:#a6e22e">Instance</span>,
</span></span><span style="display:flex;"><span>    device: <span style="color:#66d9ef">&amp;</span><span style="color:#a6e22e">Device</span>,
</span></span><span style="display:flex;"><span>    physical_device: <span style="color:#a6e22e">PhysicalDevice</span>,
</span></span><span style="display:flex;"><span>    elements: <span style="color:#66d9ef">&amp;</span>[T],
</span></span><span style="display:flex;"><span>    usage: <span style="color:#a6e22e">BufferUsageFlags</span>,
</span></span><span style="display:flex;"><span>    transfer_command_pool: <span style="color:#a6e22e">CommandPool</span>,
</span></span><span style="display:flex;"><span>    transfer_queue: <span style="color:#a6e22e">Queue</span>,
</span></span><span style="display:flex;"><span>) -&gt; Result<span style="color:#f92672">&lt;</span>(Buffer, DeviceMemory)<span style="color:#f92672">&gt;</span></span></span></code></pre></div>
<p>Notably this function is generic over any type T, and takes a slice of T&rsquo;s to push to the GPU. Additionally the caller must provide a command pool created on a queue family that supports transfer operations, and a specific queue to push the copy command buffer to.</p>
<p>The first thing required is to determine how many bytes we need to allocate. This is quite simple as we can get the size of a T from std::mem::size_of, and we know how many T&rsquo;s there are. We must, however also convert this to a DeviceSize, which is a type alias for u64, because size_of returns a usize.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> size <span style="color:#f92672">=</span> (mem::size_of::<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span>() <span style="color:#f92672">*</span> elements.len()) <span style="color:#66d9ef">as</span> DeviceSize;</span></span></code></pre></div>
<p>Next we need to create 2 buffers, and backing memory storage. One will be for the staging buffer and will be dropped after copying the data, which will require a usage flag of <strong>TRANSFER_SRC</strong>, and will require a memory type that is <strong>HOST_VISIBLE</strong> and <strong>HOST_COHERENT</strong>.</p>
<p>The device local buffer we will be returning needs to have <strong>TRANSFER_DST</strong>, and the memory type needs to be <strong>DEVICE_LOCAL</strong>. Written as code this would be</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> (staging_buffer, staging_buffer_memory) <span style="color:#f92672">=</span> create_buffer(
</span></span><span style="display:flex;"><span>    instance,
</span></span><span style="display:flex;"><span>    device,
</span></span><span style="display:flex;"><span>    physical_device,
</span></span><span style="display:flex;"><span>    usage <span style="color:#f92672">|</span> BufferUsageFlags::<span style="color:#66d9ef">TRANSFER_SRC</span>,
</span></span><span style="display:flex;"><span>    MemoryPropertyFlags::<span style="color:#66d9ef">HOST_VISIBLE</span> <span style="color:#f92672">|</span> MemoryPropertyFlags::<span style="color:#66d9ef">HOST_COHERENT</span>,
</span></span><span style="display:flex;"><span>    size,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>.context(<span style="color:#e6db74">&#34;Failed to create staging buffer.&#34;</span>)<span style="color:#f92672">?</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> (gpu_buffer, gpu_buffer_memory) <span style="color:#f92672">=</span> create_buffer(
</span></span><span style="display:flex;"><span>    instance,
</span></span><span style="display:flex;"><span>    device,
</span></span><span style="display:flex;"><span>    physical_device,
</span></span><span style="display:flex;"><span>    usage <span style="color:#f92672">|</span> BufferUsageFlags::<span style="color:#66d9ef">TRANSFER_DST</span>,
</span></span><span style="display:flex;"><span>    MemoryPropertyFlags::<span style="color:#66d9ef">DEVICE_LOCAL</span>,
</span></span><span style="display:flex;"><span>    size,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>.context(<span style="color:#e6db74">&#34;Failed to create GPU buffer.&#34;</span>)<span style="color:#f92672">?</span>;</span></span></code></pre></div>
<p>We then go ahead and copy the data from our slice of T&rsquo;s to the allocated staging buffer memory using the method that we previously used for our vertex buffer (map, write, unmap)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> write_ptr <span style="color:#f92672">=</span> device
</span></span><span style="display:flex;"><span>    .map_memory(staging_buffer_memory, <span style="color:#ae81ff">0</span>, size, MemoryMapFlags::empty())
</span></span><span style="display:flex;"><span>    .context(<span style="color:#e6db74">&#34;Failed to map the staging buffer memory.&#34;</span>)<span style="color:#f92672">?</span> <span style="color:#66d9ef">as</span> <span style="color:#f92672">*</span><span style="color:#66d9ef">mut</span> T;
</span></span><span style="display:flex;"><span>ptr::copy_nonoverlapping(elements.as_ptr(), write_ptr, elements.len());
</span></span><span style="display:flex;"><span>device.unmap_memory(staging_buffer_memory);</span></span></code></pre></div>
<p>Our data is now residing in our staging buffer so we can tell Vulkan to transfer it to our device local buffer. To do this we first need to allocate a command buffer to record the copy operation into. This needs to be a primary command buffer because we will be submitting it directly to the queue.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> command_buffer <span style="color:#f92672">=</span> device
</span></span><span style="display:flex;"><span>    .allocate_command_buffers(
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&amp;</span>CommandBufferAllocateInfo::builder()
</span></span><span style="display:flex;"><span>            .command_pool(transfer_command_pool)
</span></span><span style="display:flex;"><span>            .level(CommandBufferLevel::<span style="color:#66d9ef">PRIMARY</span>)
</span></span><span style="display:flex;"><span>            .command_buffer_count(<span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    .context(<span style="color:#e6db74">&#34;Failed to allocate a staging transfer command buffer.&#34;</span>)<span style="color:#f92672">?</span>[<span style="color:#ae81ff">0</span>];</span></span></code></pre></div>
<p>Before we can record any commands to the buffer, we need to tell Vulkan we are starting to record to that particular buffer. In this case we will use the <strong>ONE_TIME_SUBMIT</strong> flag since we will be returning the command buffer to the pool once the copy operation is over.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>device
</span></span><span style="display:flex;"><span>    .begin_command_buffer(
</span></span><span style="display:flex;"><span>        command_buffer,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&amp;</span>CommandBufferBeginInfo::builder().flags(CommandBufferUsageFlags::<span style="color:#66d9ef">ONE_TIME_SUBMIT</span>),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    .context(<span style="color:#e6db74">&#34;Failed to begin recording the command buffer.&#34;</span>)<span style="color:#f92672">?</span>;</span></span></code></pre></div>
<p>Now that we&rsquo;ve told Vulkan we&rsquo;re recording our commands into that buffer, we can go ahead and issue our command. In this case we have only a single command to do a buffer copy operation.</p>
<p>Vulkan expects the source buffer, and the destination buffer, but also we can specify offsets in each to copy with. In our case though, we copy from the beginning of the source buffer (our staging buffer), to the beginning of the destination buffer (our device local buffer).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>device.cmd_copy_buffer(
</span></span><span style="display:flex;"><span>    command_buffer,
</span></span><span style="display:flex;"><span>    staging_buffer,
</span></span><span style="display:flex;"><span>    gpu_buffer,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&amp;</span>[<span style="color:#f92672">*</span>BufferCopy::builder().size(size)],
</span></span><span style="display:flex;"><span>);</span></span></code></pre></div>
<p>With that, we can tell Vulkan we&rsquo;re done recording commands into the command buffer</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>device
</span></span><span style="display:flex;"><span>    .end_command_buffer(command_buffer)
</span></span><span style="display:flex;"><span>    .context(<span style="color:#e6db74">&#34;Failed to end recording the command buffer.&#34;</span>)<span style="color:#f92672">?</span>;</span></span></code></pre></div>
<p>We will now submit the buffer to the transfer queue, much like we submitted our drawing buffer to the graphics queue for rendering. We could provide a fence or semaphore to this operation if needed, but in our case we will push the buffer to the queue, and then <em>wait</em> until the queue is finished processing.</p>
<p>Blocking the CPU like this isn&rsquo;t necessarily a good idea, but it makes the code simpler in this case!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// submit the copy operation to the transfer queue.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> command_buffers <span style="color:#f92672">=</span> [command_buffer];
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> submit_infos <span style="color:#f92672">=</span> [<span style="color:#f92672">*</span>SubmitInfo::builder().command_buffers(<span style="color:#f92672">&amp;</span>command_buffers)];
</span></span><span style="display:flex;"><span>device
</span></span><span style="display:flex;"><span>    .queue_submit(transfer_queue, <span style="color:#f92672">&amp;</span>submit_infos, Fence::null())
</span></span><span style="display:flex;"><span>    .context(<span style="color:#e6db74">&#34;Failed to submit the command buffer to the queue.&#34;</span>)<span style="color:#f92672">?</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// block the thread until the copy operation is finished.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>device
</span></span><span style="display:flex;"><span>    .queue_wait_idle(transfer_queue)
</span></span><span style="display:flex;"><span>    .context(<span style="color:#e6db74">&#34;Failed to wait for the transfer to finish.&#34;</span>)<span style="color:#f92672">?</span>;</span></span></code></pre></div>
<p>After the copy operation is finished we have no more need for the transfer command buffer, nor for the staging buffer/memory so we free those. Note that we might want to keep these around for re-use in a bigger application but for now, we are just pushing the data to the GPU once and never changing it, so we can do that at the beginning an drop the staging buffers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>device.free_command_buffers(transfer_command_pool, <span style="color:#f92672">&amp;</span>[command_buffer]);
</span></span><span style="display:flex;"><span>device.free_memory(staging_buffer_memory, None);
</span></span><span style="display:flex;"><span>device.destroy_buffer(staging_buffer, None);</span></span></code></pre></div>
<h1 id="modifying-the-vertex-shader-function">Modifying the Vertex Shader Function<a hidden class="anchor" aria-hidden="true" href="#modifying-the-vertex-shader-function">#</a></h1>
<p>Finally, we can go ahead and just modify the create_vertex_shader function to simply use the staged buffer function we just created, with a buffer usage type of <strong>VERTEX_BUFFER</strong>. Since the function is so simple I&rsquo;ll just drop all the code here.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">create_vertex_buffer</span>(
</span></span><span style="display:flex;"><span>    instance: <span style="color:#66d9ef">&amp;</span><span style="color:#a6e22e">Instance</span>,
</span></span><span style="display:flex;"><span>    device: <span style="color:#66d9ef">&amp;</span><span style="color:#a6e22e">Device</span>,
</span></span><span style="display:flex;"><span>    physical_device: <span style="color:#a6e22e">PhysicalDevice</span>,
</span></span><span style="display:flex;"><span>    vertices: <span style="color:#66d9ef">&amp;</span>[Vertex],
</span></span><span style="display:flex;"><span>    transfer_command_pool: <span style="color:#a6e22e">CommandPool</span>,
</span></span><span style="display:flex;"><span>    transfer_queue: <span style="color:#a6e22e">Queue</span>,
</span></span><span style="display:flex;"><span>) -&gt; Result<span style="color:#f92672">&lt;</span>(Buffer, DeviceMemory)<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>    create_staged_buffer(
</span></span><span style="display:flex;"><span>        instance,
</span></span><span style="display:flex;"><span>        device,
</span></span><span style="display:flex;"><span>        physical_device,
</span></span><span style="display:flex;"><span>        vertices,
</span></span><span style="display:flex;"><span>        BufferUsageFlags::<span style="color:#66d9ef">VERTEX_BUFFER</span>,
</span></span><span style="display:flex;"><span>        transfer_command_pool,
</span></span><span style="display:flex;"><span>        transfer_queue,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    .context(<span style="color:#e6db74">&#34;Failed to create a vertex buffer.&#34;</span>)
</span></span><span style="display:flex;"><span>}</span></span></code></pre></div>
<h1 id="testing">Testing<a hidden class="anchor" aria-hidden="true" href="#testing">#</a></h1>
<p>We&rsquo;ll go ahead and test that after making tese changes our program still works as before.</p>
<p><img loading="lazy" src="output.png" alt="Multicolor Square"  />
</p>
<p>Indeed it does! (and now our vertex data resides in the much faster GPU-only memory section :D)</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://forgottenmaster.github.io/">Robin Smith</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></body>

</html>
